{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data# Import the data\n",
    "df = pd.read_csv(\"../crowding_data.csv\", low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'expid', 'membid', 'myear', 'sex', 'calcage', 'citizen', 'status',\n",
       "       'msolo', 'msuccess', 'msmtdate1', 'msmtdate2', 'msmtdate3', 'route1',\n",
       "       'route2', 'route3', 'route4', 'mo2used', 'mo2none', 'mo2climb',\n",
       "       'mo2descent', 'mo2sleep', 'death', 'deathdate', 'msmtbid', 'stdrte',\n",
       "       'new_route', 'new_status', 'climber_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View column names and drop unnecesary columns for the model \n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set features\n",
    "feature_names = ['sex', 'calcage', 'citizen', 'new_route', 'mo2used', 'mo2climb',\n",
    "                 'mo2descent', 'mo2sleep', 'stdrte', 'new_status', 'climber_count']\n",
    "\n",
    "X = df[feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>calcage</th>\n",
       "      <th>citizen</th>\n",
       "      <th>new_route</th>\n",
       "      <th>mo2used</th>\n",
       "      <th>mo2climb</th>\n",
       "      <th>mo2descent</th>\n",
       "      <th>mo2sleep</th>\n",
       "      <th>stdrte</th>\n",
       "      <th>new_status</th>\n",
       "      <th>climber_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>82</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>82</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15003</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15004</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15005</th>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15006</th>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15007</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15008 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sex  calcage  citizen  new_route  mo2used  mo2climb  mo2descent  \\\n",
       "0        0       32       15          2      1.0       1.0         0.0   \n",
       "1        0       40       82          2      0.0       0.0         0.0   \n",
       "2        0       29       82          2      1.0       1.0         0.0   \n",
       "3        0       37       82          1      0.0       0.0         0.0   \n",
       "4        0       33       82          1      0.0       0.0         0.0   \n",
       "...    ...      ...      ...        ...      ...       ...         ...   \n",
       "15003    1       16       27          0      1.0       1.0         0.0   \n",
       "15004    0       37       27          0      1.0       1.0         0.0   \n",
       "15005    0       57       27          0      1.0       1.0         0.0   \n",
       "15006    0       35       27          0      1.0       1.0         0.0   \n",
       "15007    0       37       27          0      1.0       1.0         0.0   \n",
       "\n",
       "       mo2sleep  stdrte  new_status  climber_count  \n",
       "0           1.0     1.0           2            3.0  \n",
       "1           0.0     1.0           2            3.0  \n",
       "2           1.0     1.0           2            3.0  \n",
       "3           0.0     0.0           1            3.0  \n",
       "4           0.0     0.0           1            3.0  \n",
       "...         ...     ...         ...            ...  \n",
       "15003       1.0     1.0           0           15.0  \n",
       "15004       1.0     1.0           0           15.0  \n",
       "15005       1.0     1.0           0           15.0  \n",
       "15006       1.0     1.0           0           15.0  \n",
       "15007       1.0     1.0           0           15.0  \n",
       "\n",
       "[15008 rows x 11 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert X values to numerical \n",
    "\n",
    "###                KEY                  ### \n",
    "###        Male = 0, Female = 1         ###\n",
    "###        True = 1, False = 0          ###\n",
    "###  Citizen and Route = see label map  ###\n",
    "\n",
    "X.replace(True, 1, inplace=True)\n",
    "X['sex'] = pd.get_dummies(X['sex'])\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "# Perform label transformation and create label maps for later use \n",
    "X['citizen'] = le.fit_transform(X['citizen'])\n",
    "country_label_map = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "X['new_route'] = le.fit_transform(X['new_route'])\n",
    "route_label_map = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "X['new_status'] = le.fit_transform(X['new_route'])\n",
    "status_label_map = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_names = df['death'].unique()\n",
    "target_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y  = df['death']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Train Test Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "Scale the data using the MinMaxScaler and perform some feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create the scaler\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "\n",
    "# Transform the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the y values to numerical using label_encoder/to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)\n",
    "y_test_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and initial trial model and add layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "inputs = X_train.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=60, activation='relu', input_dim=inputs))\n",
    "model.add(Dense(units=200, activation='relu'))\n",
    "model.add(Dense(units=2, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 60)                720       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200)               12200     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 402       \n",
      "=================================================================\n",
      "Total params: 13,322\n",
      "Trainable params: 13,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "352/352 - 1s - loss: 0.0902 - accuracy: 0.9835\n",
      "Epoch 2/100\n",
      "352/352 - 0s - loss: 0.0661 - accuracy: 0.9870\n",
      "Epoch 3/100\n",
      "352/352 - 0s - loss: 0.0655 - accuracy: 0.9870\n",
      "Epoch 4/100\n",
      "352/352 - 0s - loss: 0.0647 - accuracy: 0.9870\n",
      "Epoch 5/100\n",
      "352/352 - 0s - loss: 0.0646 - accuracy: 0.9870\n",
      "Epoch 6/100\n",
      "352/352 - 0s - loss: 0.0643 - accuracy: 0.9870\n",
      "Epoch 7/100\n",
      "352/352 - 0s - loss: 0.0638 - accuracy: 0.9870\n",
      "Epoch 8/100\n",
      "352/352 - 0s - loss: 0.0635 - accuracy: 0.9870\n",
      "Epoch 9/100\n",
      "352/352 - 0s - loss: 0.0632 - accuracy: 0.9870\n",
      "Epoch 10/100\n",
      "352/352 - 0s - loss: 0.0632 - accuracy: 0.9870\n",
      "Epoch 11/100\n",
      "352/352 - 0s - loss: 0.0634 - accuracy: 0.9870\n",
      "Epoch 12/100\n",
      "352/352 - 0s - loss: 0.0631 - accuracy: 0.9870\n",
      "Epoch 13/100\n",
      "352/352 - 0s - loss: 0.0630 - accuracy: 0.9870\n",
      "Epoch 14/100\n",
      "352/352 - 0s - loss: 0.0626 - accuracy: 0.9870\n",
      "Epoch 15/100\n",
      "352/352 - 0s - loss: 0.0626 - accuracy: 0.9870\n",
      "Epoch 16/100\n",
      "352/352 - 0s - loss: 0.0624 - accuracy: 0.9870\n",
      "Epoch 17/100\n",
      "352/352 - 0s - loss: 0.0629 - accuracy: 0.9870\n",
      "Epoch 18/100\n",
      "352/352 - 0s - loss: 0.0625 - accuracy: 0.9870\n",
      "Epoch 19/100\n",
      "352/352 - 0s - loss: 0.0620 - accuracy: 0.9870\n",
      "Epoch 20/100\n",
      "352/352 - 0s - loss: 0.0621 - accuracy: 0.9870\n",
      "Epoch 21/100\n",
      "352/352 - 0s - loss: 0.0621 - accuracy: 0.9870\n",
      "Epoch 22/100\n",
      "352/352 - 0s - loss: 0.0616 - accuracy: 0.9870\n",
      "Epoch 23/100\n",
      "352/352 - 0s - loss: 0.0618 - accuracy: 0.9870\n",
      "Epoch 24/100\n",
      "352/352 - 0s - loss: 0.0614 - accuracy: 0.9870\n",
      "Epoch 25/100\n",
      "352/352 - 0s - loss: 0.0615 - accuracy: 0.9870\n",
      "Epoch 26/100\n",
      "352/352 - 0s - loss: 0.0618 - accuracy: 0.9870\n",
      "Epoch 27/100\n",
      "352/352 - 0s - loss: 0.0607 - accuracy: 0.9871\n",
      "Epoch 28/100\n",
      "352/352 - 0s - loss: 0.0614 - accuracy: 0.9869\n",
      "Epoch 29/100\n",
      "352/352 - 0s - loss: 0.0607 - accuracy: 0.9870\n",
      "Epoch 30/100\n",
      "352/352 - 0s - loss: 0.0604 - accuracy: 0.9870\n",
      "Epoch 31/100\n",
      "352/352 - 0s - loss: 0.0606 - accuracy: 0.9870\n",
      "Epoch 32/100\n",
      "352/352 - 0s - loss: 0.0605 - accuracy: 0.9869\n",
      "Epoch 33/100\n",
      "352/352 - 0s - loss: 0.0603 - accuracy: 0.9871\n",
      "Epoch 34/100\n",
      "352/352 - 0s - loss: 0.0601 - accuracy: 0.9870\n",
      "Epoch 35/100\n",
      "352/352 - 0s - loss: 0.0602 - accuracy: 0.9870\n",
      "Epoch 36/100\n",
      "352/352 - 0s - loss: 0.0599 - accuracy: 0.9869\n",
      "Epoch 37/100\n",
      "352/352 - 0s - loss: 0.0601 - accuracy: 0.9869\n",
      "Epoch 38/100\n",
      "352/352 - 0s - loss: 0.0596 - accuracy: 0.9871\n",
      "Epoch 39/100\n",
      "352/352 - 0s - loss: 0.0603 - accuracy: 0.9870\n",
      "Epoch 40/100\n",
      "352/352 - 0s - loss: 0.0598 - accuracy: 0.9870\n",
      "Epoch 41/100\n",
      "352/352 - 0s - loss: 0.0594 - accuracy: 0.9870\n",
      "Epoch 42/100\n",
      "352/352 - 0s - loss: 0.0596 - accuracy: 0.9870\n",
      "Epoch 43/100\n",
      "352/352 - 0s - loss: 0.0595 - accuracy: 0.9869\n",
      "Epoch 44/100\n",
      "352/352 - 0s - loss: 0.0593 - accuracy: 0.9870\n",
      "Epoch 45/100\n",
      "352/352 - 0s - loss: 0.0592 - accuracy: 0.9871\n",
      "Epoch 46/100\n",
      "352/352 - 0s - loss: 0.0591 - accuracy: 0.9869\n",
      "Epoch 47/100\n",
      "352/352 - 0s - loss: 0.0586 - accuracy: 0.9872\n",
      "Epoch 48/100\n",
      "352/352 - 0s - loss: 0.0593 - accuracy: 0.9871\n",
      "Epoch 49/100\n",
      "352/352 - 0s - loss: 0.0589 - accuracy: 0.9869\n",
      "Epoch 50/100\n",
      "352/352 - 0s - loss: 0.0584 - accuracy: 0.9870\n",
      "Epoch 51/100\n",
      "352/352 - 0s - loss: 0.0583 - accuracy: 0.9871\n",
      "Epoch 52/100\n",
      "352/352 - 0s - loss: 0.0584 - accuracy: 0.9872\n",
      "Epoch 53/100\n",
      "352/352 - 0s - loss: 0.0583 - accuracy: 0.9871\n",
      "Epoch 54/100\n",
      "352/352 - 0s - loss: 0.0582 - accuracy: 0.9870\n",
      "Epoch 55/100\n",
      "352/352 - 0s - loss: 0.0579 - accuracy: 0.9869\n",
      "Epoch 56/100\n",
      "352/352 - 0s - loss: 0.0580 - accuracy: 0.9869\n",
      "Epoch 57/100\n",
      "352/352 - 0s - loss: 0.0582 - accuracy: 0.9870\n",
      "Epoch 58/100\n",
      "352/352 - 0s - loss: 0.0575 - accuracy: 0.9870\n",
      "Epoch 59/100\n",
      "352/352 - 0s - loss: 0.0576 - accuracy: 0.9870\n",
      "Epoch 60/100\n",
      "352/352 - 0s - loss: 0.0576 - accuracy: 0.9873\n",
      "Epoch 61/100\n",
      "352/352 - 0s - loss: 0.0572 - accuracy: 0.9870\n",
      "Epoch 62/100\n",
      "352/352 - 0s - loss: 0.0569 - accuracy: 0.9870\n",
      "Epoch 63/100\n",
      "352/352 - 0s - loss: 0.0574 - accuracy: 0.9871\n",
      "Epoch 64/100\n",
      "352/352 - 0s - loss: 0.0570 - accuracy: 0.9871\n",
      "Epoch 65/100\n",
      "352/352 - 0s - loss: 0.0570 - accuracy: 0.9871\n",
      "Epoch 66/100\n",
      "352/352 - 0s - loss: 0.0565 - accuracy: 0.9870\n",
      "Epoch 67/100\n",
      "352/352 - 0s - loss: 0.0570 - accuracy: 0.9870\n",
      "Epoch 68/100\n",
      "352/352 - 0s - loss: 0.0568 - accuracy: 0.9871\n",
      "Epoch 69/100\n",
      "352/352 - 0s - loss: 0.0571 - accuracy: 0.9870\n",
      "Epoch 70/100\n",
      "352/352 - 0s - loss: 0.0561 - accuracy: 0.9873\n",
      "Epoch 71/100\n",
      "352/352 - 0s - loss: 0.0568 - accuracy: 0.9871\n",
      "Epoch 72/100\n",
      "352/352 - 0s - loss: 0.0561 - accuracy: 0.9871\n",
      "Epoch 73/100\n",
      "352/352 - 0s - loss: 0.0555 - accuracy: 0.9872\n",
      "Epoch 74/100\n",
      "352/352 - 0s - loss: 0.0557 - accuracy: 0.9875\n",
      "Epoch 75/100\n",
      "352/352 - 0s - loss: 0.0565 - accuracy: 0.9870\n",
      "Epoch 76/100\n",
      "352/352 - 0s - loss: 0.0558 - accuracy: 0.9873\n",
      "Epoch 77/100\n",
      "352/352 - 0s - loss: 0.0564 - accuracy: 0.9873\n",
      "Epoch 78/100\n",
      "352/352 - 0s - loss: 0.0556 - accuracy: 0.9874\n",
      "Epoch 79/100\n",
      "352/352 - 0s - loss: 0.0557 - accuracy: 0.9870\n",
      "Epoch 80/100\n",
      "352/352 - 0s - loss: 0.0554 - accuracy: 0.9873\n",
      "Epoch 81/100\n",
      "352/352 - 0s - loss: 0.0556 - accuracy: 0.9873\n",
      "Epoch 82/100\n",
      "352/352 - 0s - loss: 0.0551 - accuracy: 0.9870\n",
      "Epoch 83/100\n",
      "352/352 - 0s - loss: 0.0547 - accuracy: 0.9874\n",
      "Epoch 84/100\n",
      "352/352 - 0s - loss: 0.0550 - accuracy: 0.9870\n",
      "Epoch 85/100\n",
      "352/352 - 0s - loss: 0.0545 - accuracy: 0.9876\n",
      "Epoch 86/100\n",
      "352/352 - 0s - loss: 0.0548 - accuracy: 0.9871\n",
      "Epoch 87/100\n",
      "352/352 - 0s - loss: 0.0545 - accuracy: 0.9874\n",
      "Epoch 88/100\n",
      "352/352 - 0s - loss: 0.0548 - accuracy: 0.9870\n",
      "Epoch 89/100\n",
      "352/352 - 0s - loss: 0.0546 - accuracy: 0.9874\n",
      "Epoch 90/100\n",
      "352/352 - 0s - loss: 0.0542 - accuracy: 0.9874\n",
      "Epoch 91/100\n",
      "352/352 - 0s - loss: 0.0544 - accuracy: 0.9874\n",
      "Epoch 92/100\n",
      "352/352 - 0s - loss: 0.0538 - accuracy: 0.9877\n",
      "Epoch 93/100\n",
      "352/352 - 0s - loss: 0.0544 - accuracy: 0.9873\n",
      "Epoch 94/100\n",
      "352/352 - 0s - loss: 0.0547 - accuracy: 0.9874\n",
      "Epoch 95/100\n",
      "352/352 - 0s - loss: 0.0545 - accuracy: 0.9874\n",
      "Epoch 96/100\n",
      "352/352 - 0s - loss: 0.0541 - accuracy: 0.9875\n",
      "Epoch 97/100\n",
      "352/352 - 0s - loss: 0.0540 - accuracy: 0.9874\n",
      "Epoch 98/100\n",
      "352/352 - 0s - loss: 0.0537 - accuracy: 0.9874\n",
      "Epoch 99/100\n",
      "352/352 - 0s - loss: 0.0541 - accuracy: 0.9873\n",
      "Epoch 100/100\n",
      "352/352 - 0s - loss: 0.0535 - accuracy: 0.9872\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25f122eee80>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    verbose=2,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantify Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 - 0s - loss: 0.0907 - accuracy: 0.9843\n",
      "Neural Network Performace - Loss: 0.09071195870637894, Accuracy: 0.9842750430107117\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(f\"Neural Network Performace - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Risk of death for data point 50 is 0.35%\n"
     ]
    }
   ],
   "source": [
    "x = X_train_scaled[50].tolist()\n",
    "result = model.predict([x])\n",
    "print(f\"Risk of death for data point 50 is {round(result[0][1]*100,2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 540x540 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a confusion matrix to visualise the performance \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "predictions = np.argmax(model.predict(X_test_scaled), axis=-1)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true=encoded_y_test, y_pred=predictions)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
    "\n",
    "ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)\n",
    "\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        ax.text(x=j, y=i, s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
    "\n",
    "plt.title('Confusion Matrix', fontsize=18)\n",
    "plt.xlabel('Predictions', fontsize=18)\n",
    "ax.set_xticks([0,1])\n",
    "ax.set_xticklabels(target_names)\n",
    "plt.ylabel('Actuals', fontsize=18)\n",
    "ax.set_yticks([0,1])\n",
    "ax.set_yticklabels(target_names)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperperameter tuning\n",
    "\n",
    "#### Talos Custom Hyperparameter Optimiser for Keras, Tensorflow used \n",
    "Availble from: <a href=\"https://github.com/autonomio/talos/\">https://github.com/autonomio/talos/</a>\n",
    "<img src=\"https://raw.githubusercontent.com/autonomio/talos/master/logo.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import talos\n",
    "\n",
    "# Function to run the model \n",
    "def everest(x_train, y_train, x_val, y_val, params):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(params['first_neuron'], input_dim=x_train.shape[1], \n",
    "              activation=params['activation']))\n",
    " \n",
    "    model.add(Dropout(params['dropout']))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=params['optimizer'], metrics=['accuracy'])\n",
    "    \n",
    "    out = model.fit(x_train, \n",
    "                    y_train,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    epochs=params['epochs'],\n",
    "                    batch_size=params['batch_size'],\n",
    "                    verbose=0)\n",
    "    \n",
    "    return out, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a parameter dictionary\n",
    "p = {'first_neuron':[30,60,120,240],\n",
    "    'hidden_layers':[1, 2],\n",
    "    'batch_size': [10,20, 30],\n",
    "    'epochs': [100, 150, 200],\n",
    "    'dropout': [0],\n",
    "    'optimizer': ['Nadam', 'Adam'],\n",
    "    'losses': ['binary_crossentropy'],\n",
    "    'activation':['relu'],\n",
    "    'last_activation': ['sigmoid']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [28:06<00:00, 56.20s/it]\n"
     ]
    }
   ],
   "source": [
    "t = talos.Scan(x=X_train_scaled, y=encoded_y_train, params=p, model=everest, experiment_name='everest_tune', round_limit=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "experiment_name            everest_tune\n",
       "random_method          uniform_mersenne\n",
       "reduction_method                   None\n",
       "reduction_interval                   50\n",
       "reduction_window                     20\n",
       "reduction_threshold                 0.2\n",
       "reduction_metric                val_acc\n",
       "complete_time            08/25/21/10:05\n",
       "x_shape                     (11256, 11)\n",
       "y_shape                        (11256,)\n",
       "dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best parameters:  \n",
    "  \n",
    "There are a a number of models which reach an accuracy of 98.8451% with validation data set\n",
    "\n",
    "Note that the underlying rate death rate in data is only 1.4% so it is relatively 'easy' to achieve high accuarcy with this model\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>duration</th>\n",
       "      <th>round_epochs</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>activation</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>dropout</th>\n",
       "      <th>epochs</th>\n",
       "      <th>first_neuron</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>last_activation</th>\n",
       "      <th>losses</th>\n",
       "      <th>optimizer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>08/25/21-093655</td>\n",
       "      <td>08/25/21-093818</td>\n",
       "      <td>82.559456</td>\n",
       "      <td>150</td>\n",
       "      <td>0.058237</td>\n",
       "      <td>0.986673</td>\n",
       "      <td>0.060787</td>\n",
       "      <td>0.987267</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>08/25/21-093818</td>\n",
       "      <td>08/25/21-094033</td>\n",
       "      <td>135.116495</td>\n",
       "      <td>200</td>\n",
       "      <td>0.057235</td>\n",
       "      <td>0.986927</td>\n",
       "      <td>0.062950</td>\n",
       "      <td>0.986971</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>08/25/21-094033</td>\n",
       "      <td>08/25/21-094159</td>\n",
       "      <td>85.866252</td>\n",
       "      <td>150</td>\n",
       "      <td>0.056830</td>\n",
       "      <td>0.986673</td>\n",
       "      <td>0.061799</td>\n",
       "      <td>0.986378</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>240</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>08/25/21-094159</td>\n",
       "      <td>08/25/21-094304</td>\n",
       "      <td>64.973133</td>\n",
       "      <td>200</td>\n",
       "      <td>0.057016</td>\n",
       "      <td>0.986547</td>\n",
       "      <td>0.065341</td>\n",
       "      <td>0.987267</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>120</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08/25/21-094305</td>\n",
       "      <td>08/25/21-094328</td>\n",
       "      <td>22.989416</td>\n",
       "      <td>100</td>\n",
       "      <td>0.059663</td>\n",
       "      <td>0.986547</td>\n",
       "      <td>0.059242</td>\n",
       "      <td>0.987563</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>240</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>08/25/21-094328</td>\n",
       "      <td>08/25/21-094400</td>\n",
       "      <td>31.974996</td>\n",
       "      <td>150</td>\n",
       "      <td>0.062745</td>\n",
       "      <td>0.986420</td>\n",
       "      <td>0.057353</td>\n",
       "      <td>0.988747</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>08/25/21-094400</td>\n",
       "      <td>08/25/21-094432</td>\n",
       "      <td>32.031708</td>\n",
       "      <td>100</td>\n",
       "      <td>0.060651</td>\n",
       "      <td>0.986420</td>\n",
       "      <td>0.059389</td>\n",
       "      <td>0.988451</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>08/25/21-094432</td>\n",
       "      <td>08/25/21-094517</td>\n",
       "      <td>44.957690</td>\n",
       "      <td>200</td>\n",
       "      <td>0.059123</td>\n",
       "      <td>0.986547</td>\n",
       "      <td>0.059992</td>\n",
       "      <td>0.987563</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>08/25/21-094517</td>\n",
       "      <td>08/25/21-094558</td>\n",
       "      <td>41.377290</td>\n",
       "      <td>200</td>\n",
       "      <td>0.062547</td>\n",
       "      <td>0.986420</td>\n",
       "      <td>0.059163</td>\n",
       "      <td>0.988155</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>08/25/21-094559</td>\n",
       "      <td>08/25/21-094759</td>\n",
       "      <td>120.428813</td>\n",
       "      <td>200</td>\n",
       "      <td>0.055078</td>\n",
       "      <td>0.986673</td>\n",
       "      <td>0.070175</td>\n",
       "      <td>0.986082</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>240</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>08/25/21-094759</td>\n",
       "      <td>08/25/21-094848</td>\n",
       "      <td>48.703024</td>\n",
       "      <td>150</td>\n",
       "      <td>0.056852</td>\n",
       "      <td>0.986927</td>\n",
       "      <td>0.062387</td>\n",
       "      <td>0.987267</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>240</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>08/25/21-094848</td>\n",
       "      <td>08/25/21-094948</td>\n",
       "      <td>59.586558</td>\n",
       "      <td>100</td>\n",
       "      <td>0.059352</td>\n",
       "      <td>0.986547</td>\n",
       "      <td>0.058147</td>\n",
       "      <td>0.987563</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>08/25/21-094948</td>\n",
       "      <td>08/25/21-095023</td>\n",
       "      <td>35.243486</td>\n",
       "      <td>150</td>\n",
       "      <td>0.060820</td>\n",
       "      <td>0.986420</td>\n",
       "      <td>0.058882</td>\n",
       "      <td>0.988451</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>08/25/21-095023</td>\n",
       "      <td>08/25/21-095154</td>\n",
       "      <td>91.016913</td>\n",
       "      <td>150</td>\n",
       "      <td>0.062668</td>\n",
       "      <td>0.986293</td>\n",
       "      <td>0.057646</td>\n",
       "      <td>0.988451</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>08/25/21-095154</td>\n",
       "      <td>08/25/21-095358</td>\n",
       "      <td>123.747282</td>\n",
       "      <td>200</td>\n",
       "      <td>0.058564</td>\n",
       "      <td>0.986927</td>\n",
       "      <td>0.059509</td>\n",
       "      <td>0.987267</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>08/25/21-095358</td>\n",
       "      <td>08/25/21-095421</td>\n",
       "      <td>22.705173</td>\n",
       "      <td>100</td>\n",
       "      <td>0.061064</td>\n",
       "      <td>0.986420</td>\n",
       "      <td>0.057298</td>\n",
       "      <td>0.988451</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>120</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>08/25/21-095421</td>\n",
       "      <td>08/25/21-095454</td>\n",
       "      <td>33.308071</td>\n",
       "      <td>150</td>\n",
       "      <td>0.062174</td>\n",
       "      <td>0.986420</td>\n",
       "      <td>0.057967</td>\n",
       "      <td>0.988451</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>08/25/21-095454</td>\n",
       "      <td>08/25/21-095547</td>\n",
       "      <td>52.159812</td>\n",
       "      <td>150</td>\n",
       "      <td>0.057970</td>\n",
       "      <td>0.986547</td>\n",
       "      <td>0.061046</td>\n",
       "      <td>0.987563</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>120</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>08/25/21-095547</td>\n",
       "      <td>08/25/21-095650</td>\n",
       "      <td>63.800113</td>\n",
       "      <td>100</td>\n",
       "      <td>0.061232</td>\n",
       "      <td>0.986293</td>\n",
       "      <td>0.059006</td>\n",
       "      <td>0.988451</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>08/25/21-095651</td>\n",
       "      <td>08/25/21-095900</td>\n",
       "      <td>129.075963</td>\n",
       "      <td>200</td>\n",
       "      <td>0.060962</td>\n",
       "      <td>0.986547</td>\n",
       "      <td>0.060700</td>\n",
       "      <td>0.987563</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>08/25/21-095900</td>\n",
       "      <td>08/25/21-100006</td>\n",
       "      <td>66.110779</td>\n",
       "      <td>200</td>\n",
       "      <td>0.055119</td>\n",
       "      <td>0.986927</td>\n",
       "      <td>0.066911</td>\n",
       "      <td>0.986082</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>240</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>08/25/21-100006</td>\n",
       "      <td>08/25/21-100039</td>\n",
       "      <td>33.358451</td>\n",
       "      <td>100</td>\n",
       "      <td>0.058746</td>\n",
       "      <td>0.986420</td>\n",
       "      <td>0.059514</td>\n",
       "      <td>0.987563</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>240</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>08/25/21-100040</td>\n",
       "      <td>08/25/21-100112</td>\n",
       "      <td>32.616008</td>\n",
       "      <td>100</td>\n",
       "      <td>0.062135</td>\n",
       "      <td>0.986420</td>\n",
       "      <td>0.057237</td>\n",
       "      <td>0.988451</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>08/25/21-100112</td>\n",
       "      <td>08/25/21-100146</td>\n",
       "      <td>33.240554</td>\n",
       "      <td>150</td>\n",
       "      <td>0.057275</td>\n",
       "      <td>0.986673</td>\n",
       "      <td>0.060475</td>\n",
       "      <td>0.987267</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>240</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>08/25/21-100146</td>\n",
       "      <td>08/25/21-100208</td>\n",
       "      <td>22.587174</td>\n",
       "      <td>100</td>\n",
       "      <td>0.061557</td>\n",
       "      <td>0.986420</td>\n",
       "      <td>0.058001</td>\n",
       "      <td>0.988451</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>08/25/21-100208</td>\n",
       "      <td>08/25/21-100230</td>\n",
       "      <td>21.486540</td>\n",
       "      <td>100</td>\n",
       "      <td>0.062001</td>\n",
       "      <td>0.986420</td>\n",
       "      <td>0.057420</td>\n",
       "      <td>0.988451</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>08/25/21-100230</td>\n",
       "      <td>08/25/21-100253</td>\n",
       "      <td>22.827961</td>\n",
       "      <td>100</td>\n",
       "      <td>0.059506</td>\n",
       "      <td>0.986547</td>\n",
       "      <td>0.058192</td>\n",
       "      <td>0.987859</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>240</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>08/25/21-100253</td>\n",
       "      <td>08/25/21-100340</td>\n",
       "      <td>47.185807</td>\n",
       "      <td>150</td>\n",
       "      <td>0.059740</td>\n",
       "      <td>0.986547</td>\n",
       "      <td>0.059548</td>\n",
       "      <td>0.988451</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>08/25/21-100340</td>\n",
       "      <td>08/25/21-100430</td>\n",
       "      <td>50.186030</td>\n",
       "      <td>150</td>\n",
       "      <td>0.060774</td>\n",
       "      <td>0.986420</td>\n",
       "      <td>0.058608</td>\n",
       "      <td>0.988451</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>08/25/21-100431</td>\n",
       "      <td>08/25/21-100501</td>\n",
       "      <td>30.851390</td>\n",
       "      <td>100</td>\n",
       "      <td>0.060067</td>\n",
       "      <td>0.986420</td>\n",
       "      <td>0.058342</td>\n",
       "      <td>0.988451</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>120</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              start              end    duration  round_epochs      loss  \\\n",
       "0   08/25/21-093655  08/25/21-093818   82.559456           150  0.058237   \n",
       "1   08/25/21-093818  08/25/21-094033  135.116495           200  0.057235   \n",
       "2   08/25/21-094033  08/25/21-094159   85.866252           150  0.056830   \n",
       "3   08/25/21-094159  08/25/21-094304   64.973133           200  0.057016   \n",
       "4   08/25/21-094305  08/25/21-094328   22.989416           100  0.059663   \n",
       "5   08/25/21-094328  08/25/21-094400   31.974996           150  0.062745   \n",
       "6   08/25/21-094400  08/25/21-094432   32.031708           100  0.060651   \n",
       "7   08/25/21-094432  08/25/21-094517   44.957690           200  0.059123   \n",
       "8   08/25/21-094517  08/25/21-094558   41.377290           200  0.062547   \n",
       "9   08/25/21-094559  08/25/21-094759  120.428813           200  0.055078   \n",
       "10  08/25/21-094759  08/25/21-094848   48.703024           150  0.056852   \n",
       "11  08/25/21-094848  08/25/21-094948   59.586558           100  0.059352   \n",
       "12  08/25/21-094948  08/25/21-095023   35.243486           150  0.060820   \n",
       "13  08/25/21-095023  08/25/21-095154   91.016913           150  0.062668   \n",
       "14  08/25/21-095154  08/25/21-095358  123.747282           200  0.058564   \n",
       "15  08/25/21-095358  08/25/21-095421   22.705173           100  0.061064   \n",
       "16  08/25/21-095421  08/25/21-095454   33.308071           150  0.062174   \n",
       "17  08/25/21-095454  08/25/21-095547   52.159812           150  0.057970   \n",
       "18  08/25/21-095547  08/25/21-095650   63.800113           100  0.061232   \n",
       "19  08/25/21-095651  08/25/21-095900  129.075963           200  0.060962   \n",
       "20  08/25/21-095900  08/25/21-100006   66.110779           200  0.055119   \n",
       "21  08/25/21-100006  08/25/21-100039   33.358451           100  0.058746   \n",
       "22  08/25/21-100040  08/25/21-100112   32.616008           100  0.062135   \n",
       "23  08/25/21-100112  08/25/21-100146   33.240554           150  0.057275   \n",
       "24  08/25/21-100146  08/25/21-100208   22.587174           100  0.061557   \n",
       "25  08/25/21-100208  08/25/21-100230   21.486540           100  0.062001   \n",
       "26  08/25/21-100230  08/25/21-100253   22.827961           100  0.059506   \n",
       "27  08/25/21-100253  08/25/21-100340   47.185807           150  0.059740   \n",
       "28  08/25/21-100340  08/25/21-100430   50.186030           150  0.060774   \n",
       "29  08/25/21-100431  08/25/21-100501   30.851390           100  0.060067   \n",
       "\n",
       "    accuracy  val_loss  val_accuracy activation  batch_size  dropout  epochs  \\\n",
       "0   0.986673  0.060787      0.987267       relu          10        0     150   \n",
       "1   0.986927  0.062950      0.986971       relu          10        0     200   \n",
       "2   0.986673  0.061799      0.986378       relu          10        0     150   \n",
       "3   0.986547  0.065341      0.987267       relu          20        0     200   \n",
       "4   0.986547  0.059242      0.987563       relu          30        0     100   \n",
       "5   0.986420  0.057353      0.988747       relu          30        0     150   \n",
       "6   0.986420  0.059389      0.988451       relu          20        0     100   \n",
       "7   0.986547  0.059992      0.987563       relu          30        0     200   \n",
       "8   0.986420  0.059163      0.988155       relu          30        0     200   \n",
       "9   0.986673  0.070175      0.986082       relu          10        0     200   \n",
       "10  0.986927  0.062387      0.987267       relu          20        0     150   \n",
       "11  0.986547  0.058147      0.987563       relu          10        0     100   \n",
       "12  0.986420  0.058882      0.988451       relu          30        0     150   \n",
       "13  0.986293  0.057646      0.988451       relu          10        0     150   \n",
       "14  0.986927  0.059509      0.987267       relu          10        0     200   \n",
       "15  0.986420  0.057298      0.988451       relu          30        0     100   \n",
       "16  0.986420  0.057967      0.988451       relu          30        0     150   \n",
       "17  0.986547  0.061046      0.987563       relu          20        0     150   \n",
       "18  0.986293  0.059006      0.988451       relu          10        0     100   \n",
       "19  0.986547  0.060700      0.987563       relu          10        0     200   \n",
       "20  0.986927  0.066911      0.986082       relu          20        0     200   \n",
       "21  0.986420  0.059514      0.987563       relu          20        0     100   \n",
       "22  0.986420  0.057237      0.988451       relu          20        0     100   \n",
       "23  0.986673  0.060475      0.987267       relu          30        0     150   \n",
       "24  0.986420  0.058001      0.988451       relu          30        0     100   \n",
       "25  0.986420  0.057420      0.988451       relu          30        0     100   \n",
       "26  0.986547  0.058192      0.987859       relu          30        0     100   \n",
       "27  0.986547  0.059548      0.988451       relu          20        0     150   \n",
       "28  0.986420  0.058608      0.988451       relu          20        0     150   \n",
       "29  0.986420  0.058342      0.988451       relu          20        0     100   \n",
       "\n",
       "    first_neuron  hidden_layers last_activation               losses optimizer  \n",
       "0             60              1         sigmoid  binary_crossentropy      Adam  \n",
       "1             60              2         sigmoid  binary_crossentropy     Nadam  \n",
       "2            240              2         sigmoid  binary_crossentropy     Nadam  \n",
       "3            120              2         sigmoid  binary_crossentropy      Adam  \n",
       "4            240              2         sigmoid  binary_crossentropy     Nadam  \n",
       "5             30              1         sigmoid  binary_crossentropy      Adam  \n",
       "6            120              1         sigmoid  binary_crossentropy      Adam  \n",
       "7             60              1         sigmoid  binary_crossentropy      Adam  \n",
       "8             30              1         sigmoid  binary_crossentropy      Adam  \n",
       "9            240              1         sigmoid  binary_crossentropy     Nadam  \n",
       "10           240              1         sigmoid  binary_crossentropy     Nadam  \n",
       "11           120              1         sigmoid  binary_crossentropy      Adam  \n",
       "12            60              2         sigmoid  binary_crossentropy     Nadam  \n",
       "13            30              2         sigmoid  binary_crossentropy     Nadam  \n",
       "14            60              2         sigmoid  binary_crossentropy      Adam  \n",
       "15           120              2         sigmoid  binary_crossentropy     Nadam  \n",
       "16            30              2         sigmoid  binary_crossentropy     Nadam  \n",
       "17           120              2         sigmoid  binary_crossentropy      Adam  \n",
       "18            60              1         sigmoid  binary_crossentropy      Adam  \n",
       "19            30              1         sigmoid  binary_crossentropy      Adam  \n",
       "20           240              1         sigmoid  binary_crossentropy     Nadam  \n",
       "21           240              1         sigmoid  binary_crossentropy     Nadam  \n",
       "22            30              2         sigmoid  binary_crossentropy     Nadam  \n",
       "23           240              2         sigmoid  binary_crossentropy     Nadam  \n",
       "24           120              1         sigmoid  binary_crossentropy     Nadam  \n",
       "25            60              2         sigmoid  binary_crossentropy     Nadam  \n",
       "26           240              2         sigmoid  binary_crossentropy      Adam  \n",
       "27           120              1         sigmoid  binary_crossentropy     Nadam  \n",
       "28            60              2         sigmoid  binary_crossentropy     Nadam  \n",
       "29           120              2         sigmoid  binary_crossentropy      Adam  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display a dataframe comapring the results of the different combinations \n",
    "t.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the model with the optimised paramaters \n",
    "\n",
    "p_optimisied = {'first_neuron':60,\n",
    "                'second_neuron':200,\n",
    "                'hidden_layers':1,\n",
    "                'batch_size': 30,\n",
    "                'epochs': 150,\n",
    "                'dropout': 0,\n",
    "                'optimizer': 'Nadam',\n",
    "                'activation':'relu',\n",
    "               }\n",
    "\n",
    "def everest_optimised(x_train, y_train, params):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(params['first_neuron'], input_dim=x_train.shape[1], \n",
    "              activation=params['activation']))\n",
    "    \n",
    "#     model.add(Dense(params['second_neuron'], activation=params['activation']))\n",
    " \n",
    "    model.add(Dropout(params['dropout']))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=params['optimizer'], metrics=['accuracy'])\n",
    "    \n",
    "    out = model.fit(x_train, \n",
    "                    y_train,\n",
    "                    epochs=params['epochs'],\n",
    "                    batch_size=params['batch_size'],\n",
    "                    verbose=0)\n",
    "\n",
    "    return out, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-fit the training data to the model\n",
    "out, model = everest_optimised(X_train_scaled, encoded_y_train, p_optimisied)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 - 0s - loss: 0.0777 - accuracy: 0.9845\n",
      "Neural Network Performace - Loss: 0.07768700271844864, Accuracy: 0.9845415949821472\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(X_test_scaled, encoded_y_test, verbose=2)\n",
    "print(f\"Neural Network Performace - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "filename = 'crowding_model_death.h5'\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(\"Model 2 - Deep_learning.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "dev"
  },
  "kernelspec": {
   "display_name": "Python [conda env:PythonData] *",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
