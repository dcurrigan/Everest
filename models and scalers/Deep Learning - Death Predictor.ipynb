{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "df = pd.read_csv(\"clean_data.csv\", low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'expid', 'membid', 'myear', 'sex', 'calcage', 'citizen', 'status',\n",
       "       'msolo', 'msuccess', 'msmtdate1', 'msmtdate2', 'msmtdate3', 'route1',\n",
       "       'route2', 'route3', 'route4', 'mo2used', 'mo2none', 'mo2climb',\n",
       "       'mo2descent', 'mo2sleep', 'death', 'deathdate', 'msmtbid', 'stdrte',\n",
       "       'new_route', 'new_status', 'climber_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View column names and drop unnecesary columns for the model \n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set features\n",
    "feature_names = ['sex', 'calcage', 'citizen', 'msolo', 'new_route', 'mo2used', 'mo2climb',\n",
    "                 'mo2descent', 'mo2sleep', 'stdrte', 'new_status']\n",
    "\n",
    "X = df[feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>calcage</th>\n",
       "      <th>citizen</th>\n",
       "      <th>msolo</th>\n",
       "      <th>new_route</th>\n",
       "      <th>mo2used</th>\n",
       "      <th>mo2climb</th>\n",
       "      <th>mo2descent</th>\n",
       "      <th>mo2sleep</th>\n",
       "      <th>stdrte</th>\n",
       "      <th>new_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21693</th>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21694</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21695</th>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21696</th>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21697</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21698 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sex  calcage  citizen  msolo  new_route  mo2used  mo2climb  mo2descent  \\\n",
       "0        0       49       15    0.0          2      0.0       0.0         0.0   \n",
       "1        1       30       89    0.0          2      0.0       0.0         0.0   \n",
       "2        0       32       15    0.0          2      1.0       1.0         0.0   \n",
       "3        0       40       85    0.0          2      0.0       0.0         0.0   \n",
       "4        0       29       85    0.0          2      1.0       1.0         0.0   \n",
       "...    ...      ...      ...    ...        ...      ...       ...         ...   \n",
       "21693    0       47       28    0.0          0      1.0       1.0         0.0   \n",
       "21694    0       37       28    0.0          0      1.0       1.0         0.0   \n",
       "21695    0       57       28    0.0          0      1.0       1.0         0.0   \n",
       "21696    0       35       28    0.0          0      1.0       1.0         0.0   \n",
       "21697    0       37       28    0.0          0      1.0       1.0         0.0   \n",
       "\n",
       "       mo2sleep  stdrte  new_status  \n",
       "0           0.0     1.0           2  \n",
       "1           0.0     1.0           2  \n",
       "2           1.0     1.0           2  \n",
       "3           0.0     1.0           2  \n",
       "4           1.0     1.0           2  \n",
       "...         ...     ...         ...  \n",
       "21693       0.0     1.0           0  \n",
       "21694       1.0     1.0           0  \n",
       "21695       1.0     1.0           0  \n",
       "21696       1.0     1.0           0  \n",
       "21697       1.0     1.0           0  \n",
       "\n",
       "[21698 rows x 11 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert X values to numerical \n",
    "\n",
    "###                KEY                  ### \n",
    "###        Male = 0, Female = 1         ###\n",
    "###        True = 1, False = 0          ###\n",
    "###  Citizen and Route = see label map  ###\n",
    "\n",
    "X.replace(True, 1, inplace=True)\n",
    "X['sex'] = pd.get_dummies(X['sex'])\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "# Perform label transformation and create label maps for later use \n",
    "X['citizen'] = le.fit_transform(X['citizen'])\n",
    "country_label_map = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "X['new_route'] = le.fit_transform(X['new_route'])\n",
    "route_label_map = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "X['new_status'] = le.fit_transform(X['new_route'])\n",
    "status_label_map = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_names = df['death'].unique()\n",
    "target_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y  = df['death']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Train Test Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "Scale the data using the MinMaxScaler and perform some feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create the scaler\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "\n",
    "# Transform the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the y values to numerical using label_encoder/to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)\n",
    "y_test_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and initial trial model and add layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "inputs = X_train.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=60, activation='relu', input_dim=inputs))\n",
    "model.add(Dense(units=200, activation='relu'))\n",
    "model.add(Dense(units=2, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 60)                720       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200)               12200     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 402       \n",
      "=================================================================\n",
      "Total params: 13,322\n",
      "Trainable params: 13,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "509/509 - 1s - loss: 0.0883 - accuracy: 0.9846\n",
      "Epoch 2/100\n",
      "509/509 - 0s - loss: 0.0712 - accuracy: 0.9862\n",
      "Epoch 3/100\n",
      "509/509 - 0s - loss: 0.0706 - accuracy: 0.9862\n",
      "Epoch 4/100\n",
      "509/509 - 0s - loss: 0.0697 - accuracy: 0.9862\n",
      "Epoch 5/100\n",
      "509/509 - 0s - loss: 0.0698 - accuracy: 0.9862\n",
      "Epoch 6/100\n",
      "509/509 - 0s - loss: 0.0695 - accuracy: 0.9862\n",
      "Epoch 7/100\n",
      "509/509 - 0s - loss: 0.0687 - accuracy: 0.9862\n",
      "Epoch 8/100\n",
      "509/509 - 0s - loss: 0.0693 - accuracy: 0.9862\n",
      "Epoch 9/100\n",
      "509/509 - 0s - loss: 0.0689 - accuracy: 0.9862\n",
      "Epoch 10/100\n",
      "509/509 - 0s - loss: 0.0682 - accuracy: 0.9862\n",
      "Epoch 11/100\n",
      "509/509 - 0s - loss: 0.0684 - accuracy: 0.9862\n",
      "Epoch 12/100\n",
      "509/509 - 0s - loss: 0.0683 - accuracy: 0.9862\n",
      "Epoch 13/100\n",
      "509/509 - 0s - loss: 0.0676 - accuracy: 0.9862\n",
      "Epoch 14/100\n",
      "509/509 - 0s - loss: 0.0676 - accuracy: 0.9862\n",
      "Epoch 15/100\n",
      "509/509 - 0s - loss: 0.0680 - accuracy: 0.9862\n",
      "Epoch 16/100\n",
      "509/509 - 0s - loss: 0.0675 - accuracy: 0.9862\n",
      "Epoch 17/100\n",
      "509/509 - 0s - loss: 0.0673 - accuracy: 0.9862\n",
      "Epoch 18/100\n",
      "509/509 - 0s - loss: 0.0672 - accuracy: 0.9862\n",
      "Epoch 19/100\n",
      "509/509 - 0s - loss: 0.0669 - accuracy: 0.9862\n",
      "Epoch 20/100\n",
      "509/509 - 0s - loss: 0.0672 - accuracy: 0.9862\n",
      "Epoch 21/100\n",
      "509/509 - 0s - loss: 0.0668 - accuracy: 0.9862\n",
      "Epoch 22/100\n",
      "509/509 - 0s - loss: 0.0668 - accuracy: 0.9862\n",
      "Epoch 23/100\n",
      "509/509 - 0s - loss: 0.0666 - accuracy: 0.9862\n",
      "Epoch 24/100\n",
      "509/509 - 0s - loss: 0.0666 - accuracy: 0.9862\n",
      "Epoch 25/100\n",
      "509/509 - 0s - loss: 0.0664 - accuracy: 0.9862\n",
      "Epoch 26/100\n",
      "509/509 - 0s - loss: 0.0664 - accuracy: 0.9864\n",
      "Epoch 27/100\n",
      "509/509 - 0s - loss: 0.0663 - accuracy: 0.9862\n",
      "Epoch 28/100\n",
      "509/509 - 0s - loss: 0.0662 - accuracy: 0.9862\n",
      "Epoch 29/100\n",
      "509/509 - 0s - loss: 0.0661 - accuracy: 0.9862\n",
      "Epoch 30/100\n",
      "509/509 - 0s - loss: 0.0659 - accuracy: 0.9862\n",
      "Epoch 31/100\n",
      "509/509 - 0s - loss: 0.0659 - accuracy: 0.9863\n",
      "Epoch 32/100\n",
      "509/509 - 0s - loss: 0.0656 - accuracy: 0.9862\n",
      "Epoch 33/100\n",
      "509/509 - 0s - loss: 0.0659 - accuracy: 0.9864\n",
      "Epoch 34/100\n",
      "509/509 - 0s - loss: 0.0658 - accuracy: 0.9863\n",
      "Epoch 35/100\n",
      "509/509 - 0s - loss: 0.0659 - accuracy: 0.9862\n",
      "Epoch 36/100\n",
      "509/509 - 0s - loss: 0.0655 - accuracy: 0.9863\n",
      "Epoch 37/100\n",
      "509/509 - 0s - loss: 0.0655 - accuracy: 0.9863\n",
      "Epoch 38/100\n",
      "509/509 - 0s - loss: 0.0654 - accuracy: 0.9862\n",
      "Epoch 39/100\n",
      "509/509 - 0s - loss: 0.0652 - accuracy: 0.9862\n",
      "Epoch 40/100\n",
      "509/509 - 0s - loss: 0.0652 - accuracy: 0.9863\n",
      "Epoch 41/100\n",
      "509/509 - 0s - loss: 0.0651 - accuracy: 0.9862\n",
      "Epoch 42/100\n",
      "509/509 - 0s - loss: 0.0652 - accuracy: 0.9863\n",
      "Epoch 43/100\n",
      "509/509 - 0s - loss: 0.0655 - accuracy: 0.9862\n",
      "Epoch 44/100\n",
      "509/509 - 0s - loss: 0.0649 - accuracy: 0.9862\n",
      "Epoch 45/100\n",
      "509/509 - 0s - loss: 0.0651 - accuracy: 0.9862\n",
      "Epoch 46/100\n",
      "509/509 - 0s - loss: 0.0648 - accuracy: 0.9862\n",
      "Epoch 47/100\n",
      "509/509 - 0s - loss: 0.0650 - accuracy: 0.9862\n",
      "Epoch 48/100\n",
      "509/509 - 0s - loss: 0.0647 - accuracy: 0.9864\n",
      "Epoch 49/100\n",
      "509/509 - 0s - loss: 0.0651 - accuracy: 0.9862\n",
      "Epoch 50/100\n",
      "509/509 - 0s - loss: 0.0647 - accuracy: 0.9864\n",
      "Epoch 51/100\n",
      "509/509 - 0s - loss: 0.0650 - accuracy: 0.9862\n",
      "Epoch 52/100\n",
      "509/509 - 0s - loss: 0.0644 - accuracy: 0.9863\n",
      "Epoch 53/100\n",
      "509/509 - 0s - loss: 0.0646 - accuracy: 0.9863\n",
      "Epoch 54/100\n",
      "509/509 - 0s - loss: 0.0643 - accuracy: 0.9864\n",
      "Epoch 55/100\n",
      "509/509 - 0s - loss: 0.0646 - accuracy: 0.9862\n",
      "Epoch 56/100\n",
      "509/509 - 0s - loss: 0.0642 - accuracy: 0.9863\n",
      "Epoch 57/100\n",
      "509/509 - 0s - loss: 0.0641 - accuracy: 0.9863\n",
      "Epoch 58/100\n",
      "509/509 - 0s - loss: 0.0643 - accuracy: 0.9863\n",
      "Epoch 59/100\n",
      "509/509 - 0s - loss: 0.0642 - accuracy: 0.9864\n",
      "Epoch 60/100\n",
      "509/509 - 0s - loss: 0.0643 - accuracy: 0.9862\n",
      "Epoch 61/100\n",
      "509/509 - 0s - loss: 0.0643 - accuracy: 0.9862\n",
      "Epoch 62/100\n",
      "509/509 - 0s - loss: 0.0639 - accuracy: 0.9862\n",
      "Epoch 63/100\n",
      "509/509 - 0s - loss: 0.0639 - accuracy: 0.9863\n",
      "Epoch 64/100\n",
      "509/509 - 0s - loss: 0.0642 - accuracy: 0.9864\n",
      "Epoch 65/100\n",
      "509/509 - 0s - loss: 0.0635 - accuracy: 0.9863\n",
      "Epoch 66/100\n",
      "509/509 - 0s - loss: 0.0639 - accuracy: 0.9863\n",
      "Epoch 67/100\n",
      "509/509 - 0s - loss: 0.0637 - accuracy: 0.9863\n",
      "Epoch 68/100\n",
      "509/509 - 0s - loss: 0.0640 - accuracy: 0.9864\n",
      "Epoch 69/100\n",
      "509/509 - 0s - loss: 0.0638 - accuracy: 0.9863\n",
      "Epoch 70/100\n",
      "509/509 - 0s - loss: 0.0636 - accuracy: 0.9864\n",
      "Epoch 71/100\n",
      "509/509 - 0s - loss: 0.0637 - accuracy: 0.9863\n",
      "Epoch 72/100\n",
      "509/509 - 0s - loss: 0.0634 - accuracy: 0.9864\n",
      "Epoch 73/100\n",
      "509/509 - 0s - loss: 0.0634 - accuracy: 0.9863\n",
      "Epoch 74/100\n",
      "509/509 - 0s - loss: 0.0639 - accuracy: 0.9862\n",
      "Epoch 75/100\n",
      "509/509 - 0s - loss: 0.0634 - accuracy: 0.9863\n",
      "Epoch 76/100\n",
      "509/509 - 0s - loss: 0.0634 - accuracy: 0.9863\n",
      "Epoch 77/100\n",
      "509/509 - 0s - loss: 0.0635 - accuracy: 0.9864\n",
      "Epoch 78/100\n",
      "509/509 - 0s - loss: 0.0637 - accuracy: 0.9864\n",
      "Epoch 79/100\n",
      "509/509 - 0s - loss: 0.0635 - accuracy: 0.9862\n",
      "Epoch 80/100\n",
      "509/509 - 0s - loss: 0.0630 - accuracy: 0.9863\n",
      "Epoch 81/100\n",
      "509/509 - 0s - loss: 0.0632 - accuracy: 0.9863\n",
      "Epoch 82/100\n",
      "509/509 - 0s - loss: 0.0635 - accuracy: 0.9863\n",
      "Epoch 83/100\n",
      "509/509 - 0s - loss: 0.0628 - accuracy: 0.9863\n",
      "Epoch 84/100\n",
      "509/509 - 0s - loss: 0.0630 - accuracy: 0.9863\n",
      "Epoch 85/100\n",
      "509/509 - 0s - loss: 0.0630 - accuracy: 0.9863\n",
      "Epoch 86/100\n",
      "509/509 - 0s - loss: 0.0631 - accuracy: 0.9863\n",
      "Epoch 87/100\n",
      "509/509 - 0s - loss: 0.0632 - accuracy: 0.9863\n",
      "Epoch 88/100\n",
      "509/509 - 0s - loss: 0.0629 - accuracy: 0.9864\n",
      "Epoch 89/100\n",
      "509/509 - 0s - loss: 0.0628 - accuracy: 0.9862\n",
      "Epoch 90/100\n",
      "509/509 - 0s - loss: 0.0625 - accuracy: 0.9864\n",
      "Epoch 91/100\n",
      "509/509 - 0s - loss: 0.0626 - accuracy: 0.9862\n",
      "Epoch 92/100\n",
      "509/509 - 0s - loss: 0.0626 - accuracy: 0.9864\n",
      "Epoch 93/100\n",
      "509/509 - 0s - loss: 0.0625 - accuracy: 0.9862\n",
      "Epoch 94/100\n",
      "509/509 - 0s - loss: 0.0624 - accuracy: 0.9863\n",
      "Epoch 95/100\n",
      "509/509 - 0s - loss: 0.0626 - accuracy: 0.9862\n",
      "Epoch 96/100\n",
      "509/509 - 0s - loss: 0.0625 - accuracy: 0.9864\n",
      "Epoch 97/100\n",
      "509/509 - 0s - loss: 0.0623 - accuracy: 0.9864\n",
      "Epoch 98/100\n",
      "509/509 - 0s - loss: 0.0623 - accuracy: 0.9864\n",
      "Epoch 99/100\n",
      "509/509 - 0s - loss: 0.0624 - accuracy: 0.9862\n",
      "Epoch 100/100\n",
      "509/509 - 0s - loss: 0.0621 - accuracy: 0.9864\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1638f80b940>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    verbose=2,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantify Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 - 0s - loss: 0.0846 - accuracy: 0.9845\n",
      "Neural Network Performace - Loss: 0.08456841111183167, Accuracy: 0.9845161437988281\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(f\"Neural Network Performace - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Risk of Death for data point 50 is 0.46%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = X_train_scaled[50].tolist()\n",
    "result = model.predict([x])\n",
    "print(f\"Risk of death for data point 50 is {round(result[0][1]*100,2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 540x540 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a confusion matrix to visualise the performance \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "predictions = np.argmax(model.predict(X_test_scaled), axis=-1)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true=encoded_y_test, y_pred=predictions)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
    "\n",
    "ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)\n",
    "\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        ax.text(x=j, y=i, s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
    "\n",
    "plt.title('Confusion Matrix', fontsize=18)\n",
    "plt.xlabel('Predictions', fontsize=18)\n",
    "ax.set_xticks([0,1])\n",
    "ax.set_xticklabels(target_names)\n",
    "plt.ylabel('Actuals', fontsize=18)\n",
    "ax.set_yticks([0,1])\n",
    "ax.set_yticklabels(target_names)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperperameter tuning\n",
    "\n",
    "#### Talos Custom Hyperparameter Optimiser for Keras, Tensorflow used \n",
    "Availble from: <a href=\"https://github.com/autonomio/talos/\">https://github.com/autonomio/talos/</a>\n",
    "<img src=\"https://raw.githubusercontent.com/autonomio/talos/master/logo.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import talos\n",
    "\n",
    "# Function to run the model \n",
    "def everest(x_train, y_train, x_val, y_val, params):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(params['first_neuron'], input_dim=x_train.shape[1], \n",
    "              activation=params['activation']))\n",
    " \n",
    "    model.add(Dropout(params['dropout']))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=params['optimizer'], metrics=['accuracy'])\n",
    "    \n",
    "    out = model.fit(x_train, \n",
    "                    y_train,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    epochs=params['epochs'],\n",
    "                    batch_size=params['batch_size'],\n",
    "                    verbose=0)\n",
    "    \n",
    "    return out, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a parameter dictionary\n",
    "p = {'first_neuron':[30,60,120,240],\n",
    "    'hidden_layers':[1, 2],\n",
    "    'batch_size': [10,20, 30],\n",
    "    'epochs': [100, 150, 200],\n",
    "    'dropout': [0],\n",
    "    'optimizer': ['Nadam', 'Adam'],\n",
    "    'losses': ['binary_crossentropy'],\n",
    "    'activation':['relu'],\n",
    "    'last_activation': ['sigmoid']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [36:34<00:00, 73.13s/it]\n"
     ]
    }
   ],
   "source": [
    "t = talos.Scan(x=X_train_scaled, y=encoded_y_train, params=p, model=everest, experiment_name='everest_tune', round_limit=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "experiment_name            everest_tune\n",
       "random_method          uniform_mersenne\n",
       "reduction_method                   None\n",
       "reduction_interval                   50\n",
       "reduction_window                     20\n",
       "reduction_threshold                 0.2\n",
       "reduction_metric                val_acc\n",
       "complete_time            08/21/21/22:00\n",
       "x_shape                     (16273, 11)\n",
       "y_shape                        (16273,)\n",
       "dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best parameters:  \n",
    "  \n",
    "There are a a number of models which reach an accuracy of 98.6891% with validation data set\n",
    "\n",
    "Note that the underlying rate death rate in data is only 1.4% so it is relatively 'easy' to achieve high accuarcy with this model\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>duration</th>\n",
       "      <th>round_epochs</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>activation</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>dropout</th>\n",
       "      <th>epochs</th>\n",
       "      <th>first_neuron</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>last_activation</th>\n",
       "      <th>losses</th>\n",
       "      <th>optimizer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>08/21/21-212328</td>\n",
       "      <td>08/21/21-212558</td>\n",
       "      <td>149.762037</td>\n",
       "      <td>200</td>\n",
       "      <td>0.064495</td>\n",
       "      <td>0.985954</td>\n",
       "      <td>0.072630</td>\n",
       "      <td>0.986891</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>08/21/21-212558</td>\n",
       "      <td>08/21/21-212828</td>\n",
       "      <td>150.694211</td>\n",
       "      <td>200</td>\n",
       "      <td>0.063179</td>\n",
       "      <td>0.985954</td>\n",
       "      <td>0.074439</td>\n",
       "      <td>0.986686</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>08/21/21-212828</td>\n",
       "      <td>08/21/21-212920</td>\n",
       "      <td>51.654507</td>\n",
       "      <td>200</td>\n",
       "      <td>0.064569</td>\n",
       "      <td>0.985866</td>\n",
       "      <td>0.070142</td>\n",
       "      <td>0.986891</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>08/21/21-212920</td>\n",
       "      <td>08/21/21-213012</td>\n",
       "      <td>51.759493</td>\n",
       "      <td>200</td>\n",
       "      <td>0.064598</td>\n",
       "      <td>0.985954</td>\n",
       "      <td>0.070358</td>\n",
       "      <td>0.986891</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08/21/21-213012</td>\n",
       "      <td>08/21/21-213106</td>\n",
       "      <td>53.471271</td>\n",
       "      <td>200</td>\n",
       "      <td>0.062064</td>\n",
       "      <td>0.986042</td>\n",
       "      <td>0.078532</td>\n",
       "      <td>0.986686</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>240</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>08/21/21-213106</td>\n",
       "      <td>08/21/21-213203</td>\n",
       "      <td>57.626611</td>\n",
       "      <td>150</td>\n",
       "      <td>0.066152</td>\n",
       "      <td>0.985954</td>\n",
       "      <td>0.070243</td>\n",
       "      <td>0.986891</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>08/21/21-213203</td>\n",
       "      <td>08/21/21-213301</td>\n",
       "      <td>57.888064</td>\n",
       "      <td>150</td>\n",
       "      <td>0.063041</td>\n",
       "      <td>0.985954</td>\n",
       "      <td>0.077180</td>\n",
       "      <td>0.986891</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>240</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>08/21/21-213301</td>\n",
       "      <td>08/21/21-213418</td>\n",
       "      <td>76.144345</td>\n",
       "      <td>200</td>\n",
       "      <td>0.063290</td>\n",
       "      <td>0.985954</td>\n",
       "      <td>0.074552</td>\n",
       "      <td>0.986891</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>08/21/21-213418</td>\n",
       "      <td>08/21/21-213458</td>\n",
       "      <td>39.961998</td>\n",
       "      <td>100</td>\n",
       "      <td>0.064512</td>\n",
       "      <td>0.985954</td>\n",
       "      <td>0.071143</td>\n",
       "      <td>0.986891</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>120</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>08/21/21-213458</td>\n",
       "      <td>08/21/21-213552</td>\n",
       "      <td>54.009892</td>\n",
       "      <td>200</td>\n",
       "      <td>0.062025</td>\n",
       "      <td>0.985954</td>\n",
       "      <td>0.077404</td>\n",
       "      <td>0.986891</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>240</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>08/21/21-213552</td>\n",
       "      <td>08/21/21-213819</td>\n",
       "      <td>147.606582</td>\n",
       "      <td>200</td>\n",
       "      <td>0.064847</td>\n",
       "      <td>0.985954</td>\n",
       "      <td>0.072838</td>\n",
       "      <td>0.986891</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>08/21/21-213820</td>\n",
       "      <td>08/21/21-213859</td>\n",
       "      <td>39.178575</td>\n",
       "      <td>150</td>\n",
       "      <td>0.065559</td>\n",
       "      <td>0.985954</td>\n",
       "      <td>0.070609</td>\n",
       "      <td>0.986891</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>08/21/21-213859</td>\n",
       "      <td>08/21/21-214012</td>\n",
       "      <td>73.569802</td>\n",
       "      <td>100</td>\n",
       "      <td>0.063719</td>\n",
       "      <td>0.986042</td>\n",
       "      <td>0.074224</td>\n",
       "      <td>0.986686</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>240</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>08/21/21-214013</td>\n",
       "      <td>08/21/21-214203</td>\n",
       "      <td>110.664324</td>\n",
       "      <td>150</td>\n",
       "      <td>0.064562</td>\n",
       "      <td>0.985954</td>\n",
       "      <td>0.072313</td>\n",
       "      <td>0.986891</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>08/21/21-214203</td>\n",
       "      <td>08/21/21-214354</td>\n",
       "      <td>110.517935</td>\n",
       "      <td>150</td>\n",
       "      <td>0.062903</td>\n",
       "      <td>0.986042</td>\n",
       "      <td>0.075712</td>\n",
       "      <td>0.986891</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>240</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>08/21/21-214354</td>\n",
       "      <td>08/21/21-214543</td>\n",
       "      <td>109.419582</td>\n",
       "      <td>150</td>\n",
       "      <td>0.064286</td>\n",
       "      <td>0.986042</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.986891</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>08/21/21-214543</td>\n",
       "      <td>08/21/21-214640</td>\n",
       "      <td>56.269202</td>\n",
       "      <td>150</td>\n",
       "      <td>0.062532</td>\n",
       "      <td>0.985954</td>\n",
       "      <td>0.077573</td>\n",
       "      <td>0.986686</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>240</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>08/21/21-214640</td>\n",
       "      <td>08/21/21-214706</td>\n",
       "      <td>25.822515</td>\n",
       "      <td>100</td>\n",
       "      <td>0.065356</td>\n",
       "      <td>0.985954</td>\n",
       "      <td>0.070490</td>\n",
       "      <td>0.986891</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>08/21/21-214706</td>\n",
       "      <td>08/21/21-214822</td>\n",
       "      <td>76.497566</td>\n",
       "      <td>200</td>\n",
       "      <td>0.064146</td>\n",
       "      <td>0.985954</td>\n",
       "      <td>0.071833</td>\n",
       "      <td>0.986891</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>08/21/21-214822</td>\n",
       "      <td>08/21/21-214936</td>\n",
       "      <td>74.050482</td>\n",
       "      <td>100</td>\n",
       "      <td>0.064742</td>\n",
       "      <td>0.985954</td>\n",
       "      <td>0.070705</td>\n",
       "      <td>0.986891</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>08/21/21-214937</td>\n",
       "      <td>08/21/21-215014</td>\n",
       "      <td>37.576681</td>\n",
       "      <td>100</td>\n",
       "      <td>0.065269</td>\n",
       "      <td>0.985954</td>\n",
       "      <td>0.070469</td>\n",
       "      <td>0.986891</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>08/21/21-215014</td>\n",
       "      <td>08/21/21-215240</td>\n",
       "      <td>145.909184</td>\n",
       "      <td>200</td>\n",
       "      <td>0.061954</td>\n",
       "      <td>0.986042</td>\n",
       "      <td>0.079669</td>\n",
       "      <td>0.986686</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>08/21/21-215240</td>\n",
       "      <td>08/21/21-215353</td>\n",
       "      <td>72.929633</td>\n",
       "      <td>100</td>\n",
       "      <td>0.065917</td>\n",
       "      <td>0.985954</td>\n",
       "      <td>0.070123</td>\n",
       "      <td>0.986891</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>08/21/21-215353</td>\n",
       "      <td>08/21/21-215431</td>\n",
       "      <td>37.330918</td>\n",
       "      <td>100</td>\n",
       "      <td>0.064859</td>\n",
       "      <td>0.985954</td>\n",
       "      <td>0.070733</td>\n",
       "      <td>0.986891</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>08/21/21-215431</td>\n",
       "      <td>08/21/21-215457</td>\n",
       "      <td>26.224350</td>\n",
       "      <td>100</td>\n",
       "      <td>0.064068</td>\n",
       "      <td>0.985866</td>\n",
       "      <td>0.073629</td>\n",
       "      <td>0.986891</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>240</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>08/21/21-215457</td>\n",
       "      <td>08/21/21-215523</td>\n",
       "      <td>25.733911</td>\n",
       "      <td>100</td>\n",
       "      <td>0.065379</td>\n",
       "      <td>0.985954</td>\n",
       "      <td>0.070685</td>\n",
       "      <td>0.986891</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>08/21/21-215523</td>\n",
       "      <td>08/21/21-215713</td>\n",
       "      <td>109.818448</td>\n",
       "      <td>150</td>\n",
       "      <td>0.062674</td>\n",
       "      <td>0.986042</td>\n",
       "      <td>0.076757</td>\n",
       "      <td>0.986891</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>240</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>08/21/21-215713</td>\n",
       "      <td>08/21/21-215751</td>\n",
       "      <td>38.282367</td>\n",
       "      <td>100</td>\n",
       "      <td>0.063869</td>\n",
       "      <td>0.986042</td>\n",
       "      <td>0.073153</td>\n",
       "      <td>0.986891</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>240</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>08/21/21-215751</td>\n",
       "      <td>08/21/21-215906</td>\n",
       "      <td>74.593418</td>\n",
       "      <td>200</td>\n",
       "      <td>0.062922</td>\n",
       "      <td>0.985954</td>\n",
       "      <td>0.076296</td>\n",
       "      <td>0.986891</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>120</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>08/21/21-215906</td>\n",
       "      <td>08/21/21-220002</td>\n",
       "      <td>55.792063</td>\n",
       "      <td>150</td>\n",
       "      <td>0.064458</td>\n",
       "      <td>0.985866</td>\n",
       "      <td>0.070764</td>\n",
       "      <td>0.986891</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              start              end    duration  round_epochs      loss  \\\n",
       "0   08/21/21-212328  08/21/21-212558  149.762037           200  0.064495   \n",
       "1   08/21/21-212558  08/21/21-212828  150.694211           200  0.063179   \n",
       "2   08/21/21-212828  08/21/21-212920   51.654507           200  0.064569   \n",
       "3   08/21/21-212920  08/21/21-213012   51.759493           200  0.064598   \n",
       "4   08/21/21-213012  08/21/21-213106   53.471271           200  0.062064   \n",
       "5   08/21/21-213106  08/21/21-213203   57.626611           150  0.066152   \n",
       "6   08/21/21-213203  08/21/21-213301   57.888064           150  0.063041   \n",
       "7   08/21/21-213301  08/21/21-213418   76.144345           200  0.063290   \n",
       "8   08/21/21-213418  08/21/21-213458   39.961998           100  0.064512   \n",
       "9   08/21/21-213458  08/21/21-213552   54.009892           200  0.062025   \n",
       "10  08/21/21-213552  08/21/21-213819  147.606582           200  0.064847   \n",
       "11  08/21/21-213820  08/21/21-213859   39.178575           150  0.065559   \n",
       "12  08/21/21-213859  08/21/21-214012   73.569802           100  0.063719   \n",
       "13  08/21/21-214013  08/21/21-214203  110.664324           150  0.064562   \n",
       "14  08/21/21-214203  08/21/21-214354  110.517935           150  0.062903   \n",
       "15  08/21/21-214354  08/21/21-214543  109.419582           150  0.064286   \n",
       "16  08/21/21-214543  08/21/21-214640   56.269202           150  0.062532   \n",
       "17  08/21/21-214640  08/21/21-214706   25.822515           100  0.065356   \n",
       "18  08/21/21-214706  08/21/21-214822   76.497566           200  0.064146   \n",
       "19  08/21/21-214822  08/21/21-214936   74.050482           100  0.064742   \n",
       "20  08/21/21-214937  08/21/21-215014   37.576681           100  0.065269   \n",
       "21  08/21/21-215014  08/21/21-215240  145.909184           200  0.061954   \n",
       "22  08/21/21-215240  08/21/21-215353   72.929633           100  0.065917   \n",
       "23  08/21/21-215353  08/21/21-215431   37.330918           100  0.064859   \n",
       "24  08/21/21-215431  08/21/21-215457   26.224350           100  0.064068   \n",
       "25  08/21/21-215457  08/21/21-215523   25.733911           100  0.065379   \n",
       "26  08/21/21-215523  08/21/21-215713  109.818448           150  0.062674   \n",
       "27  08/21/21-215713  08/21/21-215751   38.282367           100  0.063869   \n",
       "28  08/21/21-215751  08/21/21-215906   74.593418           200  0.062922   \n",
       "29  08/21/21-215906  08/21/21-220002   55.792063           150  0.064458   \n",
       "\n",
       "    accuracy  val_loss  val_accuracy activation  batch_size  dropout  epochs  \\\n",
       "0   0.985954  0.072630      0.986891       relu          10        0     200   \n",
       "1   0.985954  0.074439      0.986686       relu          10        0     200   \n",
       "2   0.985866  0.070142      0.986891       relu          30        0     200   \n",
       "3   0.985954  0.070358      0.986891       relu          30        0     200   \n",
       "4   0.986042  0.078532      0.986686       relu          30        0     200   \n",
       "5   0.985954  0.070243      0.986891       relu          20        0     150   \n",
       "6   0.985954  0.077180      0.986891       relu          20        0     150   \n",
       "7   0.985954  0.074552      0.986891       relu          20        0     200   \n",
       "8   0.985954  0.071143      0.986891       relu          20        0     100   \n",
       "9   0.985954  0.077404      0.986891       relu          30        0     200   \n",
       "10  0.985954  0.072838      0.986891       relu          10        0     200   \n",
       "11  0.985954  0.070609      0.986891       relu          30        0     150   \n",
       "12  0.986042  0.074224      0.986686       relu          10        0     100   \n",
       "13  0.985954  0.072313      0.986891       relu          10        0     150   \n",
       "14  0.986042  0.075712      0.986891       relu          10        0     150   \n",
       "15  0.986042  0.071429      0.986891       relu          10        0     150   \n",
       "16  0.985954  0.077573      0.986686       relu          20        0     150   \n",
       "17  0.985954  0.070490      0.986891       relu          30        0     100   \n",
       "18  0.985954  0.071833      0.986891       relu          20        0     200   \n",
       "19  0.985954  0.070705      0.986891       relu          10        0     100   \n",
       "20  0.985954  0.070469      0.986891       relu          20        0     100   \n",
       "21  0.986042  0.079669      0.986686       relu          10        0     200   \n",
       "22  0.985954  0.070123      0.986891       relu          10        0     100   \n",
       "23  0.985954  0.070733      0.986891       relu          20        0     100   \n",
       "24  0.985866  0.073629      0.986891       relu          30        0     100   \n",
       "25  0.985954  0.070685      0.986891       relu          30        0     100   \n",
       "26  0.986042  0.076757      0.986891       relu          10        0     150   \n",
       "27  0.986042  0.073153      0.986891       relu          20        0     100   \n",
       "28  0.985954  0.076296      0.986891       relu          20        0     200   \n",
       "29  0.985866  0.070764      0.986891       relu          20        0     150   \n",
       "\n",
       "    first_neuron  hidden_layers last_activation               losses optimizer  \n",
       "0             30              1         sigmoid  binary_crossentropy     Nadam  \n",
       "1             60              2         sigmoid  binary_crossentropy      Adam  \n",
       "2             30              1         sigmoid  binary_crossentropy     Nadam  \n",
       "3             60              1         sigmoid  binary_crossentropy     Nadam  \n",
       "4            240              2         sigmoid  binary_crossentropy      Adam  \n",
       "5             30              2         sigmoid  binary_crossentropy     Nadam  \n",
       "6            240              2         sigmoid  binary_crossentropy      Adam  \n",
       "7             60              2         sigmoid  binary_crossentropy     Nadam  \n",
       "8            120              2         sigmoid  binary_crossentropy     Nadam  \n",
       "9            240              1         sigmoid  binary_crossentropy     Nadam  \n",
       "10            30              1         sigmoid  binary_crossentropy      Adam  \n",
       "11            30              2         sigmoid  binary_crossentropy     Nadam  \n",
       "12           240              1         sigmoid  binary_crossentropy      Adam  \n",
       "13            30              2         sigmoid  binary_crossentropy     Nadam  \n",
       "14           240              2         sigmoid  binary_crossentropy     Nadam  \n",
       "15            60              2         sigmoid  binary_crossentropy     Nadam  \n",
       "16           240              2         sigmoid  binary_crossentropy     Nadam  \n",
       "17            60              2         sigmoid  binary_crossentropy      Adam  \n",
       "18            30              2         sigmoid  binary_crossentropy      Adam  \n",
       "19            60              2         sigmoid  binary_crossentropy     Nadam  \n",
       "20            60              1         sigmoid  binary_crossentropy      Adam  \n",
       "21           120              1         sigmoid  binary_crossentropy     Nadam  \n",
       "22            30              1         sigmoid  binary_crossentropy     Nadam  \n",
       "23            60              2         sigmoid  binary_crossentropy      Adam  \n",
       "24           240              2         sigmoid  binary_crossentropy     Nadam  \n",
       "25            60              1         sigmoid  binary_crossentropy      Adam  \n",
       "26           240              1         sigmoid  binary_crossentropy      Adam  \n",
       "27           240              2         sigmoid  binary_crossentropy      Adam  \n",
       "28           120              2         sigmoid  binary_crossentropy      Adam  \n",
       "29            60              1         sigmoid  binary_crossentropy      Adam  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display a dataframe comapring the results of the different combinations \n",
    "t.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the model with the optimised paramaters \n",
    "\n",
    "p_optimisied = {'first_neuron':60,\n",
    "                'second_neuron':120,\n",
    "                'hidden_layers':2,\n",
    "                'batch_size': 30,\n",
    "                'epochs': 200,\n",
    "                'dropout': 0,\n",
    "                'optimizer': 'adam',\n",
    "                'activation':'relu',\n",
    "               }\n",
    "\n",
    "def everest_optimised(x_train, y_train, params):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(params['first_neuron'], input_dim=x_train.shape[1], \n",
    "              activation=params['activation']))\n",
    "    \n",
    "    model.add(Dense(params['second_neuron'], activation=params['activation']))\n",
    " \n",
    "    model.add(Dropout(params['dropout']))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=params['optimizer'], metrics=['accuracy'])\n",
    "    \n",
    "    out = model.fit(x_train, \n",
    "                    y_train,\n",
    "                    epochs=params['epochs'],\n",
    "                    batch_size=params['batch_size'],\n",
    "                    verbose=0)\n",
    "\n",
    "    return out, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-fit the training data to the model\n",
    "out, model = everest_optimised(X_train_scaled, encoded_y_train, p_optimisied)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 - 0s - loss: 0.1127 - accuracy: 0.9845\n",
      "Neural Network Performace - Loss: 0.11270985007286072, Accuracy: 0.9845161437988281\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(X_test_scaled, encoded_y_test, verbose=2)\n",
    "print(f\"Neural Network Performace - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 540x540 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a confusion matrix to visualise the performance of the adjusted model\n",
    "predictions = np.argmax(model.predict(X_test_scaled), axis=-1)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true=encoded_y_test, y_pred=predictions)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
    "\n",
    "ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)\n",
    "\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        ax.text(x=j, y=i, s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
    "\n",
    "plt.title('Confusion Matrix', fontsize=18)\n",
    "plt.xlabel('Predictions', fontsize=18)\n",
    "ax.set_xticks([0,1])\n",
    "ax.set_xticklabels(target_names)\n",
    "plt.ylabel('Actuals', fontsize=18)\n",
    "ax.set_yticks([0,1])\n",
    "ax.set_yticklabels(target_names)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "filename = 'death_model.h5'\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(\"Model 2 - Deep_learning.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "dev"
  },
  "kernelspec": {
   "display_name": "Python [conda env:PythonData] *",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
