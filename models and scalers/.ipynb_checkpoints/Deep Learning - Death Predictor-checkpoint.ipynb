{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "df = pd.read_csv(\"../clean_data.csv\", low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'expid', 'membid', 'myear', 'sex', 'calcage', 'citizen', 'status',\n",
       "       'msolo', 'msuccess', 'msmtdate1', 'msmtdate2', 'msmtdate3', 'route1',\n",
       "       'route2', 'route3', 'route4', 'mo2used', 'mo2none', 'mo2climb',\n",
       "       'mo2descent', 'mo2sleep', 'death', 'deathdate', 'msmtbid', 'stdrte',\n",
       "       'new_route', 'new_status', 'climber_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View column names and drop unnecesary columns for the model \n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set features\n",
    "feature_names = ['sex', 'calcage', 'citizen', 'new_route', 'mo2used', 'mo2climb',\n",
    "                 'mo2descent', 'mo2sleep', 'stdrte', 'new_status']\n",
    "\n",
    "X = df[feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>calcage</th>\n",
       "      <th>citizen</th>\n",
       "      <th>new_route</th>\n",
       "      <th>mo2used</th>\n",
       "      <th>mo2climb</th>\n",
       "      <th>mo2descent</th>\n",
       "      <th>mo2sleep</th>\n",
       "      <th>stdrte</th>\n",
       "      <th>new_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>89</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>85</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>85</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21693</th>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21694</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21695</th>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21696</th>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21697</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21698 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sex  calcage  citizen  new_route  mo2used  mo2climb  mo2descent  \\\n",
       "0        0       49       15          2      0.0       0.0         0.0   \n",
       "1        1       30       89          2      0.0       0.0         0.0   \n",
       "2        0       32       15          2      1.0       1.0         0.0   \n",
       "3        0       40       85          2      0.0       0.0         0.0   \n",
       "4        0       29       85          2      1.0       1.0         0.0   \n",
       "...    ...      ...      ...        ...      ...       ...         ...   \n",
       "21693    0       47       28          0      1.0       1.0         0.0   \n",
       "21694    0       37       28          0      1.0       1.0         0.0   \n",
       "21695    0       57       28          0      1.0       1.0         0.0   \n",
       "21696    0       35       28          0      1.0       1.0         0.0   \n",
       "21697    0       37       28          0      1.0       1.0         0.0   \n",
       "\n",
       "       mo2sleep  stdrte  new_status  \n",
       "0           0.0     1.0           2  \n",
       "1           0.0     1.0           2  \n",
       "2           1.0     1.0           2  \n",
       "3           0.0     1.0           2  \n",
       "4           1.0     1.0           2  \n",
       "...         ...     ...         ...  \n",
       "21693       0.0     1.0           0  \n",
       "21694       1.0     1.0           0  \n",
       "21695       1.0     1.0           0  \n",
       "21696       1.0     1.0           0  \n",
       "21697       1.0     1.0           0  \n",
       "\n",
       "[21698 rows x 10 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert X values to numerical \n",
    "\n",
    "###                KEY                  ### \n",
    "###        Male = 0, Female = 1         ###\n",
    "###        True = 1, False = 0          ###\n",
    "###  Citizen and Route = see label map  ###\n",
    "\n",
    "X.replace(True, 1, inplace=True)\n",
    "X['sex'] = pd.get_dummies(X['sex'])\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "# Perform label transformation and create label maps for later use \n",
    "X['citizen'] = le.fit_transform(X['citizen'])\n",
    "country_label_map = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "X['new_route'] = le.fit_transform(X['new_route'])\n",
    "route_label_map = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "X['new_status'] = le.fit_transform(X['new_route'])\n",
    "status_label_map = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_names = df['death'].unique()\n",
    "target_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y  = df['death']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Train Test Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "Scale the data using the MinMaxScaler and perform some feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create the scaler\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "\n",
    "# Transform the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the y values to numerical using label_encoder/to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)\n",
    "y_test_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and initial trial model and add layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "inputs = X_train.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=60, activation='relu', input_dim=inputs))\n",
    "model.add(Dense(units=200, activation='relu'))\n",
    "model.add(Dense(units=2, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 60)                720       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200)               12200     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 402       \n",
      "=================================================================\n",
      "Total params: 13,322\n",
      "Trainable params: 13,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "509/509 - 1s - loss: 0.0863 - accuracy: 0.9857\n",
      "Epoch 2/100\n",
      "509/509 - 0s - loss: 0.0703 - accuracy: 0.9862\n",
      "Epoch 3/100\n",
      "509/509 - 0s - loss: 0.0700 - accuracy: 0.9862\n",
      "Epoch 4/100\n",
      "509/509 - 0s - loss: 0.0696 - accuracy: 0.9862\n",
      "Epoch 5/100\n",
      "509/509 - 0s - loss: 0.0692 - accuracy: 0.9862\n",
      "Epoch 6/100\n",
      "509/509 - 0s - loss: 0.0692 - accuracy: 0.9862\n",
      "Epoch 7/100\n",
      "509/509 - 0s - loss: 0.0690 - accuracy: 0.9862\n",
      "Epoch 8/100\n",
      "509/509 - 0s - loss: 0.0690 - accuracy: 0.9862\n",
      "Epoch 9/100\n",
      "509/509 - 0s - loss: 0.0691 - accuracy: 0.9862\n",
      "Epoch 10/100\n",
      "509/509 - 0s - loss: 0.0682 - accuracy: 0.9862\n",
      "Epoch 11/100\n",
      "509/509 - 0s - loss: 0.0680 - accuracy: 0.9862\n",
      "Epoch 12/100\n",
      "509/509 - 0s - loss: 0.0679 - accuracy: 0.9862\n",
      "Epoch 13/100\n",
      "509/509 - 0s - loss: 0.0676 - accuracy: 0.9862\n",
      "Epoch 14/100\n",
      "509/509 - 0s - loss: 0.0675 - accuracy: 0.9862\n",
      "Epoch 15/100\n",
      "509/509 - 0s - loss: 0.0674 - accuracy: 0.9862\n",
      "Epoch 16/100\n",
      "509/509 - 0s - loss: 0.0675 - accuracy: 0.9862\n",
      "Epoch 17/100\n",
      "509/509 - 0s - loss: 0.0671 - accuracy: 0.9862\n",
      "Epoch 18/100\n",
      "509/509 - 0s - loss: 0.0670 - accuracy: 0.9862\n",
      "Epoch 19/100\n",
      "509/509 - 0s - loss: 0.0674 - accuracy: 0.9862\n",
      "Epoch 20/100\n",
      "509/509 - 0s - loss: 0.0665 - accuracy: 0.9862\n",
      "Epoch 21/100\n",
      "509/509 - 0s - loss: 0.0666 - accuracy: 0.9862\n",
      "Epoch 22/100\n",
      "509/509 - 0s - loss: 0.0666 - accuracy: 0.9862\n",
      "Epoch 23/100\n",
      "509/509 - 0s - loss: 0.0667 - accuracy: 0.9862\n",
      "Epoch 24/100\n",
      "509/509 - 0s - loss: 0.0666 - accuracy: 0.9864\n",
      "Epoch 25/100\n",
      "509/509 - 0s - loss: 0.0665 - accuracy: 0.9863\n",
      "Epoch 26/100\n",
      "509/509 - 0s - loss: 0.0666 - accuracy: 0.9863\n",
      "Epoch 27/100\n",
      "509/509 - 0s - loss: 0.0659 - accuracy: 0.9862\n",
      "Epoch 28/100\n",
      "509/509 - 0s - loss: 0.0664 - accuracy: 0.9862\n",
      "Epoch 29/100\n",
      "509/509 - 0s - loss: 0.0658 - accuracy: 0.9863\n",
      "Epoch 30/100\n",
      "509/509 - 0s - loss: 0.0658 - accuracy: 0.9864\n",
      "Epoch 31/100\n",
      "509/509 - 0s - loss: 0.0660 - accuracy: 0.9864\n",
      "Epoch 32/100\n",
      "509/509 - 0s - loss: 0.0660 - accuracy: 0.9862\n",
      "Epoch 33/100\n",
      "509/509 - 0s - loss: 0.0658 - accuracy: 0.9862\n",
      "Epoch 34/100\n",
      "509/509 - 0s - loss: 0.0655 - accuracy: 0.9863\n",
      "Epoch 35/100\n",
      "509/509 - 0s - loss: 0.0653 - accuracy: 0.9863\n",
      "Epoch 36/100\n",
      "509/509 - 0s - loss: 0.0653 - accuracy: 0.9862\n",
      "Epoch 37/100\n",
      "509/509 - 0s - loss: 0.0660 - accuracy: 0.9863\n",
      "Epoch 38/100\n",
      "509/509 - 0s - loss: 0.0654 - accuracy: 0.9862\n",
      "Epoch 39/100\n",
      "509/509 - 0s - loss: 0.0650 - accuracy: 0.9863\n",
      "Epoch 40/100\n",
      "509/509 - 0s - loss: 0.0651 - accuracy: 0.9864\n",
      "Epoch 41/100\n",
      "509/509 - 0s - loss: 0.0651 - accuracy: 0.9862\n",
      "Epoch 42/100\n",
      "509/509 - 0s - loss: 0.0652 - accuracy: 0.9862\n",
      "Epoch 43/100\n",
      "509/509 - 0s - loss: 0.0648 - accuracy: 0.9863\n",
      "Epoch 44/100\n",
      "509/509 - 0s - loss: 0.0651 - accuracy: 0.9864\n",
      "Epoch 45/100\n",
      "509/509 - 0s - loss: 0.0648 - accuracy: 0.9862\n",
      "Epoch 46/100\n",
      "509/509 - 0s - loss: 0.0646 - accuracy: 0.9864\n",
      "Epoch 47/100\n",
      "509/509 - 0s - loss: 0.0644 - accuracy: 0.9864\n",
      "Epoch 48/100\n",
      "509/509 - 0s - loss: 0.0648 - accuracy: 0.9862\n",
      "Epoch 49/100\n",
      "509/509 - 0s - loss: 0.0644 - accuracy: 0.9864\n",
      "Epoch 50/100\n",
      "509/509 - 0s - loss: 0.0644 - accuracy: 0.9863\n",
      "Epoch 51/100\n",
      "509/509 - 0s - loss: 0.0643 - accuracy: 0.9863\n",
      "Epoch 52/100\n",
      "509/509 - 0s - loss: 0.0641 - accuracy: 0.9864\n",
      "Epoch 53/100\n",
      "509/509 - 0s - loss: 0.0643 - accuracy: 0.9863\n",
      "Epoch 54/100\n",
      "509/509 - 0s - loss: 0.0641 - accuracy: 0.9863\n",
      "Epoch 55/100\n",
      "509/509 - 0s - loss: 0.0641 - accuracy: 0.9864\n",
      "Epoch 56/100\n",
      "509/509 - 0s - loss: 0.0638 - accuracy: 0.9864\n",
      "Epoch 57/100\n",
      "509/509 - 0s - loss: 0.0640 - accuracy: 0.9863\n",
      "Epoch 58/100\n",
      "509/509 - 0s - loss: 0.0641 - accuracy: 0.9864\n",
      "Epoch 59/100\n",
      "509/509 - 0s - loss: 0.0640 - accuracy: 0.9863\n",
      "Epoch 60/100\n",
      "509/509 - 0s - loss: 0.0634 - accuracy: 0.9864\n",
      "Epoch 61/100\n",
      "509/509 - 0s - loss: 0.0634 - accuracy: 0.9863\n",
      "Epoch 62/100\n",
      "509/509 - 0s - loss: 0.0636 - accuracy: 0.9863\n",
      "Epoch 63/100\n",
      "509/509 - 0s - loss: 0.0639 - accuracy: 0.9864\n",
      "Epoch 64/100\n",
      "509/509 - 0s - loss: 0.0634 - accuracy: 0.9864\n",
      "Epoch 65/100\n",
      "509/509 - 0s - loss: 0.0630 - accuracy: 0.9863\n",
      "Epoch 66/100\n",
      "509/509 - 0s - loss: 0.0630 - accuracy: 0.9864\n",
      "Epoch 67/100\n",
      "509/509 - 0s - loss: 0.0636 - accuracy: 0.9863\n",
      "Epoch 68/100\n",
      "509/509 - 0s - loss: 0.0630 - accuracy: 0.9863\n",
      "Epoch 69/100\n",
      "509/509 - 0s - loss: 0.0631 - accuracy: 0.9864\n",
      "Epoch 70/100\n",
      "509/509 - 0s - loss: 0.0631 - accuracy: 0.9864\n",
      "Epoch 71/100\n",
      "509/509 - 0s - loss: 0.0631 - accuracy: 0.9863\n",
      "Epoch 72/100\n",
      "509/509 - 0s - loss: 0.0630 - accuracy: 0.9864\n",
      "Epoch 73/100\n",
      "509/509 - 0s - loss: 0.0630 - accuracy: 0.9864\n",
      "Epoch 74/100\n",
      "509/509 - 0s - loss: 0.0627 - accuracy: 0.9864\n",
      "Epoch 75/100\n",
      "509/509 - 0s - loss: 0.0627 - accuracy: 0.9863\n",
      "Epoch 76/100\n",
      "509/509 - 0s - loss: 0.0626 - accuracy: 0.9864\n",
      "Epoch 77/100\n",
      "509/509 - 0s - loss: 0.0630 - accuracy: 0.9864\n",
      "Epoch 78/100\n",
      "509/509 - 0s - loss: 0.0628 - accuracy: 0.9864\n",
      "Epoch 79/100\n",
      "509/509 - 0s - loss: 0.0623 - accuracy: 0.9863\n",
      "Epoch 80/100\n",
      "509/509 - 0s - loss: 0.0625 - accuracy: 0.9864\n",
      "Epoch 81/100\n",
      "509/509 - 0s - loss: 0.0625 - accuracy: 0.9863\n",
      "Epoch 82/100\n",
      "509/509 - 0s - loss: 0.0622 - accuracy: 0.9864\n",
      "Epoch 83/100\n",
      "509/509 - 0s - loss: 0.0627 - accuracy: 0.9863\n",
      "Epoch 84/100\n",
      "509/509 - 0s - loss: 0.0624 - accuracy: 0.9864\n",
      "Epoch 85/100\n",
      "509/509 - 0s - loss: 0.0622 - accuracy: 0.9863\n",
      "Epoch 86/100\n",
      "509/509 - 0s - loss: 0.0621 - accuracy: 0.9864\n",
      "Epoch 87/100\n",
      "509/509 - 0s - loss: 0.0624 - accuracy: 0.9863\n",
      "Epoch 88/100\n",
      "509/509 - 0s - loss: 0.0620 - accuracy: 0.9864\n",
      "Epoch 89/100\n",
      "509/509 - 0s - loss: 0.0623 - accuracy: 0.9864\n",
      "Epoch 90/100\n",
      "509/509 - 0s - loss: 0.0619 - accuracy: 0.9864\n",
      "Epoch 91/100\n",
      "509/509 - 0s - loss: 0.0620 - accuracy: 0.9864\n",
      "Epoch 92/100\n",
      "509/509 - 0s - loss: 0.0618 - accuracy: 0.9864\n",
      "Epoch 93/100\n",
      "509/509 - 0s - loss: 0.0621 - accuracy: 0.9864\n",
      "Epoch 94/100\n",
      "509/509 - 0s - loss: 0.0620 - accuracy: 0.9864\n",
      "Epoch 95/100\n",
      "509/509 - 0s - loss: 0.0617 - accuracy: 0.9864\n",
      "Epoch 96/100\n",
      "509/509 - 0s - loss: 0.0617 - accuracy: 0.9863\n",
      "Epoch 97/100\n",
      "509/509 - 0s - loss: 0.0616 - accuracy: 0.9864\n",
      "Epoch 98/100\n",
      "509/509 - 0s - loss: 0.0613 - accuracy: 0.9863\n",
      "Epoch 99/100\n",
      "509/509 - 0s - loss: 0.0616 - accuracy: 0.9864\n",
      "Epoch 100/100\n",
      "509/509 - 0s - loss: 0.0616 - accuracy: 0.9864\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1bc93eb9cf8>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    verbose=2,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantify Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 - 0s - loss: 0.0831 - accuracy: 0.9847\n",
      "Neural Network Performace - Loss: 0.08310303092002869, Accuracy: 0.9847004413604736\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(f\"Neural Network Performace - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Risk of death for data point 50 is 0.57%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = X_train_scaled[50].tolist()\n",
    "result = model.predict([x])\n",
    "print(f\"Risk of death for data point 50 is {round(result[0][1]*100,2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 540x540 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a confusion matrix to visualise the performance \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "predictions = np.argmax(model.predict(X_test_scaled), axis=-1)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true=encoded_y_test, y_pred=predictions)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
    "\n",
    "ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)\n",
    "\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        ax.text(x=j, y=i, s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
    "\n",
    "plt.title('Confusion Matrix', fontsize=18)\n",
    "plt.xlabel('Predictions', fontsize=18)\n",
    "ax.set_xticks([0,1])\n",
    "ax.set_xticklabels(target_names)\n",
    "plt.ylabel('Actuals', fontsize=18)\n",
    "ax.set_yticks([0,1])\n",
    "ax.set_yticklabels(target_names)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperperameter tuning\n",
    "\n",
    "#### Talos Custom Hyperparameter Optimiser for Keras, Tensorflow used \n",
    "Availble from: <a href=\"https://github.com/autonomio/talos/\">https://github.com/autonomio/talos/</a>\n",
    "<img src=\"https://raw.githubusercontent.com/autonomio/talos/master/logo.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import talos\n",
    "\n",
    "# Function to run the model \n",
    "def everest(x_train, y_train, x_val, y_val, params):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(params['first_neuron'], input_dim=x_train.shape[1], \n",
    "              activation=params['activation']))\n",
    " \n",
    "    model.add(Dropout(params['dropout']))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=params['optimizer'], metrics=['accuracy'])\n",
    "    \n",
    "    out = model.fit(x_train, \n",
    "                    y_train,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    epochs=params['epochs'],\n",
    "                    batch_size=params['batch_size'],\n",
    "                    verbose=0)\n",
    "    \n",
    "    return out, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a parameter dictionary\n",
    "p = {'first_neuron':[30,60,120,240],\n",
    "    'hidden_layers':[1, 2],\n",
    "    'batch_size': [10,20, 30],\n",
    "    'epochs': [100, 150, 200],\n",
    "    'dropout': [0],\n",
    "    'optimizer': ['Nadam', 'Adam'],\n",
    "    'losses': ['binary_crossentropy'],\n",
    "    'activation':['relu'],\n",
    "    'last_activation': ['sigmoid']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [36:20<00:00, 72.68s/it]\n"
     ]
    }
   ],
   "source": [
    "t = talos.Scan(x=X_train_scaled, y=encoded_y_train, params=p, model=everest, experiment_name='everest_tune', round_limit=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "experiment_name            everest_tune\n",
       "random_method          uniform_mersenne\n",
       "reduction_method                   None\n",
       "reduction_interval                   50\n",
       "reduction_window                     20\n",
       "reduction_threshold                 0.2\n",
       "reduction_metric                val_acc\n",
       "complete_time            08/25/21/08:55\n",
       "x_shape                     (16273, 10)\n",
       "y_shape                        (16273,)\n",
       "dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best parameters:  \n",
    "  \n",
    "There are a a number of models which reach an accuracy of 98.8939% with validation data set\n",
    "\n",
    "Note that the underlying rate death rate in data is only 1.4% so it is relatively 'easy' to achieve high accuarcy with this model\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>duration</th>\n",
       "      <th>round_epochs</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>activation</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>dropout</th>\n",
       "      <th>epochs</th>\n",
       "      <th>first_neuron</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>last_activation</th>\n",
       "      <th>losses</th>\n",
       "      <th>optimizer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>08/25/21-081845</td>\n",
       "      <td>08/25/21-081924</td>\n",
       "      <td>38.964841</td>\n",
       "      <td>100</td>\n",
       "      <td>0.069590</td>\n",
       "      <td>0.985076</td>\n",
       "      <td>0.059857</td>\n",
       "      <td>0.988939</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>08/25/21-081924</td>\n",
       "      <td>08/25/21-082002</td>\n",
       "      <td>37.321072</td>\n",
       "      <td>100</td>\n",
       "      <td>0.070227</td>\n",
       "      <td>0.985076</td>\n",
       "      <td>0.059889</td>\n",
       "      <td>0.988939</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>08/25/21-082002</td>\n",
       "      <td>08/25/21-082119</td>\n",
       "      <td>76.714332</td>\n",
       "      <td>100</td>\n",
       "      <td>0.068532</td>\n",
       "      <td>0.985076</td>\n",
       "      <td>0.059954</td>\n",
       "      <td>0.988939</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>08/25/21-082119</td>\n",
       "      <td>08/25/21-082201</td>\n",
       "      <td>42.747454</td>\n",
       "      <td>150</td>\n",
       "      <td>0.068666</td>\n",
       "      <td>0.985164</td>\n",
       "      <td>0.059544</td>\n",
       "      <td>0.988939</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08/25/21-082202</td>\n",
       "      <td>08/25/21-082322</td>\n",
       "      <td>80.740770</td>\n",
       "      <td>100</td>\n",
       "      <td>0.068745</td>\n",
       "      <td>0.985164</td>\n",
       "      <td>0.059329</td>\n",
       "      <td>0.988939</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>08/25/21-082322</td>\n",
       "      <td>08/25/21-082405</td>\n",
       "      <td>42.247122</td>\n",
       "      <td>150</td>\n",
       "      <td>0.068365</td>\n",
       "      <td>0.985076</td>\n",
       "      <td>0.060794</td>\n",
       "      <td>0.988939</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>08/25/21-082405</td>\n",
       "      <td>08/25/21-082526</td>\n",
       "      <td>81.030664</td>\n",
       "      <td>200</td>\n",
       "      <td>0.067796</td>\n",
       "      <td>0.985076</td>\n",
       "      <td>0.061036</td>\n",
       "      <td>0.988939</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>08/25/21-082526</td>\n",
       "      <td>08/25/21-082554</td>\n",
       "      <td>28.152574</td>\n",
       "      <td>100</td>\n",
       "      <td>0.068716</td>\n",
       "      <td>0.985076</td>\n",
       "      <td>0.059283</td>\n",
       "      <td>0.988939</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>08/25/21-082554</td>\n",
       "      <td>08/25/21-082832</td>\n",
       "      <td>157.647629</td>\n",
       "      <td>200</td>\n",
       "      <td>0.068110</td>\n",
       "      <td>0.985076</td>\n",
       "      <td>0.060289</td>\n",
       "      <td>0.988939</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>08/25/21-082832</td>\n",
       "      <td>08/25/21-082950</td>\n",
       "      <td>78.458975</td>\n",
       "      <td>100</td>\n",
       "      <td>0.070171</td>\n",
       "      <td>0.985076</td>\n",
       "      <td>0.059696</td>\n",
       "      <td>0.988939</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>08/25/21-082951</td>\n",
       "      <td>08/25/21-083048</td>\n",
       "      <td>57.232181</td>\n",
       "      <td>200</td>\n",
       "      <td>0.065710</td>\n",
       "      <td>0.985251</td>\n",
       "      <td>0.060520</td>\n",
       "      <td>0.988734</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>240</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>08/25/21-083048</td>\n",
       "      <td>08/25/21-083246</td>\n",
       "      <td>118.496112</td>\n",
       "      <td>150</td>\n",
       "      <td>0.066490</td>\n",
       "      <td>0.985339</td>\n",
       "      <td>0.063825</td>\n",
       "      <td>0.988529</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>240</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>08/25/21-083247</td>\n",
       "      <td>08/25/21-083447</td>\n",
       "      <td>120.481900</td>\n",
       "      <td>150</td>\n",
       "      <td>0.067734</td>\n",
       "      <td>0.985251</td>\n",
       "      <td>0.060369</td>\n",
       "      <td>0.988734</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>08/25/21-083447</td>\n",
       "      <td>08/25/21-083531</td>\n",
       "      <td>43.807759</td>\n",
       "      <td>100</td>\n",
       "      <td>0.068117</td>\n",
       "      <td>0.985164</td>\n",
       "      <td>0.060083</td>\n",
       "      <td>0.988939</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>120</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>08/25/21-083531</td>\n",
       "      <td>08/25/21-083615</td>\n",
       "      <td>43.790956</td>\n",
       "      <td>100</td>\n",
       "      <td>0.067818</td>\n",
       "      <td>0.985251</td>\n",
       "      <td>0.059544</td>\n",
       "      <td>0.988734</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>240</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>08/25/21-083615</td>\n",
       "      <td>08/25/21-083659</td>\n",
       "      <td>44.353891</td>\n",
       "      <td>100</td>\n",
       "      <td>0.068933</td>\n",
       "      <td>0.985076</td>\n",
       "      <td>0.059650</td>\n",
       "      <td>0.988939</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>08/25/21-083659</td>\n",
       "      <td>08/25/21-084001</td>\n",
       "      <td>181.270836</td>\n",
       "      <td>200</td>\n",
       "      <td>0.066874</td>\n",
       "      <td>0.985251</td>\n",
       "      <td>0.060251</td>\n",
       "      <td>0.988734</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>08/25/21-084001</td>\n",
       "      <td>08/25/21-084303</td>\n",
       "      <td>181.827549</td>\n",
       "      <td>200</td>\n",
       "      <td>0.065449</td>\n",
       "      <td>0.985339</td>\n",
       "      <td>0.063002</td>\n",
       "      <td>0.988734</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>120</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>08/25/21-084303</td>\n",
       "      <td>08/25/21-084351</td>\n",
       "      <td>47.742463</td>\n",
       "      <td>150</td>\n",
       "      <td>0.066888</td>\n",
       "      <td>0.985251</td>\n",
       "      <td>0.060138</td>\n",
       "      <td>0.988734</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>240</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>08/25/21-084351</td>\n",
       "      <td>08/25/21-084437</td>\n",
       "      <td>45.880066</td>\n",
       "      <td>100</td>\n",
       "      <td>0.068523</td>\n",
       "      <td>0.985076</td>\n",
       "      <td>0.059875</td>\n",
       "      <td>0.988939</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>08/25/21-084437</td>\n",
       "      <td>08/25/21-084558</td>\n",
       "      <td>80.869499</td>\n",
       "      <td>100</td>\n",
       "      <td>0.069054</td>\n",
       "      <td>0.985076</td>\n",
       "      <td>0.059406</td>\n",
       "      <td>0.988939</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>08/25/21-084558</td>\n",
       "      <td>08/25/21-084641</td>\n",
       "      <td>42.974301</td>\n",
       "      <td>100</td>\n",
       "      <td>0.068128</td>\n",
       "      <td>0.985251</td>\n",
       "      <td>0.061795</td>\n",
       "      <td>0.988529</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>120</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>08/25/21-084641</td>\n",
       "      <td>08/25/21-084810</td>\n",
       "      <td>88.840329</td>\n",
       "      <td>200</td>\n",
       "      <td>0.069187</td>\n",
       "      <td>0.984988</td>\n",
       "      <td>0.061273</td>\n",
       "      <td>0.988939</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>08/25/21-084810</td>\n",
       "      <td>08/25/21-084842</td>\n",
       "      <td>32.631084</td>\n",
       "      <td>100</td>\n",
       "      <td>0.070005</td>\n",
       "      <td>0.985076</td>\n",
       "      <td>0.060767</td>\n",
       "      <td>0.988939</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>08/25/21-084843</td>\n",
       "      <td>08/25/21-084932</td>\n",
       "      <td>49.840816</td>\n",
       "      <td>150</td>\n",
       "      <td>0.067525</td>\n",
       "      <td>0.985076</td>\n",
       "      <td>0.059860</td>\n",
       "      <td>0.988939</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>08/25/21-084933</td>\n",
       "      <td>08/25/21-085038</td>\n",
       "      <td>65.609612</td>\n",
       "      <td>200</td>\n",
       "      <td>0.066890</td>\n",
       "      <td>0.985251</td>\n",
       "      <td>0.060751</td>\n",
       "      <td>0.988529</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>120</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>08/25/21-085038</td>\n",
       "      <td>08/25/21-085127</td>\n",
       "      <td>48.222773</td>\n",
       "      <td>150</td>\n",
       "      <td>0.068057</td>\n",
       "      <td>0.985164</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>0.988939</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>08/25/21-085127</td>\n",
       "      <td>08/25/21-085216</td>\n",
       "      <td>49.546713</td>\n",
       "      <td>100</td>\n",
       "      <td>0.067876</td>\n",
       "      <td>0.985251</td>\n",
       "      <td>0.060060</td>\n",
       "      <td>0.988734</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>240</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>08/25/21-085216</td>\n",
       "      <td>08/25/21-085432</td>\n",
       "      <td>135.655181</td>\n",
       "      <td>150</td>\n",
       "      <td>0.069046</td>\n",
       "      <td>0.985076</td>\n",
       "      <td>0.059223</td>\n",
       "      <td>0.988939</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>08/25/21-085432</td>\n",
       "      <td>08/25/21-085506</td>\n",
       "      <td>33.367645</td>\n",
       "      <td>100</td>\n",
       "      <td>0.068802</td>\n",
       "      <td>0.985076</td>\n",
       "      <td>0.059850</td>\n",
       "      <td>0.988939</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>120</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              start              end    duration  round_epochs      loss  \\\n",
       "0   08/25/21-081845  08/25/21-081924   38.964841           100  0.069590   \n",
       "1   08/25/21-081924  08/25/21-082002   37.321072           100  0.070227   \n",
       "2   08/25/21-082002  08/25/21-082119   76.714332           100  0.068532   \n",
       "3   08/25/21-082119  08/25/21-082201   42.747454           150  0.068666   \n",
       "4   08/25/21-082202  08/25/21-082322   80.740770           100  0.068745   \n",
       "5   08/25/21-082322  08/25/21-082405   42.247122           150  0.068365   \n",
       "6   08/25/21-082405  08/25/21-082526   81.030664           200  0.067796   \n",
       "7   08/25/21-082526  08/25/21-082554   28.152574           100  0.068716   \n",
       "8   08/25/21-082554  08/25/21-082832  157.647629           200  0.068110   \n",
       "9   08/25/21-082832  08/25/21-082950   78.458975           100  0.070171   \n",
       "10  08/25/21-082951  08/25/21-083048   57.232181           200  0.065710   \n",
       "11  08/25/21-083048  08/25/21-083246  118.496112           150  0.066490   \n",
       "12  08/25/21-083247  08/25/21-083447  120.481900           150  0.067734   \n",
       "13  08/25/21-083447  08/25/21-083531   43.807759           100  0.068117   \n",
       "14  08/25/21-083531  08/25/21-083615   43.790956           100  0.067818   \n",
       "15  08/25/21-083615  08/25/21-083659   44.353891           100  0.068933   \n",
       "16  08/25/21-083659  08/25/21-084001  181.270836           200  0.066874   \n",
       "17  08/25/21-084001  08/25/21-084303  181.827549           200  0.065449   \n",
       "18  08/25/21-084303  08/25/21-084351   47.742463           150  0.066888   \n",
       "19  08/25/21-084351  08/25/21-084437   45.880066           100  0.068523   \n",
       "20  08/25/21-084437  08/25/21-084558   80.869499           100  0.069054   \n",
       "21  08/25/21-084558  08/25/21-084641   42.974301           100  0.068128   \n",
       "22  08/25/21-084641  08/25/21-084810   88.840329           200  0.069187   \n",
       "23  08/25/21-084810  08/25/21-084842   32.631084           100  0.070005   \n",
       "24  08/25/21-084843  08/25/21-084932   49.840816           150  0.067525   \n",
       "25  08/25/21-084933  08/25/21-085038   65.609612           200  0.066890   \n",
       "26  08/25/21-085038  08/25/21-085127   48.222773           150  0.068057   \n",
       "27  08/25/21-085127  08/25/21-085216   49.546713           100  0.067876   \n",
       "28  08/25/21-085216  08/25/21-085432  135.655181           150  0.069046   \n",
       "29  08/25/21-085432  08/25/21-085506   33.367645           100  0.068802   \n",
       "\n",
       "    accuracy  val_loss  val_accuracy activation  batch_size  dropout  epochs  \\\n",
       "0   0.985076  0.059857      0.988939       relu          20        0     100   \n",
       "1   0.985076  0.059889      0.988939       relu          20        0     100   \n",
       "2   0.985076  0.059954      0.988939       relu          10        0     100   \n",
       "3   0.985164  0.059544      0.988939       relu          30        0     150   \n",
       "4   0.985164  0.059329      0.988939       relu          10        0     100   \n",
       "5   0.985076  0.060794      0.988939       relu          30        0     150   \n",
       "6   0.985076  0.061036      0.988939       relu          20        0     200   \n",
       "7   0.985076  0.059283      0.988939       relu          30        0     100   \n",
       "8   0.985076  0.060289      0.988939       relu          10        0     200   \n",
       "9   0.985076  0.059696      0.988939       relu          10        0     100   \n",
       "10  0.985251  0.060520      0.988734       relu          30        0     200   \n",
       "11  0.985339  0.063825      0.988529       relu          10        0     150   \n",
       "12  0.985251  0.060369      0.988734       relu          10        0     150   \n",
       "13  0.985164  0.060083      0.988939       relu          20        0     100   \n",
       "14  0.985251  0.059544      0.988734       relu          20        0     100   \n",
       "15  0.985076  0.059650      0.988939       relu          20        0     100   \n",
       "16  0.985251  0.060251      0.988734       relu          10        0     200   \n",
       "17  0.985339  0.063002      0.988734       relu          10        0     200   \n",
       "18  0.985251  0.060138      0.988734       relu          30        0     150   \n",
       "19  0.985076  0.059875      0.988939       relu          20        0     100   \n",
       "20  0.985076  0.059406      0.988939       relu          10        0     100   \n",
       "21  0.985251  0.061795      0.988529       relu          20        0     100   \n",
       "22  0.984988  0.061273      0.988939       relu          20        0     200   \n",
       "23  0.985076  0.060767      0.988939       relu          30        0     100   \n",
       "24  0.985076  0.059860      0.988939       relu          30        0     150   \n",
       "25  0.985251  0.060751      0.988529       relu          30        0     200   \n",
       "26  0.985164  0.060018      0.988939       relu          30        0     150   \n",
       "27  0.985251  0.060060      0.988734       relu          20        0     100   \n",
       "28  0.985076  0.059223      0.988939       relu          10        0     150   \n",
       "29  0.985076  0.059850      0.988939       relu          30        0     100   \n",
       "\n",
       "    first_neuron  hidden_layers last_activation               losses optimizer  \n",
       "0             30              1         sigmoid  binary_crossentropy      Adam  \n",
       "1             30              2         sigmoid  binary_crossentropy      Adam  \n",
       "2             60              1         sigmoid  binary_crossentropy     Nadam  \n",
       "3             30              1         sigmoid  binary_crossentropy     Nadam  \n",
       "4            120              1         sigmoid  binary_crossentropy     Nadam  \n",
       "5             60              1         sigmoid  binary_crossentropy     Nadam  \n",
       "6             60              1         sigmoid  binary_crossentropy     Nadam  \n",
       "7             60              2         sigmoid  binary_crossentropy      Adam  \n",
       "8             30              2         sigmoid  binary_crossentropy     Nadam  \n",
       "9             30              1         sigmoid  binary_crossentropy      Adam  \n",
       "10           240              2         sigmoid  binary_crossentropy      Adam  \n",
       "11           240              2         sigmoid  binary_crossentropy     Nadam  \n",
       "12            60              1         sigmoid  binary_crossentropy     Nadam  \n",
       "13           120              2         sigmoid  binary_crossentropy      Adam  \n",
       "14           240              2         sigmoid  binary_crossentropy      Adam  \n",
       "15            60              2         sigmoid  binary_crossentropy      Adam  \n",
       "16            60              2         sigmoid  binary_crossentropy      Adam  \n",
       "17           120              2         sigmoid  binary_crossentropy      Adam  \n",
       "18           240              2         sigmoid  binary_crossentropy     Nadam  \n",
       "19            60              1         sigmoid  binary_crossentropy      Adam  \n",
       "20            30              2         sigmoid  binary_crossentropy      Adam  \n",
       "21           120              2         sigmoid  binary_crossentropy     Nadam  \n",
       "22            30              2         sigmoid  binary_crossentropy      Adam  \n",
       "23            30              2         sigmoid  binary_crossentropy     Nadam  \n",
       "24           120              1         sigmoid  binary_crossentropy      Adam  \n",
       "25           120              2         sigmoid  binary_crossentropy     Nadam  \n",
       "26           120              1         sigmoid  binary_crossentropy     Nadam  \n",
       "27           240              1         sigmoid  binary_crossentropy     Nadam  \n",
       "28            30              2         sigmoid  binary_crossentropy      Adam  \n",
       "29           120              2         sigmoid  binary_crossentropy     Nadam  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display a dataframe comapring the results of the different combinations \n",
    "t.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the model with the optimised paramaters \n",
    "\n",
    "p_optimisied = {'first_neuron':30,\n",
    "                'second_neuron':120,\n",
    "                'hidden_layers':2,\n",
    "                'batch_size': 20,\n",
    "                'epochs': 100,\n",
    "                'dropout': 0,\n",
    "                'optimizer': 'adam',\n",
    "                'activation':'relu',\n",
    "               }\n",
    "\n",
    "def everest_optimised(x_train, y_train, params):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(params['first_neuron'], input_dim=x_train.shape[1], \n",
    "              activation=params['activation']))\n",
    "    \n",
    "    model.add(Dense(params['second_neuron'], activation=params['activation']))\n",
    " \n",
    "    model.add(Dropout(params['dropout']))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=params['optimizer'], metrics=['accuracy'])\n",
    "    \n",
    "    out = model.fit(x_train, \n",
    "                    y_train,\n",
    "                    epochs=params['epochs'],\n",
    "                    batch_size=params['batch_size'],\n",
    "                    verbose=0)\n",
    "\n",
    "    return out, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-fit the training data to the model\n",
    "out, model = everest_optimised(X_train_scaled, encoded_y_train, p_optimisied)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 - 0s - loss: 0.0813 - accuracy: 0.9847\n",
      "Neural Network Performace - Loss: 0.08128473907709122, Accuracy: 0.9847004413604736\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(X_test_scaled, encoded_y_test, verbose=2)\n",
    "print(f\"Neural Network Performace - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "filename = 'death_model.h5'\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(\"death_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "dev"
  },
  "kernelspec": {
   "display_name": "Python [conda env:PythonData] *",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
