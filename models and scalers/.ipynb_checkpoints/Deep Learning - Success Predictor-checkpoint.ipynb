{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "df = pd.read_csv(\"../clean_data.csv\", low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'expid', 'membid', 'myear', 'sex', 'calcage', 'citizen', 'status',\n",
       "       'msolo', 'msuccess', 'msmtdate1', 'msmtdate2', 'msmtdate3', 'route1',\n",
       "       'route2', 'route3', 'route4', 'mo2used', 'mo2none', 'mo2climb',\n",
       "       'mo2descent', 'mo2sleep', 'death', 'deathdate', 'msmtbid', 'stdrte',\n",
       "       'new_route', 'new_status', 'climber_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View column names and drop unnecesary columns for the model \n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set features\n",
    "feature_names = ['sex', 'calcage', 'citizen', 'new_route', 'mo2used', 'mo2climb',\n",
    "                 'mo2descent', 'mo2sleep', 'stdrte', 'new_status']\n",
    "\n",
    "X = df[feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>calcage</th>\n",
       "      <th>citizen</th>\n",
       "      <th>new_route</th>\n",
       "      <th>mo2used</th>\n",
       "      <th>mo2climb</th>\n",
       "      <th>mo2descent</th>\n",
       "      <th>mo2sleep</th>\n",
       "      <th>stdrte</th>\n",
       "      <th>new_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>89</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>85</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>85</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21693</th>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21694</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21695</th>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21696</th>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21697</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21698 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sex  calcage  citizen  new_route  mo2used  mo2climb  mo2descent  \\\n",
       "0        0       49       15          2      0.0       0.0         0.0   \n",
       "1        1       30       89          2      0.0       0.0         0.0   \n",
       "2        0       32       15          2      1.0       1.0         0.0   \n",
       "3        0       40       85          2      0.0       0.0         0.0   \n",
       "4        0       29       85          2      1.0       1.0         0.0   \n",
       "...    ...      ...      ...        ...      ...       ...         ...   \n",
       "21693    0       47       28          0      1.0       1.0         0.0   \n",
       "21694    0       37       28          0      1.0       1.0         0.0   \n",
       "21695    0       57       28          0      1.0       1.0         0.0   \n",
       "21696    0       35       28          0      1.0       1.0         0.0   \n",
       "21697    0       37       28          0      1.0       1.0         0.0   \n",
       "\n",
       "       mo2sleep  stdrte  new_status  \n",
       "0           0.0     1.0           3  \n",
       "1           0.0     1.0           3  \n",
       "2           1.0     1.0           0  \n",
       "3           0.0     1.0           5  \n",
       "4           1.0     1.0           5  \n",
       "...         ...     ...         ...  \n",
       "21693       0.0     1.0           0  \n",
       "21694       1.0     1.0           0  \n",
       "21695       1.0     1.0           0  \n",
       "21696       1.0     1.0           0  \n",
       "21697       1.0     1.0           0  \n",
       "\n",
       "[21698 rows x 10 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert X values to numerical \n",
    "\n",
    "###                KEY                  ### \n",
    "###        Male = 0, Female = 1         ###\n",
    "###        True = 1, False = 0          ###oute, \n",
    "###  Citizen and Route = see label map  ###\n",
    "\n",
    "X.replace(True, 1, inplace=True)\n",
    "X['sex'] = pd.get_dummies(X['sex'])\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "# Perform label transformation and create label maps for later use \n",
    "X['citizen'] = le.fit_transform(X['citizen'])\n",
    "country_label_map = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "X['new_route'] = le.fit_transform(X['new_route'])\n",
    "route_label_map = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "X['new_status'] = le.fit_transform(X['new_status'])\n",
    "status_label_map = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_names = df['msuccess'].unique()\n",
    "target_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y  = df['msuccess']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Train Test Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "Scale the data using the MinMaxScaler and perform some feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create the scaler\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "\n",
    "# Transform the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data_scaler.pkl']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the scaler for later use\n",
    "import joblib \n",
    "\n",
    "filename = 'data_scaler.pkl'\n",
    "joblib.dump(X_scaler, filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the y values to numerical using label_encoder/to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)\n",
    "y_test_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and initial trial model and add layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "inputs = X_train.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=60, activation='relu', input_dim=inputs))\n",
    "model.add(Dense(units=200, activation='relu'))\n",
    "model.add(Dense(units=2, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 60)                660       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 200)               12200     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 402       \n",
      "=================================================================\n",
      "Total params: 13,262\n",
      "Trainable params: 13,262\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "509/509 - 1s - loss: 0.3472 - accuracy: 0.8695\n",
      "Epoch 2/100\n",
      "509/509 - 0s - loss: 0.3225 - accuracy: 0.8750\n",
      "Epoch 3/100\n",
      "509/509 - 0s - loss: 0.3206 - accuracy: 0.8759\n",
      "Epoch 4/100\n",
      "509/509 - 0s - loss: 0.3206 - accuracy: 0.8755\n",
      "Epoch 5/100\n",
      "509/509 - 0s - loss: 0.3205 - accuracy: 0.8756\n",
      "Epoch 6/100\n",
      "509/509 - 0s - loss: 0.3190 - accuracy: 0.8760\n",
      "Epoch 7/100\n",
      "509/509 - 0s - loss: 0.3191 - accuracy: 0.8760\n",
      "Epoch 8/100\n",
      "509/509 - 0s - loss: 0.3187 - accuracy: 0.8758\n",
      "Epoch 9/100\n",
      "509/509 - 0s - loss: 0.3185 - accuracy: 0.8765\n",
      "Epoch 10/100\n",
      "509/509 - 0s - loss: 0.3179 - accuracy: 0.8769\n",
      "Epoch 11/100\n",
      "509/509 - 0s - loss: 0.3179 - accuracy: 0.8763\n",
      "Epoch 12/100\n",
      "509/509 - 0s - loss: 0.3171 - accuracy: 0.8764\n",
      "Epoch 13/100\n",
      "509/509 - 0s - loss: 0.3177 - accuracy: 0.8764\n",
      "Epoch 14/100\n",
      "509/509 - 0s - loss: 0.3165 - accuracy: 0.8770\n",
      "Epoch 15/100\n",
      "509/509 - 0s - loss: 0.3164 - accuracy: 0.8765\n",
      "Epoch 16/100\n",
      "509/509 - 0s - loss: 0.3162 - accuracy: 0.8762\n",
      "Epoch 17/100\n",
      "509/509 - 0s - loss: 0.3160 - accuracy: 0.8765\n",
      "Epoch 18/100\n",
      "509/509 - 0s - loss: 0.3157 - accuracy: 0.8761\n",
      "Epoch 19/100\n",
      "509/509 - 0s - loss: 0.3152 - accuracy: 0.8770\n",
      "Epoch 20/100\n",
      "509/509 - 0s - loss: 0.3152 - accuracy: 0.8766\n",
      "Epoch 21/100\n",
      "509/509 - 0s - loss: 0.3150 - accuracy: 0.8759\n",
      "Epoch 22/100\n",
      "509/509 - 0s - loss: 0.3145 - accuracy: 0.8773\n",
      "Epoch 23/100\n",
      "509/509 - 0s - loss: 0.3144 - accuracy: 0.8777\n",
      "Epoch 24/100\n",
      "509/509 - 0s - loss: 0.3141 - accuracy: 0.8769\n",
      "Epoch 25/100\n",
      "509/509 - 0s - loss: 0.3137 - accuracy: 0.8773\n",
      "Epoch 26/100\n",
      "509/509 - 0s - loss: 0.3138 - accuracy: 0.8773\n",
      "Epoch 27/100\n",
      "509/509 - 0s - loss: 0.3137 - accuracy: 0.8770\n",
      "Epoch 28/100\n",
      "509/509 - 0s - loss: 0.3137 - accuracy: 0.8773\n",
      "Epoch 29/100\n",
      "509/509 - 0s - loss: 0.3132 - accuracy: 0.8770\n",
      "Epoch 30/100\n",
      "509/509 - 0s - loss: 0.3133 - accuracy: 0.8774\n",
      "Epoch 31/100\n",
      "509/509 - 0s - loss: 0.3128 - accuracy: 0.8773\n",
      "Epoch 32/100\n",
      "509/509 - 0s - loss: 0.3128 - accuracy: 0.8776\n",
      "Epoch 33/100\n",
      "509/509 - 0s - loss: 0.3131 - accuracy: 0.8772\n",
      "Epoch 34/100\n",
      "509/509 - 0s - loss: 0.3124 - accuracy: 0.8780\n",
      "Epoch 35/100\n",
      "509/509 - 0s - loss: 0.3123 - accuracy: 0.8782\n",
      "Epoch 36/100\n",
      "509/509 - 0s - loss: 0.3119 - accuracy: 0.8780\n",
      "Epoch 37/100\n",
      "509/509 - 0s - loss: 0.3117 - accuracy: 0.8787\n",
      "Epoch 38/100\n",
      "509/509 - 0s - loss: 0.3130 - accuracy: 0.8778\n",
      "Epoch 39/100\n",
      "509/509 - 0s - loss: 0.3120 - accuracy: 0.8776\n",
      "Epoch 40/100\n",
      "509/509 - 0s - loss: 0.3115 - accuracy: 0.8776\n",
      "Epoch 41/100\n",
      "509/509 - 0s - loss: 0.3113 - accuracy: 0.8783\n",
      "Epoch 42/100\n",
      "509/509 - 0s - loss: 0.3113 - accuracy: 0.8781\n",
      "Epoch 43/100\n",
      "509/509 - 0s - loss: 0.3107 - accuracy: 0.8781\n",
      "Epoch 44/100\n",
      "509/509 - 0s - loss: 0.3106 - accuracy: 0.8781\n",
      "Epoch 45/100\n",
      "509/509 - 0s - loss: 0.3108 - accuracy: 0.8783\n",
      "Epoch 46/100\n",
      "509/509 - 0s - loss: 0.3112 - accuracy: 0.8784\n",
      "Epoch 47/100\n",
      "509/509 - 0s - loss: 0.3100 - accuracy: 0.8786\n",
      "Epoch 48/100\n",
      "509/509 - 0s - loss: 0.3094 - accuracy: 0.8788\n",
      "Epoch 49/100\n",
      "509/509 - 0s - loss: 0.3097 - accuracy: 0.8788\n",
      "Epoch 50/100\n",
      "509/509 - 0s - loss: 0.3094 - accuracy: 0.8790\n",
      "Epoch 51/100\n",
      "509/509 - 0s - loss: 0.3092 - accuracy: 0.8786\n",
      "Epoch 52/100\n",
      "509/509 - 0s - loss: 0.3094 - accuracy: 0.8784\n",
      "Epoch 53/100\n",
      "509/509 - 0s - loss: 0.3089 - accuracy: 0.8792\n",
      "Epoch 54/100\n",
      "509/509 - 0s - loss: 0.3094 - accuracy: 0.8788\n",
      "Epoch 55/100\n",
      "509/509 - 0s - loss: 0.3089 - accuracy: 0.8788\n",
      "Epoch 56/100\n",
      "509/509 - 0s - loss: 0.3089 - accuracy: 0.8794\n",
      "Epoch 57/100\n",
      "509/509 - 0s - loss: 0.3084 - accuracy: 0.8792\n",
      "Epoch 58/100\n",
      "509/509 - 0s - loss: 0.3083 - accuracy: 0.8792\n",
      "Epoch 59/100\n",
      "509/509 - 0s - loss: 0.3083 - accuracy: 0.8782\n",
      "Epoch 60/100\n",
      "509/509 - 0s - loss: 0.3084 - accuracy: 0.8788\n",
      "Epoch 61/100\n",
      "509/509 - 0s - loss: 0.3081 - accuracy: 0.8786\n",
      "Epoch 62/100\n",
      "509/509 - 0s - loss: 0.3078 - accuracy: 0.8795\n",
      "Epoch 63/100\n",
      "509/509 - 0s - loss: 0.3071 - accuracy: 0.8784\n",
      "Epoch 64/100\n",
      "509/509 - 0s - loss: 0.3076 - accuracy: 0.8785\n",
      "Epoch 65/100\n",
      "509/509 - 0s - loss: 0.3082 - accuracy: 0.8783\n",
      "Epoch 66/100\n",
      "509/509 - 0s - loss: 0.3068 - accuracy: 0.8789\n",
      "Epoch 67/100\n",
      "509/509 - 0s - loss: 0.3073 - accuracy: 0.8791\n",
      "Epoch 68/100\n",
      "509/509 - 0s - loss: 0.3067 - accuracy: 0.8788\n",
      "Epoch 69/100\n",
      "509/509 - 0s - loss: 0.3064 - accuracy: 0.8799\n",
      "Epoch 70/100\n",
      "509/509 - 0s - loss: 0.3065 - accuracy: 0.8799\n",
      "Epoch 71/100\n",
      "509/509 - 0s - loss: 0.3070 - accuracy: 0.8798\n",
      "Epoch 72/100\n",
      "509/509 - 0s - loss: 0.3061 - accuracy: 0.8792\n",
      "Epoch 73/100\n",
      "509/509 - 0s - loss: 0.3063 - accuracy: 0.8797\n",
      "Epoch 74/100\n",
      "509/509 - 0s - loss: 0.3065 - accuracy: 0.8789\n",
      "Epoch 75/100\n",
      "509/509 - 0s - loss: 0.3057 - accuracy: 0.8801\n",
      "Epoch 76/100\n",
      "509/509 - 0s - loss: 0.3057 - accuracy: 0.8790\n",
      "Epoch 77/100\n",
      "509/509 - 0s - loss: 0.3051 - accuracy: 0.8805\n",
      "Epoch 78/100\n",
      "509/509 - 0s - loss: 0.3061 - accuracy: 0.8800\n",
      "Epoch 79/100\n",
      "509/509 - 0s - loss: 0.3053 - accuracy: 0.8797\n",
      "Epoch 80/100\n",
      "509/509 - 0s - loss: 0.3050 - accuracy: 0.8804\n",
      "Epoch 81/100\n",
      "509/509 - 0s - loss: 0.3051 - accuracy: 0.8800\n",
      "Epoch 82/100\n",
      "509/509 - 0s - loss: 0.3054 - accuracy: 0.8792\n",
      "Epoch 83/100\n",
      "509/509 - 0s - loss: 0.3048 - accuracy: 0.8801\n",
      "Epoch 84/100\n",
      "509/509 - 0s - loss: 0.3048 - accuracy: 0.8800\n",
      "Epoch 85/100\n",
      "509/509 - 0s - loss: 0.3044 - accuracy: 0.8796\n",
      "Epoch 86/100\n",
      "509/509 - 0s - loss: 0.3039 - accuracy: 0.8797\n",
      "Epoch 87/100\n",
      "509/509 - 0s - loss: 0.3040 - accuracy: 0.8807\n",
      "Epoch 88/100\n",
      "509/509 - 0s - loss: 0.3040 - accuracy: 0.8808\n",
      "Epoch 89/100\n",
      "509/509 - 0s - loss: 0.3044 - accuracy: 0.8798\n",
      "Epoch 90/100\n",
      "509/509 - 0s - loss: 0.3044 - accuracy: 0.8793\n",
      "Epoch 91/100\n",
      "509/509 - 0s - loss: 0.3033 - accuracy: 0.8810\n",
      "Epoch 92/100\n",
      "509/509 - 0s - loss: 0.3037 - accuracy: 0.8800\n",
      "Epoch 93/100\n",
      "509/509 - 0s - loss: 0.3032 - accuracy: 0.8801\n",
      "Epoch 94/100\n",
      "509/509 - 0s - loss: 0.3039 - accuracy: 0.8804\n",
      "Epoch 95/100\n",
      "509/509 - 0s - loss: 0.3028 - accuracy: 0.8813\n",
      "Epoch 96/100\n",
      "509/509 - 0s - loss: 0.3033 - accuracy: 0.8810\n",
      "Epoch 97/100\n",
      "509/509 - 0s - loss: 0.3033 - accuracy: 0.8811\n",
      "Epoch 98/100\n",
      "509/509 - 0s - loss: 0.3030 - accuracy: 0.8811\n",
      "Epoch 99/100\n",
      "509/509 - 0s - loss: 0.3032 - accuracy: 0.8807\n",
      "Epoch 100/100\n",
      "509/509 - 0s - loss: 0.3023 - accuracy: 0.8811\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22113e99748>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    verbose=2,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantify Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 - 0s - loss: 0.3167 - accuracy: 0.8765\n",
      "Neural Network Performace - Loss: 0.3166704475879669, Accuracy: 0.8764976859092712\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(f\"Neural Network Performace - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chance of success for datapoint 50 is: 93.46%\n"
     ]
    }
   ],
   "source": [
    "# Print some test data to try out the preduction model \n",
    "test_values = X_train_scaled[50].tolist()\n",
    "result = model.predict([test_values])\n",
    "print(f\"Chance of success for datapoint 50 is: {round(result[0][1]*100,2)}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 540x540 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a confusion matrix to visualise the performance \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "predictions = np.argmax(model.predict(X_test_scaled), axis=-1)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true=encoded_y_test, y_pred=predictions)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
    "\n",
    "ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)\n",
    "\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        ax.text(x=j, y=i, s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
    "\n",
    "plt.title('Confusion Matrix', fontsize=18)\n",
    "plt.xlabel('Predictions', fontsize=18)\n",
    "ax.set_xticks([0,1])\n",
    "ax.set_xticklabels(target_names)\n",
    "plt.ylabel('Actuals', fontsize=18)\n",
    "ax.set_yticks([0,1])\n",
    "ax.set_yticklabels(target_names)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sex', 'calcage', 'citizen', 'new_route', 'mo2climb', 'mo2sleep',\n",
       "       'stdrte', 'new_status'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use recursive feature elimination to identify the best performing features\n",
    "from sklearn.feature_selection import RFECV\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "# Initiate RFE cross-validation and fit with a linear regression model\n",
    "rfecv = RFECV(\n",
    "    estimator=tree.DecisionTreeClassifier(),\n",
    "    min_features_to_select=8,\n",
    "    step=5,\n",
    "    n_jobs=-1,\n",
    "    scoring=\"r2\",\n",
    "    cv=5,\n",
    ")\n",
    "\n",
    "_ = rfecv.fit(X_train_scaled, encoded_y_train)\n",
    "\n",
    "# Print the best columns\n",
    "X_train.columns[rfecv.support_]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RFE Suggests keeping all features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperperameter tuning\n",
    "\n",
    "#### Talos Custom Hyperparameter Optimiser for Keras, Tensorflow used \n",
    "Availble from: <a href=\"https://github.com/autonomio/talos/\">https://github.com/autonomio/talos/</a>\n",
    "<img src=\"https://raw.githubusercontent.com/autonomio/talos/master/logo.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import talos\n",
    "\n",
    "# Function to run the model \n",
    "def everest(x_train, y_train, x_val, y_val, params):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(params['first_neuron'], input_dim=x_train.shape[1], \n",
    "              activation=params['activation']))\n",
    " \n",
    "    model.add(Dropout(params['dropout']))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=params['optimizer'], metrics=['accuracy'])\n",
    "    \n",
    "    out = model.fit(x_train, \n",
    "                    y_train,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    epochs=params['epochs'],\n",
    "                    batch_size=params['batch_size'],\n",
    "                    verbose=0)\n",
    "    \n",
    "    return out, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a parameter dictionary\n",
    "p = {'first_neuron':[30,60,120,240],\n",
    "    'hidden_layers':[1, 2],\n",
    "    'batch_size': [10,20, 30],\n",
    "    'epochs': [100, 150, 200],\n",
    "    'dropout': [0],\n",
    "    'optimizer': ['Nadam', 'Adam'],\n",
    "    'losses': ['binary_crossentropy'],\n",
    "    'activation':['relu'],\n",
    "    'last_activation': ['sigmoid']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [39:42<00:00, 79.43s/it]\n"
     ]
    }
   ],
   "source": [
    "t = talos.Scan(x=X_train_scaled, y=encoded_y_train, params=p, model=everest, experiment_name='everest_tune', round_limit=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "experiment_name            everest_tune\n",
       "random_method          uniform_mersenne\n",
       "reduction_method                   None\n",
       "reduction_interval                   50\n",
       "reduction_window                     20\n",
       "reduction_threshold                 0.2\n",
       "reduction_metric                val_acc\n",
       "complete_time            08/25/21/08:56\n",
       "x_shape                     (16273, 10)\n",
       "y_shape                        (16273,)\n",
       "dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best parameters:  \n",
    "  \n",
    "(as per table below)  \n",
    "first layer: 30  \n",
    "hidden layers: 2  \n",
    "activation: relu  \n",
    "batch_size: 20  \n",
    "epochs: 150  \n",
    "dropout: 0  \n",
    "optimizer: Nadam  \n",
    "<b>accuracy (val):</b> 88.017%  \n",
    "<b>loss (val):</b> 0.316674\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>duration</th>\n",
       "      <th>round_epochs</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>activation</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>dropout</th>\n",
       "      <th>epochs</th>\n",
       "      <th>first_neuron</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>last_activation</th>\n",
       "      <th>losses</th>\n",
       "      <th>optimizer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>08/25/21-081651</td>\n",
       "      <td>08/25/21-081924</td>\n",
       "      <td>153.606198</td>\n",
       "      <td>200</td>\n",
       "      <td>0.302781</td>\n",
       "      <td>0.880432</td>\n",
       "      <td>0.321978</td>\n",
       "      <td>0.874642</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>120</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>08/25/21-081924</td>\n",
       "      <td>08/25/21-082120</td>\n",
       "      <td>115.259690</td>\n",
       "      <td>150</td>\n",
       "      <td>0.307944</td>\n",
       "      <td>0.877447</td>\n",
       "      <td>0.318839</td>\n",
       "      <td>0.875871</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>08/25/21-082120</td>\n",
       "      <td>08/25/21-082243</td>\n",
       "      <td>83.275903</td>\n",
       "      <td>200</td>\n",
       "      <td>0.311683</td>\n",
       "      <td>0.876306</td>\n",
       "      <td>0.320095</td>\n",
       "      <td>0.878533</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>08/25/21-082243</td>\n",
       "      <td>08/25/21-082325</td>\n",
       "      <td>41.615116</td>\n",
       "      <td>100</td>\n",
       "      <td>0.307395</td>\n",
       "      <td>0.878852</td>\n",
       "      <td>0.321459</td>\n",
       "      <td>0.875051</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>240</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08/25/21-082325</td>\n",
       "      <td>08/25/21-082353</td>\n",
       "      <td>28.441410</td>\n",
       "      <td>100</td>\n",
       "      <td>0.313880</td>\n",
       "      <td>0.876569</td>\n",
       "      <td>0.316681</td>\n",
       "      <td>0.877509</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>08/25/21-082353</td>\n",
       "      <td>08/25/21-082632</td>\n",
       "      <td>158.117142</td>\n",
       "      <td>200</td>\n",
       "      <td>0.307058</td>\n",
       "      <td>0.876920</td>\n",
       "      <td>0.319329</td>\n",
       "      <td>0.876690</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>08/25/21-082632</td>\n",
       "      <td>08/25/21-082733</td>\n",
       "      <td>61.686494</td>\n",
       "      <td>150</td>\n",
       "      <td>0.305680</td>\n",
       "      <td>0.879203</td>\n",
       "      <td>0.320330</td>\n",
       "      <td>0.877100</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>08/25/21-082734</td>\n",
       "      <td>08/25/21-082835</td>\n",
       "      <td>61.670819</td>\n",
       "      <td>150</td>\n",
       "      <td>0.306027</td>\n",
       "      <td>0.878588</td>\n",
       "      <td>0.322367</td>\n",
       "      <td>0.876690</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>08/25/21-082835</td>\n",
       "      <td>08/25/21-082936</td>\n",
       "      <td>60.803183</td>\n",
       "      <td>150</td>\n",
       "      <td>0.312962</td>\n",
       "      <td>0.876218</td>\n",
       "      <td>0.316674</td>\n",
       "      <td>0.880172</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>08/25/21-082936</td>\n",
       "      <td>08/25/21-083032</td>\n",
       "      <td>55.865111</td>\n",
       "      <td>200</td>\n",
       "      <td>0.312666</td>\n",
       "      <td>0.876920</td>\n",
       "      <td>0.317853</td>\n",
       "      <td>0.878943</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>08/25/21-083032</td>\n",
       "      <td>08/25/21-083154</td>\n",
       "      <td>81.296361</td>\n",
       "      <td>100</td>\n",
       "      <td>0.306936</td>\n",
       "      <td>0.878413</td>\n",
       "      <td>0.318524</td>\n",
       "      <td>0.877304</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>240</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>08/25/21-083154</td>\n",
       "      <td>08/25/21-083354</td>\n",
       "      <td>120.304415</td>\n",
       "      <td>150</td>\n",
       "      <td>0.302856</td>\n",
       "      <td>0.881749</td>\n",
       "      <td>0.326593</td>\n",
       "      <td>0.873822</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>240</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>08/25/21-083354</td>\n",
       "      <td>08/25/21-083558</td>\n",
       "      <td>123.467238</td>\n",
       "      <td>150</td>\n",
       "      <td>0.311082</td>\n",
       "      <td>0.875165</td>\n",
       "      <td>0.318217</td>\n",
       "      <td>0.878329</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>08/25/21-083558</td>\n",
       "      <td>08/25/21-083725</td>\n",
       "      <td>86.902818</td>\n",
       "      <td>100</td>\n",
       "      <td>0.312621</td>\n",
       "      <td>0.876833</td>\n",
       "      <td>0.317319</td>\n",
       "      <td>0.875666</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>08/25/21-083725</td>\n",
       "      <td>08/25/21-083755</td>\n",
       "      <td>30.724834</td>\n",
       "      <td>100</td>\n",
       "      <td>0.310513</td>\n",
       "      <td>0.877798</td>\n",
       "      <td>0.317304</td>\n",
       "      <td>0.877304</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>120</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>08/25/21-083756</td>\n",
       "      <td>08/25/21-083845</td>\n",
       "      <td>49.236881</td>\n",
       "      <td>150</td>\n",
       "      <td>0.305724</td>\n",
       "      <td>0.879203</td>\n",
       "      <td>0.321165</td>\n",
       "      <td>0.875256</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>240</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>08/25/21-083845</td>\n",
       "      <td>08/25/21-083918</td>\n",
       "      <td>32.736044</td>\n",
       "      <td>100</td>\n",
       "      <td>0.316053</td>\n",
       "      <td>0.875691</td>\n",
       "      <td>0.316559</td>\n",
       "      <td>0.877304</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>08/25/21-083918</td>\n",
       "      <td>08/25/21-084136</td>\n",
       "      <td>138.183115</td>\n",
       "      <td>150</td>\n",
       "      <td>0.309381</td>\n",
       "      <td>0.877886</td>\n",
       "      <td>0.320149</td>\n",
       "      <td>0.876280</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>08/25/21-084136</td>\n",
       "      <td>08/25/21-084310</td>\n",
       "      <td>93.361112</td>\n",
       "      <td>200</td>\n",
       "      <td>0.307676</td>\n",
       "      <td>0.879027</td>\n",
       "      <td>0.321272</td>\n",
       "      <td>0.874232</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>08/25/21-084310</td>\n",
       "      <td>08/25/21-084341</td>\n",
       "      <td>31.254015</td>\n",
       "      <td>100</td>\n",
       "      <td>0.315771</td>\n",
       "      <td>0.876130</td>\n",
       "      <td>0.317192</td>\n",
       "      <td>0.877509</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>08/25/21-084341</td>\n",
       "      <td>08/25/21-084428</td>\n",
       "      <td>47.146175</td>\n",
       "      <td>150</td>\n",
       "      <td>0.306852</td>\n",
       "      <td>0.878940</td>\n",
       "      <td>0.318208</td>\n",
       "      <td>0.877714</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>120</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>08/25/21-084428</td>\n",
       "      <td>08/25/21-084551</td>\n",
       "      <td>82.704441</td>\n",
       "      <td>100</td>\n",
       "      <td>0.313937</td>\n",
       "      <td>0.875867</td>\n",
       "      <td>0.320273</td>\n",
       "      <td>0.878533</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>08/25/21-084551</td>\n",
       "      <td>08/25/21-084802</td>\n",
       "      <td>131.106751</td>\n",
       "      <td>150</td>\n",
       "      <td>0.305015</td>\n",
       "      <td>0.879642</td>\n",
       "      <td>0.322026</td>\n",
       "      <td>0.876690</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>120</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>08/25/21-084803</td>\n",
       "      <td>08/25/21-084851</td>\n",
       "      <td>48.854972</td>\n",
       "      <td>150</td>\n",
       "      <td>0.311012</td>\n",
       "      <td>0.876745</td>\n",
       "      <td>0.316683</td>\n",
       "      <td>0.877714</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>08/25/21-084852</td>\n",
       "      <td>08/25/21-084941</td>\n",
       "      <td>49.755342</td>\n",
       "      <td>150</td>\n",
       "      <td>0.312719</td>\n",
       "      <td>0.875165</td>\n",
       "      <td>0.318164</td>\n",
       "      <td>0.875871</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>08/25/21-084941</td>\n",
       "      <td>08/25/21-085015</td>\n",
       "      <td>33.096976</td>\n",
       "      <td>100</td>\n",
       "      <td>0.315129</td>\n",
       "      <td>0.875867</td>\n",
       "      <td>0.316464</td>\n",
       "      <td>0.877714</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>08/25/21-085015</td>\n",
       "      <td>08/25/21-085103</td>\n",
       "      <td>48.178424</td>\n",
       "      <td>100</td>\n",
       "      <td>0.309661</td>\n",
       "      <td>0.877974</td>\n",
       "      <td>0.317882</td>\n",
       "      <td>0.876280</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>08/25/21-085103</td>\n",
       "      <td>08/25/21-085408</td>\n",
       "      <td>185.516495</td>\n",
       "      <td>200</td>\n",
       "      <td>0.302791</td>\n",
       "      <td>0.879905</td>\n",
       "      <td>0.326933</td>\n",
       "      <td>0.876690</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>08/25/21-085409</td>\n",
       "      <td>08/25/21-085515</td>\n",
       "      <td>66.790987</td>\n",
       "      <td>200</td>\n",
       "      <td>0.301973</td>\n",
       "      <td>0.882100</td>\n",
       "      <td>0.320688</td>\n",
       "      <td>0.875461</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>240</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>08/25/21-085516</td>\n",
       "      <td>08/25/21-085633</td>\n",
       "      <td>77.832502</td>\n",
       "      <td>200</td>\n",
       "      <td>0.300183</td>\n",
       "      <td>0.882275</td>\n",
       "      <td>0.326761</td>\n",
       "      <td>0.875256</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>240</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              start              end    duration  round_epochs      loss  \\\n",
       "0   08/25/21-081651  08/25/21-081924  153.606198           200  0.302781   \n",
       "1   08/25/21-081924  08/25/21-082120  115.259690           150  0.307944   \n",
       "2   08/25/21-082120  08/25/21-082243   83.275903           200  0.311683   \n",
       "3   08/25/21-082243  08/25/21-082325   41.615116           100  0.307395   \n",
       "4   08/25/21-082325  08/25/21-082353   28.441410           100  0.313880   \n",
       "5   08/25/21-082353  08/25/21-082632  158.117142           200  0.307058   \n",
       "6   08/25/21-082632  08/25/21-082733   61.686494           150  0.305680   \n",
       "7   08/25/21-082734  08/25/21-082835   61.670819           150  0.306027   \n",
       "8   08/25/21-082835  08/25/21-082936   60.803183           150  0.312962   \n",
       "9   08/25/21-082936  08/25/21-083032   55.865111           200  0.312666   \n",
       "10  08/25/21-083032  08/25/21-083154   81.296361           100  0.306936   \n",
       "11  08/25/21-083154  08/25/21-083354  120.304415           150  0.302856   \n",
       "12  08/25/21-083354  08/25/21-083558  123.467238           150  0.311082   \n",
       "13  08/25/21-083558  08/25/21-083725   86.902818           100  0.312621   \n",
       "14  08/25/21-083725  08/25/21-083755   30.724834           100  0.310513   \n",
       "15  08/25/21-083756  08/25/21-083845   49.236881           150  0.305724   \n",
       "16  08/25/21-083845  08/25/21-083918   32.736044           100  0.316053   \n",
       "17  08/25/21-083918  08/25/21-084136  138.183115           150  0.309381   \n",
       "18  08/25/21-084136  08/25/21-084310   93.361112           200  0.307676   \n",
       "19  08/25/21-084310  08/25/21-084341   31.254015           100  0.315771   \n",
       "20  08/25/21-084341  08/25/21-084428   47.146175           150  0.306852   \n",
       "21  08/25/21-084428  08/25/21-084551   82.704441           100  0.313937   \n",
       "22  08/25/21-084551  08/25/21-084802  131.106751           150  0.305015   \n",
       "23  08/25/21-084803  08/25/21-084851   48.854972           150  0.311012   \n",
       "24  08/25/21-084852  08/25/21-084941   49.755342           150  0.312719   \n",
       "25  08/25/21-084941  08/25/21-085015   33.096976           100  0.315129   \n",
       "26  08/25/21-085015  08/25/21-085103   48.178424           100  0.309661   \n",
       "27  08/25/21-085103  08/25/21-085408  185.516495           200  0.302791   \n",
       "28  08/25/21-085409  08/25/21-085515   66.790987           200  0.301973   \n",
       "29  08/25/21-085516  08/25/21-085633   77.832502           200  0.300183   \n",
       "\n",
       "    accuracy  val_loss  val_accuracy activation  batch_size  dropout  epochs  \\\n",
       "0   0.880432  0.321978      0.874642       relu          10        0     200   \n",
       "1   0.877447  0.318839      0.875871       relu          10        0     150   \n",
       "2   0.876306  0.320095      0.878533       relu          20        0     200   \n",
       "3   0.878852  0.321459      0.875051       relu          20        0     100   \n",
       "4   0.876569  0.316681      0.877509       relu          30        0     100   \n",
       "5   0.876920  0.319329      0.876690       relu          10        0     200   \n",
       "6   0.879203  0.320330      0.877100       relu          20        0     150   \n",
       "7   0.878588  0.322367      0.876690       relu          20        0     150   \n",
       "8   0.876218  0.316674      0.880172       relu          20        0     150   \n",
       "9   0.876920  0.317853      0.878943       relu          30        0     200   \n",
       "10  0.878413  0.318524      0.877304       relu          10        0     100   \n",
       "11  0.881749  0.326593      0.873822       relu          10        0     150   \n",
       "12  0.875165  0.318217      0.878329       relu          10        0     150   \n",
       "13  0.876833  0.317319      0.875666       relu          10        0     100   \n",
       "14  0.877798  0.317304      0.877304       relu          30        0     100   \n",
       "15  0.879203  0.321165      0.875256       relu          30        0     150   \n",
       "16  0.875691  0.316559      0.877304       relu          30        0     100   \n",
       "17  0.877886  0.320149      0.876280       relu          10        0     150   \n",
       "18  0.879027  0.321272      0.874232       relu          20        0     200   \n",
       "19  0.876130  0.317192      0.877509       relu          30        0     100   \n",
       "20  0.878940  0.318208      0.877714       relu          30        0     150   \n",
       "21  0.875867  0.320273      0.878533       relu          10        0     100   \n",
       "22  0.879642  0.322026      0.876690       relu          10        0     150   \n",
       "23  0.876745  0.316683      0.877714       relu          30        0     150   \n",
       "24  0.875165  0.318164      0.875871       relu          30        0     150   \n",
       "25  0.875867  0.316464      0.877714       relu          30        0     100   \n",
       "26  0.877974  0.317882      0.876280       relu          20        0     100   \n",
       "27  0.879905  0.326933      0.876690       relu          10        0     200   \n",
       "28  0.882100  0.320688      0.875461       relu          30        0     200   \n",
       "29  0.882275  0.326761      0.875256       relu          20        0     200   \n",
       "\n",
       "    first_neuron  hidden_layers last_activation               losses optimizer  \n",
       "0            120              2         sigmoid  binary_crossentropy      Adam  \n",
       "1             60              2         sigmoid  binary_crossentropy      Adam  \n",
       "2             30              2         sigmoid  binary_crossentropy     Nadam  \n",
       "3            240              1         sigmoid  binary_crossentropy     Nadam  \n",
       "4             60              1         sigmoid  binary_crossentropy      Adam  \n",
       "5             60              2         sigmoid  binary_crossentropy     Nadam  \n",
       "6            120              1         sigmoid  binary_crossentropy     Nadam  \n",
       "7            120              1         sigmoid  binary_crossentropy      Adam  \n",
       "8             30              2         sigmoid  binary_crossentropy     Nadam  \n",
       "9             30              1         sigmoid  binary_crossentropy     Nadam  \n",
       "10           240              2         sigmoid  binary_crossentropy     Nadam  \n",
       "11           240              2         sigmoid  binary_crossentropy      Adam  \n",
       "12            30              1         sigmoid  binary_crossentropy      Adam  \n",
       "13            60              1         sigmoid  binary_crossentropy     Nadam  \n",
       "14           120              2         sigmoid  binary_crossentropy      Adam  \n",
       "15           240              2         sigmoid  binary_crossentropy      Adam  \n",
       "16            30              1         sigmoid  binary_crossentropy      Adam  \n",
       "17            60              2         sigmoid  binary_crossentropy     Nadam  \n",
       "18            60              1         sigmoid  binary_crossentropy     Nadam  \n",
       "19            30              2         sigmoid  binary_crossentropy      Adam  \n",
       "20           120              2         sigmoid  binary_crossentropy      Adam  \n",
       "21            30              2         sigmoid  binary_crossentropy     Nadam  \n",
       "22           120              2         sigmoid  binary_crossentropy      Adam  \n",
       "23            60              2         sigmoid  binary_crossentropy      Adam  \n",
       "24            30              2         sigmoid  binary_crossentropy     Nadam  \n",
       "25            30              2         sigmoid  binary_crossentropy     Nadam  \n",
       "26           120              1         sigmoid  binary_crossentropy      Adam  \n",
       "27           120              1         sigmoid  binary_crossentropy      Adam  \n",
       "28           240              2         sigmoid  binary_crossentropy      Adam  \n",
       "29           240              1         sigmoid  binary_crossentropy     Nadam  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display a dataframe comapring the results of the different combinations \n",
    "t.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the model with the optimised paramaters \n",
    "\n",
    "p_optimisied = {'first_neuron':30,\n",
    "                'second_neuron':200,\n",
    "                'hidden_layers':2,\n",
    "                'batch_size': 20,\n",
    "                'epochs': 150,\n",
    "                'dropout': 0,\n",
    "                'optimizer': 'Nadam',\n",
    "                'activation':'relu',\n",
    "               }\n",
    "\n",
    "def everest_optimised(x_train, y_train, params):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(params['first_neuron'], input_dim=x_train.shape[1], \n",
    "              activation=params['activation']))\n",
    "    \n",
    "    model.add(Dense(params['second_neuron'], activation=params['activation']))\n",
    " \n",
    "    model.add(Dropout(params['dropout']))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=params['optimizer'], metrics=['accuracy'])\n",
    "    \n",
    "    out = model.fit(x_train, \n",
    "                    y_train,\n",
    "                    epochs=params['epochs'],\n",
    "                    batch_size=params['batch_size'],\n",
    "                    verbose=0)\n",
    "\n",
    "    return out, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-fit the training data to the model\n",
    "out, model = everest_optimised(X_train_scaled, encoded_y_train, p_optimisied)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 - 0s - loss: 0.3169 - accuracy: 0.8782\n",
      "Neural Network Performace - Loss: 0.31689390540122986, Accuracy: 0.8781566619873047\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(X_test_scaled, encoded_y_test, verbose=2)\n",
    "print(f\"Neural Network Performace - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "filename = 'success_model.h5'\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(\"success_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "dev"
  },
  "kernelspec": {
   "display_name": "Python [conda env:PythonData] *",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
