{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "df = pd.read_csv(\"../crowding_data.csv\", low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'expid', 'membid', 'myear', 'sex', 'calcage', 'citizen', 'status',\n",
       "       'msolo', 'msuccess', 'msmtdate1', 'msmtdate2', 'msmtdate3', 'route1',\n",
       "       'route2', 'route3', 'route4', 'mo2used', 'mo2none', 'mo2climb',\n",
       "       'mo2descent', 'mo2sleep', 'death', 'deathdate', 'msmtbid', 'stdrte',\n",
       "       'new_route', 'new_status', 'climber_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View column names and drop unnecesary columns for the model \n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set features\n",
    "feature_names = ['sex', 'calcage', 'citizen', 'new_route', 'mo2used', 'mo2climb',\n",
    "                 'mo2descent', 'mo2sleep', 'stdrte', 'new_status', 'climber_count']\n",
    "\n",
    "X = df[feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>calcage</th>\n",
       "      <th>citizen</th>\n",
       "      <th>new_route</th>\n",
       "      <th>mo2used</th>\n",
       "      <th>mo2climb</th>\n",
       "      <th>mo2descent</th>\n",
       "      <th>mo2sleep</th>\n",
       "      <th>stdrte</th>\n",
       "      <th>new_status</th>\n",
       "      <th>climber_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>82</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>82</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15003</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15004</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15005</th>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15006</th>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15007</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15008 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sex  calcage  citizen  new_route  mo2used  mo2climb  mo2descent  \\\n",
       "0        0       32       15          2      1.0       1.0         0.0   \n",
       "1        0       40       82          2      0.0       0.0         0.0   \n",
       "2        0       29       82          2      1.0       1.0         0.0   \n",
       "3        0       37       82          1      0.0       0.0         0.0   \n",
       "4        0       33       82          1      0.0       0.0         0.0   \n",
       "...    ...      ...      ...        ...      ...       ...         ...   \n",
       "15003    1       16       27          0      1.0       1.0         0.0   \n",
       "15004    0       37       27          0      1.0       1.0         0.0   \n",
       "15005    0       57       27          0      1.0       1.0         0.0   \n",
       "15006    0       35       27          0      1.0       1.0         0.0   \n",
       "15007    0       37       27          0      1.0       1.0         0.0   \n",
       "\n",
       "       mo2sleep  stdrte  new_status  climber_count  \n",
       "0           1.0     1.0           2            3.0  \n",
       "1           0.0     1.0           2            3.0  \n",
       "2           1.0     1.0           2            3.0  \n",
       "3           0.0     0.0           1            3.0  \n",
       "4           0.0     0.0           1            3.0  \n",
       "...         ...     ...         ...            ...  \n",
       "15003       1.0     1.0           0           15.0  \n",
       "15004       1.0     1.0           0           15.0  \n",
       "15005       1.0     1.0           0           15.0  \n",
       "15006       1.0     1.0           0           15.0  \n",
       "15007       1.0     1.0           0           15.0  \n",
       "\n",
       "[15008 rows x 11 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert X values to numerical \n",
    "\n",
    "###                KEY                  ### \n",
    "###        Male = 0, Female = 1         ###\n",
    "###        True = 1, False = 0          ###\n",
    "###  Citizen and Route = see label map  ###\n",
    "\n",
    "X.replace(True, 1, inplace=True)\n",
    "X['sex'] = pd.get_dummies(X['sex'])\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "# Perform label transformation and create label maps for later use \n",
    "X['citizen'] = le.fit_transform(X['citizen'])\n",
    "country_label_map = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "X['new_route'] = le.fit_transform(X['new_route'])\n",
    "route_label_map = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "X['new_status'] = le.fit_transform(X['new_route'])\n",
    "status_label_map = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_names = df['msuccess'].unique()\n",
    "target_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y  = df['msuccess']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Train Test Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "Scale the data using the MinMaxScaler and perform some feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create the scaler\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "\n",
    "# Transform the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['crowding_scaler.pkl']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the scaler for later use\n",
    "import joblib \n",
    "\n",
    "filename = 'crowding_scaler.pkl'\n",
    "joblib.dump(X_scaler, filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the y values to numerical using label_encoder/to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)\n",
    "y_test_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and initial trial model and add layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "inputs = X_train.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=60, activation='relu', input_dim=inputs))\n",
    "model.add(Dense(units=200, activation='relu'))\n",
    "model.add(Dense(units=2, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 60)                720       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 200)               12200     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 2)                 402       \n",
      "=================================================================\n",
      "Total params: 13,322\n",
      "Trainable params: 13,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "352/352 - 1s - loss: 0.4414 - accuracy: 0.8151\n",
      "Epoch 2/100\n",
      "352/352 - 0s - loss: 0.4092 - accuracy: 0.8340\n",
      "Epoch 3/100\n",
      "352/352 - 0s - loss: 0.4080 - accuracy: 0.8344\n",
      "Epoch 4/100\n",
      "352/352 - 0s - loss: 0.4053 - accuracy: 0.8358\n",
      "Epoch 5/100\n",
      "352/352 - 0s - loss: 0.4033 - accuracy: 0.8348\n",
      "Epoch 6/100\n",
      "352/352 - 0s - loss: 0.4010 - accuracy: 0.8365\n",
      "Epoch 7/100\n",
      "352/352 - 0s - loss: 0.3994 - accuracy: 0.8373\n",
      "Epoch 8/100\n",
      "352/352 - 0s - loss: 0.4008 - accuracy: 0.8356\n",
      "Epoch 9/100\n",
      "352/352 - 0s - loss: 0.3978 - accuracy: 0.8386\n",
      "Epoch 10/100\n",
      "352/352 - 0s - loss: 0.3977 - accuracy: 0.8370\n",
      "Epoch 11/100\n",
      "352/352 - 0s - loss: 0.3991 - accuracy: 0.8369\n",
      "Epoch 12/100\n",
      "352/352 - 0s - loss: 0.3954 - accuracy: 0.8392\n",
      "Epoch 13/100\n",
      "352/352 - 0s - loss: 0.3960 - accuracy: 0.8380\n",
      "Epoch 14/100\n",
      "352/352 - 0s - loss: 0.3963 - accuracy: 0.8390\n",
      "Epoch 15/100\n",
      "352/352 - 0s - loss: 0.3945 - accuracy: 0.8404\n",
      "Epoch 16/100\n",
      "352/352 - 0s - loss: 0.3943 - accuracy: 0.8386\n",
      "Epoch 17/100\n",
      "352/352 - 0s - loss: 0.3960 - accuracy: 0.8372\n",
      "Epoch 18/100\n",
      "352/352 - 0s - loss: 0.3936 - accuracy: 0.8402\n",
      "Epoch 19/100\n",
      "352/352 - 0s - loss: 0.3921 - accuracy: 0.8406\n",
      "Epoch 20/100\n",
      "352/352 - 0s - loss: 0.3922 - accuracy: 0.8412\n",
      "Epoch 21/100\n",
      "352/352 - 0s - loss: 0.3908 - accuracy: 0.8401\n",
      "Epoch 22/100\n",
      "352/352 - 0s - loss: 0.3909 - accuracy: 0.8412\n",
      "Epoch 23/100\n",
      "352/352 - 0s - loss: 0.3912 - accuracy: 0.8413\n",
      "Epoch 24/100\n",
      "352/352 - 0s - loss: 0.3914 - accuracy: 0.8418\n",
      "Epoch 25/100\n",
      "352/352 - 0s - loss: 0.3892 - accuracy: 0.8424\n",
      "Epoch 26/100\n",
      "352/352 - 0s - loss: 0.3893 - accuracy: 0.8396\n",
      "Epoch 27/100\n",
      "352/352 - 0s - loss: 0.3892 - accuracy: 0.8422\n",
      "Epoch 28/100\n",
      "352/352 - 0s - loss: 0.3887 - accuracy: 0.8429\n",
      "Epoch 29/100\n",
      "352/352 - 0s - loss: 0.3896 - accuracy: 0.8412\n",
      "Epoch 30/100\n",
      "352/352 - 0s - loss: 0.3872 - accuracy: 0.8425\n",
      "Epoch 31/100\n",
      "352/352 - 0s - loss: 0.3874 - accuracy: 0.8429\n",
      "Epoch 32/100\n",
      "352/352 - 0s - loss: 0.3869 - accuracy: 0.8422\n",
      "Epoch 33/100\n",
      "352/352 - 0s - loss: 0.3857 - accuracy: 0.8432\n",
      "Epoch 34/100\n",
      "352/352 - 0s - loss: 0.3868 - accuracy: 0.8428\n",
      "Epoch 35/100\n",
      "352/352 - 0s - loss: 0.3848 - accuracy: 0.8440\n",
      "Epoch 36/100\n",
      "352/352 - 0s - loss: 0.3846 - accuracy: 0.8431\n",
      "Epoch 37/100\n",
      "352/352 - 0s - loss: 0.3838 - accuracy: 0.8443\n",
      "Epoch 38/100\n",
      "352/352 - 0s - loss: 0.3835 - accuracy: 0.8429\n",
      "Epoch 39/100\n",
      "352/352 - 0s - loss: 0.3830 - accuracy: 0.8431\n",
      "Epoch 40/100\n",
      "352/352 - 0s - loss: 0.3818 - accuracy: 0.8459\n",
      "Epoch 41/100\n",
      "352/352 - 0s - loss: 0.3822 - accuracy: 0.8439\n",
      "Epoch 42/100\n",
      "352/352 - 0s - loss: 0.3834 - accuracy: 0.8451\n",
      "Epoch 43/100\n",
      "352/352 - 0s - loss: 0.3815 - accuracy: 0.8451\n",
      "Epoch 44/100\n",
      "352/352 - 0s - loss: 0.3806 - accuracy: 0.8480\n",
      "Epoch 45/100\n",
      "352/352 - 0s - loss: 0.3816 - accuracy: 0.8461\n",
      "Epoch 46/100\n",
      "352/352 - 0s - loss: 0.3797 - accuracy: 0.8466\n",
      "Epoch 47/100\n",
      "352/352 - 0s - loss: 0.3802 - accuracy: 0.8455\n",
      "Epoch 48/100\n",
      "352/352 - 0s - loss: 0.3796 - accuracy: 0.8467\n",
      "Epoch 49/100\n",
      "352/352 - 0s - loss: 0.3787 - accuracy: 0.8476\n",
      "Epoch 50/100\n",
      "352/352 - 0s - loss: 0.3790 - accuracy: 0.8466\n",
      "Epoch 51/100\n",
      "352/352 - 0s - loss: 0.3788 - accuracy: 0.8480\n",
      "Epoch 52/100\n",
      "352/352 - 0s - loss: 0.3781 - accuracy: 0.8467\n",
      "Epoch 53/100\n",
      "352/352 - 0s - loss: 0.3778 - accuracy: 0.8472\n",
      "Epoch 54/100\n",
      "352/352 - 0s - loss: 0.3778 - accuracy: 0.8480\n",
      "Epoch 55/100\n",
      "352/352 - 0s - loss: 0.3770 - accuracy: 0.8475\n",
      "Epoch 56/100\n",
      "352/352 - 0s - loss: 0.3761 - accuracy: 0.8489\n",
      "Epoch 57/100\n",
      "352/352 - 0s - loss: 0.3753 - accuracy: 0.8482\n",
      "Epoch 58/100\n",
      "352/352 - 0s - loss: 0.3761 - accuracy: 0.8468\n",
      "Epoch 59/100\n",
      "352/352 - 0s - loss: 0.3756 - accuracy: 0.8491\n",
      "Epoch 60/100\n",
      "352/352 - 0s - loss: 0.3744 - accuracy: 0.8492\n",
      "Epoch 61/100\n",
      "352/352 - 0s - loss: 0.3750 - accuracy: 0.8491\n",
      "Epoch 62/100\n",
      "352/352 - 0s - loss: 0.3742 - accuracy: 0.8493\n",
      "Epoch 63/100\n",
      "352/352 - 0s - loss: 0.3736 - accuracy: 0.8483\n",
      "Epoch 64/100\n",
      "352/352 - 0s - loss: 0.3733 - accuracy: 0.8498\n",
      "Epoch 65/100\n",
      "352/352 - 0s - loss: 0.3736 - accuracy: 0.8497\n",
      "Epoch 66/100\n",
      "352/352 - 0s - loss: 0.3727 - accuracy: 0.8501\n",
      "Epoch 67/100\n",
      "352/352 - 0s - loss: 0.3721 - accuracy: 0.8487\n",
      "Epoch 68/100\n",
      "352/352 - 0s - loss: 0.3709 - accuracy: 0.8503\n",
      "Epoch 69/100\n",
      "352/352 - 0s - loss: 0.3719 - accuracy: 0.8498\n",
      "Epoch 70/100\n",
      "352/352 - 0s - loss: 0.3718 - accuracy: 0.8501\n",
      "Epoch 71/100\n",
      "352/352 - 0s - loss: 0.3710 - accuracy: 0.8491\n",
      "Epoch 72/100\n",
      "352/352 - 0s - loss: 0.3716 - accuracy: 0.8507\n",
      "Epoch 73/100\n",
      "352/352 - 0s - loss: 0.3705 - accuracy: 0.8492\n",
      "Epoch 74/100\n",
      "352/352 - 0s - loss: 0.3697 - accuracy: 0.8524\n",
      "Epoch 75/100\n",
      "352/352 - 0s - loss: 0.3695 - accuracy: 0.8512\n",
      "Epoch 76/100\n",
      "352/352 - 0s - loss: 0.3713 - accuracy: 0.8498\n",
      "Epoch 77/100\n",
      "352/352 - 0s - loss: 0.3682 - accuracy: 0.8530\n",
      "Epoch 78/100\n",
      "352/352 - 0s - loss: 0.3681 - accuracy: 0.8523\n",
      "Epoch 79/100\n",
      "352/352 - 0s - loss: 0.3675 - accuracy: 0.8536\n",
      "Epoch 80/100\n",
      "352/352 - 0s - loss: 0.3683 - accuracy: 0.8515\n",
      "Epoch 81/100\n",
      "352/352 - 0s - loss: 0.3669 - accuracy: 0.8499\n",
      "Epoch 82/100\n",
      "352/352 - 0s - loss: 0.3679 - accuracy: 0.8521\n",
      "Epoch 83/100\n",
      "352/352 - 0s - loss: 0.3680 - accuracy: 0.8503\n",
      "Epoch 84/100\n",
      "352/352 - 0s - loss: 0.3652 - accuracy: 0.8537\n",
      "Epoch 85/100\n",
      "352/352 - 0s - loss: 0.3663 - accuracy: 0.8516\n",
      "Epoch 86/100\n",
      "352/352 - 0s - loss: 0.3651 - accuracy: 0.8523\n",
      "Epoch 87/100\n",
      "352/352 - 0s - loss: 0.3656 - accuracy: 0.8514\n",
      "Epoch 88/100\n",
      "352/352 - 0s - loss: 0.3646 - accuracy: 0.8552\n",
      "Epoch 89/100\n",
      "352/352 - 0s - loss: 0.3649 - accuracy: 0.8531\n",
      "Epoch 90/100\n",
      "352/352 - 0s - loss: 0.3649 - accuracy: 0.8533\n",
      "Epoch 91/100\n",
      "352/352 - 0s - loss: 0.3662 - accuracy: 0.8522\n",
      "Epoch 92/100\n",
      "352/352 - 0s - loss: 0.3621 - accuracy: 0.8556\n",
      "Epoch 93/100\n",
      "352/352 - 0s - loss: 0.3632 - accuracy: 0.8544\n",
      "Epoch 94/100\n",
      "352/352 - 0s - loss: 0.3628 - accuracy: 0.8539\n",
      "Epoch 95/100\n",
      "352/352 - 0s - loss: 0.3626 - accuracy: 0.8539\n",
      "Epoch 96/100\n",
      "352/352 - 0s - loss: 0.3622 - accuracy: 0.8529\n",
      "Epoch 97/100\n",
      "352/352 - 0s - loss: 0.3618 - accuracy: 0.8559\n",
      "Epoch 98/100\n",
      "352/352 - 0s - loss: 0.3620 - accuracy: 0.8551\n",
      "Epoch 99/100\n",
      "352/352 - 0s - loss: 0.3614 - accuracy: 0.8550\n",
      "Epoch 100/100\n",
      "352/352 - 0s - loss: 0.3609 - accuracy: 0.8543\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16e93e7a470>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    verbose=2,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantify Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 - 0s - loss: 0.3844 - accuracy: 0.8462\n",
      "Neural Network Performace - Loss: 0.38435932993888855, Accuracy: 0.8462153673171997\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(f\"Neural Network Performace - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chance of success for datapoint 50 is: 71.57%\n",
      "\n",
      "With crowding model the chance of success is: 95.38%\n"
     ]
    }
   ],
   "source": [
    "# Print some test data to try out the preduction model \n",
    "from tensorflow.keras.models import load_model\n",
    "success_model = load_model(\"success_model.h5\")\n",
    "\n",
    "test_values2 = X_train_scaled[50].tolist()\n",
    "test_values1 = test_values2[:-1]\n",
    "result1 = success_model.predict([test_values1])\n",
    "print(f\"Chance of success for datapoint 50 is: {round(result1[0][0]*100,2)}%\")\n",
    "\n",
    "result2 = model.predict([test_values2])\n",
    "print(\"\")\n",
    "print(f\"With crowding model the chance of success is: {round(result2[0][1]*100,2)}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 540x540 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a confusion matrix to visualise the performance \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "predictions = np.argmax(model.predict(X_test_scaled), axis=-1)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true=encoded_y_test, y_pred=predictions)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
    "\n",
    "ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)\n",
    "\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        ax.text(x=j, y=i, s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
    "\n",
    "plt.title('Confusion Matrix', fontsize=18)\n",
    "plt.xlabel('Predictions', fontsize=18)\n",
    "ax.set_xticks([0,1])\n",
    "ax.set_xticklabels(target_names)\n",
    "plt.ylabel('Actuals', fontsize=18)\n",
    "ax.set_yticks([0,1])\n",
    "ax.set_yticklabels(target_names)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperperameter tuning\n",
    "\n",
    "#### Talos Custom Hyperparameter Optimiser for Keras, Tensorflow used \n",
    "Availble from: <a href=\"https://github.com/autonomio/talos/\">https://github.com/autonomio/talos/</a>\n",
    "<img src=\"https://raw.githubusercontent.com/autonomio/talos/master/logo.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import talos\n",
    "\n",
    "# Function to run the model \n",
    "def everest(x_train, y_train, x_val, y_val, params):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(params['first_neuron'], input_dim=x_train.shape[1], \n",
    "              activation=params['activation']))\n",
    " \n",
    "    model.add(Dropout(params['dropout']))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=params['optimizer'], metrics=['accuracy'])\n",
    "    \n",
    "    out = model.fit(x_train, \n",
    "                    y_train,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    epochs=params['epochs'],\n",
    "                    batch_size=params['batch_size'],\n",
    "                    verbose=0)\n",
    "    \n",
    "    return out, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a parameter dictionary\n",
    "p = {'first_neuron':[30,60,120,240],\n",
    "    'hidden_layers':[1, 2],\n",
    "    'batch_size': [10,20, 30],\n",
    "    'epochs': [100, 150, 200],\n",
    "    'dropout': [0],\n",
    "    'optimizer': ['Nadam', 'Adam'],\n",
    "    'losses': ['binary_crossentropy'],\n",
    "    'activation':['relu'],\n",
    "    'last_activation': ['sigmoid']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [29:53<00:00, 59.78s/it]\n"
     ]
    }
   ],
   "source": [
    "t = talos.Scan(x=X_train_scaled, y=encoded_y_train, params=p, model=everest, experiment_name='everest_tune', round_limit=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "experiment_name            everest_tune\n",
       "random_method          uniform_mersenne\n",
       "reduction_method                   None\n",
       "reduction_interval                   50\n",
       "reduction_window                     20\n",
       "reduction_threshold                 0.2\n",
       "reduction_metric                val_acc\n",
       "complete_time            08/25/21/07:08\n",
       "x_shape                     (11256, 12)\n",
       "y_shape                        (11256,)\n",
       "dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best parameters:  \n",
    "  \n",
    "(as per table below)  \n",
    "first layer: 30  \n",
    "hidden layers: 1  \n",
    "activation: relu  \n",
    "batch_size: 30  \n",
    "epochs: 200  \n",
    "dropout: 0  \n",
    "optimizer: Nadam  \n",
    "<b>accuracy:</b> 85.40% \n",
    "<b>loss:</b> 0.384203\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>duration</th>\n",
       "      <th>round_epochs</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>activation</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>dropout</th>\n",
       "      <th>epochs</th>\n",
       "      <th>first_neuron</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>last_activation</th>\n",
       "      <th>losses</th>\n",
       "      <th>optimizer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>08/24/21-230705</td>\n",
       "      <td>08/24/21-230803</td>\n",
       "      <td>57.759185</td>\n",
       "      <td>200</td>\n",
       "      <td>0.388966</td>\n",
       "      <td>0.839827</td>\n",
       "      <td>0.384203</td>\n",
       "      <td>0.854012</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>08/24/21-230803</td>\n",
       "      <td>08/24/21-231044</td>\n",
       "      <td>161.200146</td>\n",
       "      <td>200</td>\n",
       "      <td>0.376175</td>\n",
       "      <td>0.847569</td>\n",
       "      <td>0.389589</td>\n",
       "      <td>0.846609</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>08/24/21-231044</td>\n",
       "      <td>08/24/21-231127</td>\n",
       "      <td>42.301092</td>\n",
       "      <td>100</td>\n",
       "      <td>0.380480</td>\n",
       "      <td>0.845666</td>\n",
       "      <td>0.386948</td>\n",
       "      <td>0.847794</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>240</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>08/24/21-231127</td>\n",
       "      <td>08/24/21-231210</td>\n",
       "      <td>43.669270</td>\n",
       "      <td>150</td>\n",
       "      <td>0.387740</td>\n",
       "      <td>0.842747</td>\n",
       "      <td>0.385565</td>\n",
       "      <td>0.847498</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08/24/21-231211</td>\n",
       "      <td>08/24/21-231253</td>\n",
       "      <td>42.230203</td>\n",
       "      <td>100</td>\n",
       "      <td>0.387910</td>\n",
       "      <td>0.842620</td>\n",
       "      <td>0.386112</td>\n",
       "      <td>0.846906</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>08/24/21-231253</td>\n",
       "      <td>08/24/21-231322</td>\n",
       "      <td>28.739540</td>\n",
       "      <td>100</td>\n",
       "      <td>0.395750</td>\n",
       "      <td>0.838431</td>\n",
       "      <td>0.389195</td>\n",
       "      <td>0.844240</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>08/24/21-231322</td>\n",
       "      <td>08/24/21-231443</td>\n",
       "      <td>81.024342</td>\n",
       "      <td>100</td>\n",
       "      <td>0.380030</td>\n",
       "      <td>0.845920</td>\n",
       "      <td>0.389505</td>\n",
       "      <td>0.846017</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>08/24/21-231443</td>\n",
       "      <td>08/24/21-231607</td>\n",
       "      <td>84.355661</td>\n",
       "      <td>200</td>\n",
       "      <td>0.379817</td>\n",
       "      <td>0.845158</td>\n",
       "      <td>0.385439</td>\n",
       "      <td>0.849275</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>08/24/21-231608</td>\n",
       "      <td>08/24/21-231650</td>\n",
       "      <td>42.228505</td>\n",
       "      <td>100</td>\n",
       "      <td>0.390933</td>\n",
       "      <td>0.838812</td>\n",
       "      <td>0.384830</td>\n",
       "      <td>0.846609</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>08/24/21-231650</td>\n",
       "      <td>08/24/21-231816</td>\n",
       "      <td>85.573669</td>\n",
       "      <td>200</td>\n",
       "      <td>0.369190</td>\n",
       "      <td>0.849981</td>\n",
       "      <td>0.390682</td>\n",
       "      <td>0.847498</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>240</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>08/24/21-231816</td>\n",
       "      <td>08/24/21-232028</td>\n",
       "      <td>132.444658</td>\n",
       "      <td>150</td>\n",
       "      <td>0.383956</td>\n",
       "      <td>0.842620</td>\n",
       "      <td>0.390337</td>\n",
       "      <td>0.843352</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>08/24/21-232028</td>\n",
       "      <td>08/24/21-232154</td>\n",
       "      <td>85.758805</td>\n",
       "      <td>100</td>\n",
       "      <td>0.375592</td>\n",
       "      <td>0.848966</td>\n",
       "      <td>0.391175</td>\n",
       "      <td>0.846313</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>240</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>08/24/21-232154</td>\n",
       "      <td>08/24/21-232257</td>\n",
       "      <td>63.016487</td>\n",
       "      <td>150</td>\n",
       "      <td>0.378298</td>\n",
       "      <td>0.846554</td>\n",
       "      <td>0.392641</td>\n",
       "      <td>0.849571</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>120</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>08/24/21-232257</td>\n",
       "      <td>08/24/21-232341</td>\n",
       "      <td>43.591939</td>\n",
       "      <td>150</td>\n",
       "      <td>0.379819</td>\n",
       "      <td>0.845666</td>\n",
       "      <td>0.390331</td>\n",
       "      <td>0.843944</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>08/24/21-232341</td>\n",
       "      <td>08/24/21-232538</td>\n",
       "      <td>116.590720</td>\n",
       "      <td>150</td>\n",
       "      <td>0.384522</td>\n",
       "      <td>0.841604</td>\n",
       "      <td>0.387361</td>\n",
       "      <td>0.849867</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>08/24/21-232538</td>\n",
       "      <td>08/24/21-232700</td>\n",
       "      <td>82.414135</td>\n",
       "      <td>200</td>\n",
       "      <td>0.381302</td>\n",
       "      <td>0.846808</td>\n",
       "      <td>0.385183</td>\n",
       "      <td>0.847794</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>08/24/21-232700</td>\n",
       "      <td>08/24/21-232759</td>\n",
       "      <td>58.323823</td>\n",
       "      <td>200</td>\n",
       "      <td>0.374489</td>\n",
       "      <td>0.848966</td>\n",
       "      <td>0.397207</td>\n",
       "      <td>0.843648</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>120</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>08/24/21-232759</td>\n",
       "      <td>08/24/21-233041</td>\n",
       "      <td>162.447369</td>\n",
       "      <td>200</td>\n",
       "      <td>0.375298</td>\n",
       "      <td>0.846300</td>\n",
       "      <td>0.385911</td>\n",
       "      <td>0.850459</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>08/24/21-233042</td>\n",
       "      <td>08/24/21-233143</td>\n",
       "      <td>61.464201</td>\n",
       "      <td>150</td>\n",
       "      <td>0.387760</td>\n",
       "      <td>0.843635</td>\n",
       "      <td>0.385589</td>\n",
       "      <td>0.852236</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>08/24/21-233143</td>\n",
       "      <td>08/24/21-233302</td>\n",
       "      <td>78.838834</td>\n",
       "      <td>100</td>\n",
       "      <td>0.389535</td>\n",
       "      <td>0.840716</td>\n",
       "      <td>0.385909</td>\n",
       "      <td>0.847498</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>08/24/21-233302</td>\n",
       "      <td>08/24/21-233344</td>\n",
       "      <td>41.687417</td>\n",
       "      <td>100</td>\n",
       "      <td>0.383186</td>\n",
       "      <td>0.842493</td>\n",
       "      <td>0.385868</td>\n",
       "      <td>0.848090</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>120</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>08/24/21-233344</td>\n",
       "      <td>08/24/21-233413</td>\n",
       "      <td>29.505259</td>\n",
       "      <td>100</td>\n",
       "      <td>0.385264</td>\n",
       "      <td>0.841097</td>\n",
       "      <td>0.384028</td>\n",
       "      <td>0.851940</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>08/24/21-233414</td>\n",
       "      <td>08/24/21-233455</td>\n",
       "      <td>41.268531</td>\n",
       "      <td>100</td>\n",
       "      <td>0.389535</td>\n",
       "      <td>0.842873</td>\n",
       "      <td>0.384488</td>\n",
       "      <td>0.848386</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>08/24/21-233455</td>\n",
       "      <td>08/24/21-233552</td>\n",
       "      <td>57.019354</td>\n",
       "      <td>200</td>\n",
       "      <td>0.373516</td>\n",
       "      <td>0.849854</td>\n",
       "      <td>0.390962</td>\n",
       "      <td>0.849571</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>08/24/21-233552</td>\n",
       "      <td>08/24/21-233623</td>\n",
       "      <td>30.226746</td>\n",
       "      <td>100</td>\n",
       "      <td>0.380398</td>\n",
       "      <td>0.846173</td>\n",
       "      <td>0.389864</td>\n",
       "      <td>0.843648</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>240</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>08/24/21-233623</td>\n",
       "      <td>08/25/21-023824</td>\n",
       "      <td>10921.443959</td>\n",
       "      <td>150</td>\n",
       "      <td>0.379851</td>\n",
       "      <td>0.843000</td>\n",
       "      <td>0.382705</td>\n",
       "      <td>0.850163</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>08/25/21-023825</td>\n",
       "      <td>08/25/21-070602</td>\n",
       "      <td>16057.611233</td>\n",
       "      <td>100</td>\n",
       "      <td>0.393344</td>\n",
       "      <td>0.839066</td>\n",
       "      <td>0.396399</td>\n",
       "      <td>0.841575</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>08/25/21-070602</td>\n",
       "      <td>08/25/21-070719</td>\n",
       "      <td>76.477196</td>\n",
       "      <td>100</td>\n",
       "      <td>0.383703</td>\n",
       "      <td>0.843762</td>\n",
       "      <td>0.384225</td>\n",
       "      <td>0.848386</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>08/25/21-070719</td>\n",
       "      <td>08/25/21-070759</td>\n",
       "      <td>39.527877</td>\n",
       "      <td>150</td>\n",
       "      <td>0.384848</td>\n",
       "      <td>0.843381</td>\n",
       "      <td>0.384968</td>\n",
       "      <td>0.846906</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>08/25/21-070759</td>\n",
       "      <td>08/25/21-070855</td>\n",
       "      <td>56.519375</td>\n",
       "      <td>200</td>\n",
       "      <td>0.379917</td>\n",
       "      <td>0.845285</td>\n",
       "      <td>0.385437</td>\n",
       "      <td>0.847498</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              start              end      duration  round_epochs      loss  \\\n",
       "0   08/24/21-230705  08/24/21-230803     57.759185           200  0.388966   \n",
       "1   08/24/21-230803  08/24/21-231044    161.200146           200  0.376175   \n",
       "2   08/24/21-231044  08/24/21-231127     42.301092           100  0.380480   \n",
       "3   08/24/21-231127  08/24/21-231210     43.669270           150  0.387740   \n",
       "4   08/24/21-231211  08/24/21-231253     42.230203           100  0.387910   \n",
       "5   08/24/21-231253  08/24/21-231322     28.739540           100  0.395750   \n",
       "6   08/24/21-231322  08/24/21-231443     81.024342           100  0.380030   \n",
       "7   08/24/21-231443  08/24/21-231607     84.355661           200  0.379817   \n",
       "8   08/24/21-231608  08/24/21-231650     42.228505           100  0.390933   \n",
       "9   08/24/21-231650  08/24/21-231816     85.573669           200  0.369190   \n",
       "10  08/24/21-231816  08/24/21-232028    132.444658           150  0.383956   \n",
       "11  08/24/21-232028  08/24/21-232154     85.758805           100  0.375592   \n",
       "12  08/24/21-232154  08/24/21-232257     63.016487           150  0.378298   \n",
       "13  08/24/21-232257  08/24/21-232341     43.591939           150  0.379819   \n",
       "14  08/24/21-232341  08/24/21-232538    116.590720           150  0.384522   \n",
       "15  08/24/21-232538  08/24/21-232700     82.414135           200  0.381302   \n",
       "16  08/24/21-232700  08/24/21-232759     58.323823           200  0.374489   \n",
       "17  08/24/21-232759  08/24/21-233041    162.447369           200  0.375298   \n",
       "18  08/24/21-233042  08/24/21-233143     61.464201           150  0.387760   \n",
       "19  08/24/21-233143  08/24/21-233302     78.838834           100  0.389535   \n",
       "20  08/24/21-233302  08/24/21-233344     41.687417           100  0.383186   \n",
       "21  08/24/21-233344  08/24/21-233413     29.505259           100  0.385264   \n",
       "22  08/24/21-233414  08/24/21-233455     41.268531           100  0.389535   \n",
       "23  08/24/21-233455  08/24/21-233552     57.019354           200  0.373516   \n",
       "24  08/24/21-233552  08/24/21-233623     30.226746           100  0.380398   \n",
       "25  08/24/21-233623  08/25/21-023824  10921.443959           150  0.379851   \n",
       "26  08/25/21-023825  08/25/21-070602  16057.611233           100  0.393344   \n",
       "27  08/25/21-070602  08/25/21-070719     76.477196           100  0.383703   \n",
       "28  08/25/21-070719  08/25/21-070759     39.527877           150  0.384848   \n",
       "29  08/25/21-070759  08/25/21-070855     56.519375           200  0.379917   \n",
       "\n",
       "    accuracy  val_loss  val_accuracy activation  batch_size  dropout  epochs  \\\n",
       "0   0.839827  0.384203      0.854012       relu          30        0     200   \n",
       "1   0.847569  0.389589      0.846609       relu          10        0     200   \n",
       "2   0.845666  0.386948      0.847794       relu          20        0     100   \n",
       "3   0.842747  0.385565      0.847498       relu          30        0     150   \n",
       "4   0.842620  0.386112      0.846906       relu          20        0     100   \n",
       "5   0.838431  0.389195      0.844240       relu          30        0     100   \n",
       "6   0.845920  0.389505      0.846017       relu          10        0     100   \n",
       "7   0.845158  0.385439      0.849275       relu          20        0     200   \n",
       "8   0.838812  0.384830      0.846609       relu          20        0     100   \n",
       "9   0.849981  0.390682      0.847498       relu          20        0     200   \n",
       "10  0.842620  0.390337      0.843352       relu          10        0     150   \n",
       "11  0.848966  0.391175      0.846313       relu          10        0     100   \n",
       "12  0.846554  0.392641      0.849571       relu          20        0     150   \n",
       "13  0.845666  0.390331      0.843944       relu          30        0     150   \n",
       "14  0.841604  0.387361      0.849867       relu          10        0     150   \n",
       "15  0.846808  0.385183      0.847794       relu          20        0     200   \n",
       "16  0.848966  0.397207      0.843648       relu          30        0     200   \n",
       "17  0.846300  0.385911      0.850459       relu          10        0     200   \n",
       "18  0.843635  0.385589      0.852236       relu          20        0     150   \n",
       "19  0.840716  0.385909      0.847498       relu          10        0     100   \n",
       "20  0.842493  0.385868      0.848090       relu          20        0     100   \n",
       "21  0.841097  0.384028      0.851940       relu          30        0     100   \n",
       "22  0.842873  0.384488      0.848386       relu          20        0     100   \n",
       "23  0.849854  0.390962      0.849571       relu          30        0     200   \n",
       "24  0.846173  0.389864      0.843648       relu          30        0     100   \n",
       "25  0.843000  0.382705      0.850163       relu          10        0     150   \n",
       "26  0.839066  0.396399      0.841575       relu          30        0     100   \n",
       "27  0.843762  0.384225      0.848386       relu          10        0     100   \n",
       "28  0.843381  0.384968      0.846906       relu          30        0     150   \n",
       "29  0.845285  0.385437      0.847498       relu          30        0     200   \n",
       "\n",
       "    first_neuron  hidden_layers last_activation               losses optimizer  \n",
       "0             30              1         sigmoid  binary_crossentropy     Nadam  \n",
       "1             60              2         sigmoid  binary_crossentropy     Nadam  \n",
       "2            240              2         sigmoid  binary_crossentropy     Nadam  \n",
       "3             30              2         sigmoid  binary_crossentropy      Adam  \n",
       "4             60              1         sigmoid  binary_crossentropy     Nadam  \n",
       "5             30              2         sigmoid  binary_crossentropy     Nadam  \n",
       "6            120              1         sigmoid  binary_crossentropy     Nadam  \n",
       "7             60              2         sigmoid  binary_crossentropy     Nadam  \n",
       "8             30              2         sigmoid  binary_crossentropy      Adam  \n",
       "9            240              1         sigmoid  binary_crossentropy     Nadam  \n",
       "10            30              1         sigmoid  binary_crossentropy     Nadam  \n",
       "11           240              2         sigmoid  binary_crossentropy      Adam  \n",
       "12           120              2         sigmoid  binary_crossentropy      Adam  \n",
       "13           120              1         sigmoid  binary_crossentropy      Adam  \n",
       "14            30              2         sigmoid  binary_crossentropy     Nadam  \n",
       "15            60              1         sigmoid  binary_crossentropy      Adam  \n",
       "16           120              2         sigmoid  binary_crossentropy      Adam  \n",
       "17            60              1         sigmoid  binary_crossentropy      Adam  \n",
       "18            30              2         sigmoid  binary_crossentropy     Nadam  \n",
       "19            30              1         sigmoid  binary_crossentropy     Nadam  \n",
       "20           120              2         sigmoid  binary_crossentropy     Nadam  \n",
       "21           120              1         sigmoid  binary_crossentropy     Nadam  \n",
       "22            30              2         sigmoid  binary_crossentropy     Nadam  \n",
       "23           120              1         sigmoid  binary_crossentropy     Nadam  \n",
       "24           240              2         sigmoid  binary_crossentropy     Nadam  \n",
       "25            60              1         sigmoid  binary_crossentropy      Adam  \n",
       "26            30              1         sigmoid  binary_crossentropy     Nadam  \n",
       "27            60              1         sigmoid  binary_crossentropy      Adam  \n",
       "28            60              2         sigmoid  binary_crossentropy      Adam  \n",
       "29            60              1         sigmoid  binary_crossentropy     Nadam  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display a dataframe comapring the results of the different combinations \n",
    "t.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the model with the optimised paramaters \n",
    "\n",
    "p_optimisied = {'first_neuron':30,\n",
    "#                 'second_neuron':200,\n",
    "                'hidden_layers':1,\n",
    "                'batch_size': 30,\n",
    "                'epochs': 200,\n",
    "                'dropout': 0,\n",
    "                'optimizer': 'Nadam',\n",
    "                'activation':'relu',\n",
    "               }\n",
    "\n",
    "def everest_optimised(x_train, y_train, params):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(params['first_neuron'], input_dim=x_train.shape[1], \n",
    "              activation=params['activation']))\n",
    "    \n",
    "#     model.add(Dense(params['second_neuron'], activation=params['activation']))\n",
    " \n",
    "    model.add(Dropout(params['dropout']))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=params['optimizer'], metrics=['accuracy'])\n",
    "    \n",
    "    out = model.fit(x_train, \n",
    "                    y_train,\n",
    "                    epochs=params['epochs'],\n",
    "                    batch_size=params['batch_size'],\n",
    "                    verbose=0)\n",
    "\n",
    "    return out, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-fit the training data to the model\n",
    "out, model = everest_optimised(X_train_scaled, encoded_y_train, p_optimisied)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 - 0s - loss: 0.3841 - accuracy: 0.8459\n",
      "Neural Network Performace - Loss: 0.3841450810432434, Accuracy: 0.8459488153457642\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(X_test_scaled, encoded_y_test, verbose=2)\n",
    "print(f\"Neural Network Performace - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "filename = 'crowding_model_success.h5'\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(\"crowding_model_success.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "dev"
  },
  "kernelspec": {
   "display_name": "Python [conda env:PythonData] *",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
