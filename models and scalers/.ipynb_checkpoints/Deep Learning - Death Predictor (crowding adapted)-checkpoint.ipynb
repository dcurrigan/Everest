{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data# Import the data\n",
    "df = pd.read_csv(\"../crowding_data.csv\", low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'expid', 'membid', 'myear', 'sex', 'calcage', 'citizen', 'status',\n",
       "       'msolo', 'msuccess', 'msmtdate1', 'msmtdate2', 'msmtdate3', 'route1',\n",
       "       'route2', 'route3', 'route4', 'mo2used', 'mo2none', 'mo2climb',\n",
       "       'mo2descent', 'mo2sleep', 'death', 'deathdate', 'msmtbid', 'stdrte',\n",
       "       'new_route', 'new_status', 'climber_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View column names and drop unnecesary columns for the model \n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set features\n",
    "feature_names = ['sex', 'calcage', 'citizen', 'msolo', 'new_route', 'mo2used', 'mo2climb',\n",
    "                 'mo2descent', 'mo2sleep', 'stdrte', 'new_status', 'climber_count']\n",
    "\n",
    "X = df[feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>calcage</th>\n",
       "      <th>citizen</th>\n",
       "      <th>msolo</th>\n",
       "      <th>new_route</th>\n",
       "      <th>mo2used</th>\n",
       "      <th>mo2climb</th>\n",
       "      <th>mo2descent</th>\n",
       "      <th>mo2sleep</th>\n",
       "      <th>stdrte</th>\n",
       "      <th>new_status</th>\n",
       "      <th>climber_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15003</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15004</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15005</th>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15006</th>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15007</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15008 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sex  calcage  citizen  msolo  new_route  mo2used  mo2climb  mo2descent  \\\n",
       "0        0       32       15    0.0          2      1.0       1.0         0.0   \n",
       "1        0       40       82    0.0          2      0.0       0.0         0.0   \n",
       "2        0       29       82    0.0          2      1.0       1.0         0.0   \n",
       "3        0       37       82    0.0          1      0.0       0.0         0.0   \n",
       "4        0       33       82    0.0          1      0.0       0.0         0.0   \n",
       "...    ...      ...      ...    ...        ...      ...       ...         ...   \n",
       "15003    1       16       27    0.0          0      1.0       1.0         0.0   \n",
       "15004    0       37       27    0.0          0      1.0       1.0         0.0   \n",
       "15005    0       57       27    0.0          0      1.0       1.0         0.0   \n",
       "15006    0       35       27    0.0          0      1.0       1.0         0.0   \n",
       "15007    0       37       27    0.0          0      1.0       1.0         0.0   \n",
       "\n",
       "       mo2sleep  stdrte  new_status  climber_count  \n",
       "0           1.0     1.0           2            3.0  \n",
       "1           0.0     1.0           2            3.0  \n",
       "2           1.0     1.0           2            3.0  \n",
       "3           0.0     0.0           1            3.0  \n",
       "4           0.0     0.0           1            3.0  \n",
       "...         ...     ...         ...            ...  \n",
       "15003       1.0     1.0           0           15.0  \n",
       "15004       1.0     1.0           0           15.0  \n",
       "15005       1.0     1.0           0           15.0  \n",
       "15006       1.0     1.0           0           15.0  \n",
       "15007       1.0     1.0           0           15.0  \n",
       "\n",
       "[15008 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert X values to numerical \n",
    "\n",
    "###                KEY                  ### \n",
    "###        Male = 0, Female = 1         ###\n",
    "###        True = 1, False = 0          ###\n",
    "###  Citizen and Route = see label map  ###\n",
    "\n",
    "X.replace(True, 1, inplace=True)\n",
    "X['sex'] = pd.get_dummies(X['sex'])\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "# Perform label transformation and create label maps for later use \n",
    "X['citizen'] = le.fit_transform(X['citizen'])\n",
    "country_label_map = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "X['new_route'] = le.fit_transform(X['new_route'])\n",
    "route_label_map = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "X['new_status'] = le.fit_transform(X['new_route'])\n",
    "status_label_map = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_names = df['death'].unique()\n",
    "target_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y  = df['death']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Train Test Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "Scale the data using the MinMaxScaler and perform some feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create the scaler\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "\n",
    "# Transform the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the y values to numerical using label_encoder/to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)\n",
    "y_test_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and initial trial model and add layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "inputs = X_train.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=60, activation='relu', input_dim=inputs))\n",
    "model.add(Dense(units=200, activation='relu'))\n",
    "model.add(Dense(units=2, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 60)                780       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200)               12200     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 402       \n",
      "=================================================================\n",
      "Total params: 13,382\n",
      "Trainable params: 13,382\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "352/352 - 1s - loss: 0.0887 - accuracy: 0.9869\n",
      "Epoch 2/100\n",
      "352/352 - 0s - loss: 0.0666 - accuracy: 0.9870\n",
      "Epoch 3/100\n",
      "352/352 - 0s - loss: 0.0657 - accuracy: 0.9870\n",
      "Epoch 4/100\n",
      "352/352 - 0s - loss: 0.0648 - accuracy: 0.9870\n",
      "Epoch 5/100\n",
      "352/352 - 0s - loss: 0.0644 - accuracy: 0.9870\n",
      "Epoch 6/100\n",
      "352/352 - 0s - loss: 0.0639 - accuracy: 0.9870\n",
      "Epoch 7/100\n",
      "352/352 - 0s - loss: 0.0643 - accuracy: 0.9870\n",
      "Epoch 8/100\n",
      "352/352 - 0s - loss: 0.0639 - accuracy: 0.9870\n",
      "Epoch 9/100\n",
      "352/352 - 0s - loss: 0.0635 - accuracy: 0.9870\n",
      "Epoch 10/100\n",
      "352/352 - 0s - loss: 0.0637 - accuracy: 0.9870\n",
      "Epoch 11/100\n",
      "352/352 - 0s - loss: 0.0634 - accuracy: 0.9870\n",
      "Epoch 12/100\n",
      "352/352 - 0s - loss: 0.0635 - accuracy: 0.9870\n",
      "Epoch 13/100\n",
      "352/352 - 0s - loss: 0.0630 - accuracy: 0.9870\n",
      "Epoch 14/100\n",
      "352/352 - 0s - loss: 0.0627 - accuracy: 0.9870\n",
      "Epoch 15/100\n",
      "352/352 - 0s - loss: 0.0629 - accuracy: 0.9870\n",
      "Epoch 16/100\n",
      "352/352 - 0s - loss: 0.0631 - accuracy: 0.9870\n",
      "Epoch 17/100\n",
      "352/352 - 0s - loss: 0.0621 - accuracy: 0.9870\n",
      "Epoch 18/100\n",
      "352/352 - 0s - loss: 0.0619 - accuracy: 0.9870\n",
      "Epoch 19/100\n",
      "352/352 - 0s - loss: 0.0623 - accuracy: 0.9870\n",
      "Epoch 20/100\n",
      "352/352 - 0s - loss: 0.0616 - accuracy: 0.9870\n",
      "Epoch 21/100\n",
      "352/352 - 0s - loss: 0.0615 - accuracy: 0.9870\n",
      "Epoch 22/100\n",
      "352/352 - 0s - loss: 0.0620 - accuracy: 0.9870\n",
      "Epoch 23/100\n",
      "352/352 - 0s - loss: 0.0618 - accuracy: 0.9871\n",
      "Epoch 24/100\n",
      "352/352 - 0s - loss: 0.0610 - accuracy: 0.9871\n",
      "Epoch 25/100\n",
      "352/352 - 0s - loss: 0.0606 - accuracy: 0.9871\n",
      "Epoch 26/100\n",
      "352/352 - 0s - loss: 0.0608 - accuracy: 0.9871\n",
      "Epoch 27/100\n",
      "352/352 - 0s - loss: 0.0608 - accuracy: 0.9871\n",
      "Epoch 28/100\n",
      "352/352 - 0s - loss: 0.0603 - accuracy: 0.9871\n",
      "Epoch 29/100\n",
      "352/352 - 0s - loss: 0.0602 - accuracy: 0.9871\n",
      "Epoch 30/100\n",
      "352/352 - 0s - loss: 0.0601 - accuracy: 0.9871\n",
      "Epoch 31/100\n",
      "352/352 - 0s - loss: 0.0599 - accuracy: 0.9871\n",
      "Epoch 32/100\n",
      "352/352 - 0s - loss: 0.0598 - accuracy: 0.9871\n",
      "Epoch 33/100\n",
      "352/352 - 0s - loss: 0.0595 - accuracy: 0.9871\n",
      "Epoch 34/100\n",
      "352/352 - 0s - loss: 0.0594 - accuracy: 0.9871\n",
      "Epoch 35/100\n",
      "352/352 - 0s - loss: 0.0591 - accuracy: 0.9871\n",
      "Epoch 36/100\n",
      "352/352 - 0s - loss: 0.0593 - accuracy: 0.9871\n",
      "Epoch 37/100\n",
      "352/352 - 0s - loss: 0.0599 - accuracy: 0.9871\n",
      "Epoch 38/100\n",
      "352/352 - 0s - loss: 0.0590 - accuracy: 0.9871\n",
      "Epoch 39/100\n",
      "352/352 - 0s - loss: 0.0595 - accuracy: 0.9871\n",
      "Epoch 40/100\n",
      "352/352 - 0s - loss: 0.0594 - accuracy: 0.9871\n",
      "Epoch 41/100\n",
      "352/352 - 0s - loss: 0.0592 - accuracy: 0.9870\n",
      "Epoch 42/100\n",
      "352/352 - 0s - loss: 0.0590 - accuracy: 0.9870\n",
      "Epoch 43/100\n",
      "352/352 - 0s - loss: 0.0594 - accuracy: 0.9871\n",
      "Epoch 44/100\n",
      "352/352 - 0s - loss: 0.0583 - accuracy: 0.9871\n",
      "Epoch 45/100\n",
      "352/352 - 0s - loss: 0.0588 - accuracy: 0.9872\n",
      "Epoch 46/100\n",
      "352/352 - 0s - loss: 0.0586 - accuracy: 0.9871\n",
      "Epoch 47/100\n",
      "352/352 - 0s - loss: 0.0585 - accuracy: 0.9872\n",
      "Epoch 48/100\n",
      "352/352 - 0s - loss: 0.0580 - accuracy: 0.9870\n",
      "Epoch 49/100\n",
      "352/352 - 0s - loss: 0.0579 - accuracy: 0.9870\n",
      "Epoch 50/100\n",
      "352/352 - 0s - loss: 0.0582 - accuracy: 0.9870\n",
      "Epoch 51/100\n",
      "352/352 - 0s - loss: 0.0577 - accuracy: 0.9871\n",
      "Epoch 52/100\n",
      "352/352 - 0s - loss: 0.0578 - accuracy: 0.9871\n",
      "Epoch 53/100\n",
      "352/352 - 0s - loss: 0.0575 - accuracy: 0.9870\n",
      "Epoch 54/100\n",
      "352/352 - 0s - loss: 0.0577 - accuracy: 0.9871\n",
      "Epoch 55/100\n",
      "352/352 - 0s - loss: 0.0574 - accuracy: 0.9871\n",
      "Epoch 56/100\n",
      "352/352 - 0s - loss: 0.0574 - accuracy: 0.9871\n",
      "Epoch 57/100\n",
      "352/352 - 0s - loss: 0.0577 - accuracy: 0.9872\n",
      "Epoch 58/100\n",
      "352/352 - 0s - loss: 0.0573 - accuracy: 0.9870\n",
      "Epoch 59/100\n",
      "352/352 - 0s - loss: 0.0572 - accuracy: 0.9873\n",
      "Epoch 60/100\n",
      "352/352 - 0s - loss: 0.0566 - accuracy: 0.9870\n",
      "Epoch 61/100\n",
      "352/352 - 0s - loss: 0.0567 - accuracy: 0.9871\n",
      "Epoch 62/100\n",
      "352/352 - 0s - loss: 0.0568 - accuracy: 0.9871\n",
      "Epoch 63/100\n",
      "352/352 - 0s - loss: 0.0569 - accuracy: 0.9871\n",
      "Epoch 64/100\n",
      "352/352 - 0s - loss: 0.0569 - accuracy: 0.9871\n",
      "Epoch 65/100\n",
      "352/352 - 0s - loss: 0.0567 - accuracy: 0.9870\n",
      "Epoch 66/100\n",
      "352/352 - 0s - loss: 0.0561 - accuracy: 0.9871\n",
      "Epoch 67/100\n",
      "352/352 - 0s - loss: 0.0562 - accuracy: 0.9871\n",
      "Epoch 68/100\n",
      "352/352 - 0s - loss: 0.0564 - accuracy: 0.9872\n",
      "Epoch 69/100\n",
      "352/352 - 0s - loss: 0.0561 - accuracy: 0.9872\n",
      "Epoch 70/100\n",
      "352/352 - 0s - loss: 0.0567 - accuracy: 0.9871\n",
      "Epoch 71/100\n",
      "352/352 - 0s - loss: 0.0565 - accuracy: 0.9870\n",
      "Epoch 72/100\n",
      "352/352 - 0s - loss: 0.0562 - accuracy: 0.9870\n",
      "Epoch 73/100\n",
      "352/352 - 0s - loss: 0.0560 - accuracy: 0.9870\n",
      "Epoch 74/100\n",
      "352/352 - 0s - loss: 0.0555 - accuracy: 0.9873\n",
      "Epoch 75/100\n",
      "352/352 - 0s - loss: 0.0551 - accuracy: 0.9876\n",
      "Epoch 76/100\n",
      "352/352 - 0s - loss: 0.0551 - accuracy: 0.9871\n",
      "Epoch 77/100\n",
      "352/352 - 0s - loss: 0.0559 - accuracy: 0.9872\n",
      "Epoch 78/100\n",
      "352/352 - 0s - loss: 0.0557 - accuracy: 0.9870\n",
      "Epoch 79/100\n",
      "352/352 - 0s - loss: 0.0552 - accuracy: 0.9873\n",
      "Epoch 80/100\n",
      "352/352 - 0s - loss: 0.0550 - accuracy: 0.9873\n",
      "Epoch 81/100\n",
      "352/352 - 0s - loss: 0.0554 - accuracy: 0.9869\n",
      "Epoch 82/100\n",
      "352/352 - 0s - loss: 0.0551 - accuracy: 0.9872\n",
      "Epoch 83/100\n",
      "352/352 - 0s - loss: 0.0543 - accuracy: 0.9875\n",
      "Epoch 84/100\n",
      "352/352 - 0s - loss: 0.0550 - accuracy: 0.9871\n",
      "Epoch 85/100\n",
      "352/352 - 0s - loss: 0.0551 - accuracy: 0.9869\n",
      "Epoch 86/100\n",
      "352/352 - 0s - loss: 0.0546 - accuracy: 0.9873\n",
      "Epoch 87/100\n",
      "352/352 - 0s - loss: 0.0541 - accuracy: 0.9875\n",
      "Epoch 88/100\n",
      "352/352 - 0s - loss: 0.0548 - accuracy: 0.9870\n",
      "Epoch 89/100\n",
      "352/352 - 0s - loss: 0.0539 - accuracy: 0.9875\n",
      "Epoch 90/100\n",
      "352/352 - 0s - loss: 0.0543 - accuracy: 0.9873\n",
      "Epoch 91/100\n",
      "352/352 - 0s - loss: 0.0538 - accuracy: 0.9875\n",
      "Epoch 92/100\n",
      "352/352 - 0s - loss: 0.0544 - accuracy: 0.9875\n",
      "Epoch 93/100\n",
      "352/352 - 0s - loss: 0.0537 - accuracy: 0.9873\n",
      "Epoch 94/100\n",
      "352/352 - 0s - loss: 0.0538 - accuracy: 0.9873\n",
      "Epoch 95/100\n",
      "352/352 - 0s - loss: 0.0539 - accuracy: 0.9872\n",
      "Epoch 96/100\n",
      "352/352 - 0s - loss: 0.0533 - accuracy: 0.9869\n",
      "Epoch 97/100\n",
      "352/352 - 0s - loss: 0.0540 - accuracy: 0.9871\n",
      "Epoch 98/100\n",
      "352/352 - 0s - loss: 0.0539 - accuracy: 0.9875\n",
      "Epoch 99/100\n",
      "352/352 - 0s - loss: 0.0533 - accuracy: 0.9873\n",
      "Epoch 100/100\n",
      "352/352 - 0s - loss: 0.0535 - accuracy: 0.9875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25f0760cb00>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    verbose=2,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantify Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 - 0s - loss: 0.0972 - accuracy: 0.9840\n",
      "Neural Network Performace - Loss: 0.09724929928779602, Accuracy: 0.9840085506439209\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(f\"Neural Network Performace - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Risk of death for data point 50 is 0.26%\n"
     ]
    }
   ],
   "source": [
    "x = X_train_scaled[50].tolist()\n",
    "result = model.predict([x])\n",
    "print(f\"Risk of death for data point 50 is {round(result[0][1]*100,2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 540x540 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a confusion matrix to visualise the performance \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "predictions = np.argmax(model.predict(X_test_scaled), axis=-1)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true=encoded_y_test, y_pred=predictions)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
    "\n",
    "ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)\n",
    "\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        ax.text(x=j, y=i, s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
    "\n",
    "plt.title('Confusion Matrix', fontsize=18)\n",
    "plt.xlabel('Predictions', fontsize=18)\n",
    "ax.set_xticks([0,1])\n",
    "ax.set_xticklabels(target_names)\n",
    "plt.ylabel('Actuals', fontsize=18)\n",
    "ax.set_yticks([0,1])\n",
    "ax.set_yticklabels(target_names)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperperameter tuning\n",
    "\n",
    "#### Talos Custom Hyperparameter Optimiser for Keras, Tensorflow used \n",
    "Availble from: <a href=\"https://github.com/autonomio/talos/\">https://github.com/autonomio/talos/</a>\n",
    "<img src=\"https://raw.githubusercontent.com/autonomio/talos/master/logo.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import talos\n",
    "\n",
    "# Function to run the model \n",
    "def everest(x_train, y_train, x_val, y_val, params):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(params['first_neuron'], input_dim=x_train.shape[1], \n",
    "              activation=params['activation']))\n",
    " \n",
    "    model.add(Dropout(params['dropout']))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=params['optimizer'], metrics=['accuracy'])\n",
    "    \n",
    "    out = model.fit(x_train, \n",
    "                    y_train,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    epochs=params['epochs'],\n",
    "                    batch_size=params['batch_size'],\n",
    "                    verbose=0)\n",
    "    \n",
    "    return out, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a parameter dictionary\n",
    "p = {'first_neuron':[30,60,120,240],\n",
    "    'hidden_layers':[1, 2],\n",
    "    'batch_size': [10,20, 30],\n",
    "    'epochs': [100, 150, 200],\n",
    "    'dropout': [0],\n",
    "    'optimizer': ['Nadam', 'Adam'],\n",
    "    'losses': ['binary_crossentropy'],\n",
    "    'activation':['relu'],\n",
    "    'last_activation': ['sigmoid']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [8:06:57<00:00, 973.92s/it]\n"
     ]
    }
   ],
   "source": [
    "t = talos.Scan(x=X_train_scaled, y=encoded_y_train, params=p, model=everest, experiment_name='everest_tune', round_limit=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "experiment_name            everest_tune\n",
       "random_method          uniform_mersenne\n",
       "reduction_method                   None\n",
       "reduction_interval                   50\n",
       "reduction_window                     20\n",
       "reduction_threshold                 0.2\n",
       "reduction_metric                val_acc\n",
       "complete_time            08/25/21/07:14\n",
       "x_shape                     (11256, 12)\n",
       "y_shape                        (11256,)\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best parameters:  \n",
    "  \n",
    "There are a a number of models which reach an accuracy of 98.7859% with validation data set\n",
    "\n",
    "Note that the underlying rate death rate in data is only 1.4% so it is relatively 'easy' to achieve high accuarcy with this model\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>duration</th>\n",
       "      <th>round_epochs</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>activation</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>dropout</th>\n",
       "      <th>epochs</th>\n",
       "      <th>first_neuron</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>last_activation</th>\n",
       "      <th>losses</th>\n",
       "      <th>optimizer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>08/24/21-230711</td>\n",
       "      <td>08/24/21-230915</td>\n",
       "      <td>124.348082</td>\n",
       "      <td>150</td>\n",
       "      <td>0.056582</td>\n",
       "      <td>0.986927</td>\n",
       "      <td>0.065306</td>\n",
       "      <td>0.987267</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>120</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>08/24/21-230916</td>\n",
       "      <td>08/24/21-231001</td>\n",
       "      <td>45.658113</td>\n",
       "      <td>150</td>\n",
       "      <td>0.055801</td>\n",
       "      <td>0.986927</td>\n",
       "      <td>0.064085</td>\n",
       "      <td>0.987267</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>240</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>08/24/21-231001</td>\n",
       "      <td>08/24/21-231123</td>\n",
       "      <td>81.170788</td>\n",
       "      <td>100</td>\n",
       "      <td>0.057216</td>\n",
       "      <td>0.986800</td>\n",
       "      <td>0.062621</td>\n",
       "      <td>0.987563</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>240</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>08/24/21-231123</td>\n",
       "      <td>08/24/21-231153</td>\n",
       "      <td>30.087528</td>\n",
       "      <td>100</td>\n",
       "      <td>0.059041</td>\n",
       "      <td>0.986800</td>\n",
       "      <td>0.062481</td>\n",
       "      <td>0.987859</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>120</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08/24/21-231153</td>\n",
       "      <td>08/24/21-231236</td>\n",
       "      <td>43.327790</td>\n",
       "      <td>100</td>\n",
       "      <td>0.059604</td>\n",
       "      <td>0.986800</td>\n",
       "      <td>0.063851</td>\n",
       "      <td>0.987859</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>08/24/21-231236</td>\n",
       "      <td>08/24/21-231320</td>\n",
       "      <td>43.026431</td>\n",
       "      <td>150</td>\n",
       "      <td>0.058632</td>\n",
       "      <td>0.986800</td>\n",
       "      <td>0.062100</td>\n",
       "      <td>0.987859</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>08/24/21-231320</td>\n",
       "      <td>08/24/21-231402</td>\n",
       "      <td>42.741336</td>\n",
       "      <td>100</td>\n",
       "      <td>0.058214</td>\n",
       "      <td>0.986800</td>\n",
       "      <td>0.062338</td>\n",
       "      <td>0.987563</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>240</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>08/24/21-231403</td>\n",
       "      <td>08/24/21-231445</td>\n",
       "      <td>42.768037</td>\n",
       "      <td>150</td>\n",
       "      <td>0.061814</td>\n",
       "      <td>0.986673</td>\n",
       "      <td>0.063324</td>\n",
       "      <td>0.987859</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>08/24/21-231445</td>\n",
       "      <td>08/24/21-231728</td>\n",
       "      <td>162.651125</td>\n",
       "      <td>200</td>\n",
       "      <td>0.059410</td>\n",
       "      <td>0.986673</td>\n",
       "      <td>0.063195</td>\n",
       "      <td>0.987859</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>08/24/21-231728</td>\n",
       "      <td>08/24/21-231940</td>\n",
       "      <td>131.391770</td>\n",
       "      <td>150</td>\n",
       "      <td>0.056002</td>\n",
       "      <td>0.987054</td>\n",
       "      <td>0.064850</td>\n",
       "      <td>0.987563</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>240</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>08/24/21-231940</td>\n",
       "      <td>08/24/21-232155</td>\n",
       "      <td>135.003910</td>\n",
       "      <td>150</td>\n",
       "      <td>0.057325</td>\n",
       "      <td>0.986927</td>\n",
       "      <td>0.063773</td>\n",
       "      <td>0.987563</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>08/24/21-232155</td>\n",
       "      <td>08/24/21-232320</td>\n",
       "      <td>84.906439</td>\n",
       "      <td>200</td>\n",
       "      <td>0.058472</td>\n",
       "      <td>0.986800</td>\n",
       "      <td>0.061494</td>\n",
       "      <td>0.987859</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>08/24/21-232320</td>\n",
       "      <td>08/24/21-232403</td>\n",
       "      <td>42.501114</td>\n",
       "      <td>150</td>\n",
       "      <td>0.061615</td>\n",
       "      <td>0.986673</td>\n",
       "      <td>0.061874</td>\n",
       "      <td>0.987859</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>08/24/21-232403</td>\n",
       "      <td>08/24/21-232432</td>\n",
       "      <td>29.724560</td>\n",
       "      <td>100</td>\n",
       "      <td>0.057881</td>\n",
       "      <td>0.986927</td>\n",
       "      <td>0.062622</td>\n",
       "      <td>0.987563</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>240</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>08/24/21-232433</td>\n",
       "      <td>08/24/21-232534</td>\n",
       "      <td>61.904653</td>\n",
       "      <td>150</td>\n",
       "      <td>0.057319</td>\n",
       "      <td>0.986927</td>\n",
       "      <td>0.062825</td>\n",
       "      <td>0.987859</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>120</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>08/24/21-232535</td>\n",
       "      <td>08/24/21-232617</td>\n",
       "      <td>41.984980</td>\n",
       "      <td>100</td>\n",
       "      <td>0.059173</td>\n",
       "      <td>0.986800</td>\n",
       "      <td>0.062979</td>\n",
       "      <td>0.987859</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>120</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>08/24/21-232617</td>\n",
       "      <td>08/24/21-232714</td>\n",
       "      <td>57.572968</td>\n",
       "      <td>200</td>\n",
       "      <td>0.055300</td>\n",
       "      <td>0.987181</td>\n",
       "      <td>0.064190</td>\n",
       "      <td>0.987563</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>120</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>08/24/21-232715</td>\n",
       "      <td>08/24/21-232913</td>\n",
       "      <td>118.946707</td>\n",
       "      <td>150</td>\n",
       "      <td>0.059272</td>\n",
       "      <td>0.986673</td>\n",
       "      <td>0.062761</td>\n",
       "      <td>0.987859</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>08/24/21-232914</td>\n",
       "      <td>08/24/21-233117</td>\n",
       "      <td>123.433992</td>\n",
       "      <td>150</td>\n",
       "      <td>0.055514</td>\n",
       "      <td>0.986547</td>\n",
       "      <td>0.065143</td>\n",
       "      <td>0.987267</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>240</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>08/24/21-233117</td>\n",
       "      <td>08/24/21-233317</td>\n",
       "      <td>119.710247</td>\n",
       "      <td>150</td>\n",
       "      <td>0.056314</td>\n",
       "      <td>0.987054</td>\n",
       "      <td>0.063677</td>\n",
       "      <td>0.987563</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>08/24/21-233317</td>\n",
       "      <td>08/24/21-233346</td>\n",
       "      <td>29.112150</td>\n",
       "      <td>100</td>\n",
       "      <td>0.060523</td>\n",
       "      <td>0.986800</td>\n",
       "      <td>0.062274</td>\n",
       "      <td>0.987859</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>08/24/21-233346</td>\n",
       "      <td>08/24/21-233443</td>\n",
       "      <td>56.825332</td>\n",
       "      <td>200</td>\n",
       "      <td>0.057841</td>\n",
       "      <td>0.986800</td>\n",
       "      <td>0.064192</td>\n",
       "      <td>0.987563</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>08/24/21-233443</td>\n",
       "      <td>08/24/21-233645</td>\n",
       "      <td>121.875926</td>\n",
       "      <td>150</td>\n",
       "      <td>0.055293</td>\n",
       "      <td>0.986927</td>\n",
       "      <td>0.066053</td>\n",
       "      <td>0.987563</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>240</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>08/24/21-233645</td>\n",
       "      <td>08/24/21-233743</td>\n",
       "      <td>57.735596</td>\n",
       "      <td>200</td>\n",
       "      <td>0.056530</td>\n",
       "      <td>0.986927</td>\n",
       "      <td>0.062809</td>\n",
       "      <td>0.987859</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>08/24/21-233743</td>\n",
       "      <td>08/25/21-070550</td>\n",
       "      <td>26887.157614</td>\n",
       "      <td>200</td>\n",
       "      <td>0.059668</td>\n",
       "      <td>0.986800</td>\n",
       "      <td>0.063727</td>\n",
       "      <td>0.987267</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>08/25/21-070551</td>\n",
       "      <td>08/25/21-070709</td>\n",
       "      <td>78.611010</td>\n",
       "      <td>200</td>\n",
       "      <td>0.060501</td>\n",
       "      <td>0.986673</td>\n",
       "      <td>0.063014</td>\n",
       "      <td>0.987859</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>08/25/21-070709</td>\n",
       "      <td>08/25/21-070946</td>\n",
       "      <td>156.279279</td>\n",
       "      <td>200</td>\n",
       "      <td>0.053484</td>\n",
       "      <td>0.987054</td>\n",
       "      <td>0.068427</td>\n",
       "      <td>0.986971</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>240</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>08/25/21-070946</td>\n",
       "      <td>08/25/21-071132</td>\n",
       "      <td>105.915900</td>\n",
       "      <td>150</td>\n",
       "      <td>0.059136</td>\n",
       "      <td>0.986800</td>\n",
       "      <td>0.062763</td>\n",
       "      <td>0.987859</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>08/25/21-071132</td>\n",
       "      <td>08/25/21-071230</td>\n",
       "      <td>58.347704</td>\n",
       "      <td>150</td>\n",
       "      <td>0.057030</td>\n",
       "      <td>0.987181</td>\n",
       "      <td>0.062358</td>\n",
       "      <td>0.987563</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>08/25/21-071230</td>\n",
       "      <td>08/25/21-071409</td>\n",
       "      <td>98.298285</td>\n",
       "      <td>150</td>\n",
       "      <td>0.060064</td>\n",
       "      <td>0.986800</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.987859</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              start              end      duration  round_epochs      loss  \\\n",
       "0   08/24/21-230711  08/24/21-230915    124.348082           150  0.056582   \n",
       "1   08/24/21-230916  08/24/21-231001     45.658113           150  0.055801   \n",
       "2   08/24/21-231001  08/24/21-231123     81.170788           100  0.057216   \n",
       "3   08/24/21-231123  08/24/21-231153     30.087528           100  0.059041   \n",
       "4   08/24/21-231153  08/24/21-231236     43.327790           100  0.059604   \n",
       "5   08/24/21-231236  08/24/21-231320     43.026431           150  0.058632   \n",
       "6   08/24/21-231320  08/24/21-231402     42.741336           100  0.058214   \n",
       "7   08/24/21-231403  08/24/21-231445     42.768037           150  0.061814   \n",
       "8   08/24/21-231445  08/24/21-231728    162.651125           200  0.059410   \n",
       "9   08/24/21-231728  08/24/21-231940    131.391770           150  0.056002   \n",
       "10  08/24/21-231940  08/24/21-232155    135.003910           150  0.057325   \n",
       "11  08/24/21-232155  08/24/21-232320     84.906439           200  0.058472   \n",
       "12  08/24/21-232320  08/24/21-232403     42.501114           150  0.061615   \n",
       "13  08/24/21-232403  08/24/21-232432     29.724560           100  0.057881   \n",
       "14  08/24/21-232433  08/24/21-232534     61.904653           150  0.057319   \n",
       "15  08/24/21-232535  08/24/21-232617     41.984980           100  0.059173   \n",
       "16  08/24/21-232617  08/24/21-232714     57.572968           200  0.055300   \n",
       "17  08/24/21-232715  08/24/21-232913    118.946707           150  0.059272   \n",
       "18  08/24/21-232914  08/24/21-233117    123.433992           150  0.055514   \n",
       "19  08/24/21-233117  08/24/21-233317    119.710247           150  0.056314   \n",
       "20  08/24/21-233317  08/24/21-233346     29.112150           100  0.060523   \n",
       "21  08/24/21-233346  08/24/21-233443     56.825332           200  0.057841   \n",
       "22  08/24/21-233443  08/24/21-233645    121.875926           150  0.055293   \n",
       "23  08/24/21-233645  08/24/21-233743     57.735596           200  0.056530   \n",
       "24  08/24/21-233743  08/25/21-070550  26887.157614           200  0.059668   \n",
       "25  08/25/21-070551  08/25/21-070709     78.611010           200  0.060501   \n",
       "26  08/25/21-070709  08/25/21-070946    156.279279           200  0.053484   \n",
       "27  08/25/21-070946  08/25/21-071132    105.915900           150  0.059136   \n",
       "28  08/25/21-071132  08/25/21-071230     58.347704           150  0.057030   \n",
       "29  08/25/21-071230  08/25/21-071409     98.298285           150  0.060064   \n",
       "\n",
       "    accuracy  val_loss  val_accuracy activation  batch_size  dropout  epochs  \\\n",
       "0   0.986927  0.065306      0.987267       relu          10        0     150   \n",
       "1   0.986927  0.064085      0.987267       relu          30        0     150   \n",
       "2   0.986800  0.062621      0.987563       relu          10        0     100   \n",
       "3   0.986800  0.062481      0.987859       relu          30        0     100   \n",
       "4   0.986800  0.063851      0.987859       relu          20        0     100   \n",
       "5   0.986800  0.062100      0.987859       relu          30        0     150   \n",
       "6   0.986800  0.062338      0.987563       relu          20        0     100   \n",
       "7   0.986673  0.063324      0.987859       relu          30        0     150   \n",
       "8   0.986673  0.063195      0.987859       relu          10        0     200   \n",
       "9   0.987054  0.064850      0.987563       relu          10        0     150   \n",
       "10  0.986927  0.063773      0.987563       relu          10        0     150   \n",
       "11  0.986800  0.061494      0.987859       relu          20        0     200   \n",
       "12  0.986673  0.061874      0.987859       relu          30        0     150   \n",
       "13  0.986927  0.062622      0.987563       relu          30        0     100   \n",
       "14  0.986927  0.062825      0.987859       relu          20        0     150   \n",
       "15  0.986800  0.062979      0.987859       relu          20        0     100   \n",
       "16  0.987181  0.064190      0.987563       relu          30        0     200   \n",
       "17  0.986673  0.062761      0.987859       relu          10        0     150   \n",
       "18  0.986547  0.065143      0.987267       relu          10        0     150   \n",
       "19  0.987054  0.063677      0.987563       relu          10        0     150   \n",
       "20  0.986800  0.062274      0.987859       relu          30        0     100   \n",
       "21  0.986800  0.064192      0.987563       relu          30        0     200   \n",
       "22  0.986927  0.066053      0.987563       relu          10        0     150   \n",
       "23  0.986927  0.062809      0.987859       relu          30        0     200   \n",
       "24  0.986800  0.063727      0.987267       relu          30        0     200   \n",
       "25  0.986673  0.063014      0.987859       relu          20        0     200   \n",
       "26  0.987054  0.068427      0.986971       relu          10        0     200   \n",
       "27  0.986800  0.062763      0.987859       relu          10        0     150   \n",
       "28  0.987181  0.062358      0.987563       relu          20        0     150   \n",
       "29  0.986800  0.062500      0.987859       relu          10        0     150   \n",
       "\n",
       "    first_neuron  hidden_layers last_activation               losses optimizer  \n",
       "0            120              2         sigmoid  binary_crossentropy     Nadam  \n",
       "1            240              1         sigmoid  binary_crossentropy      Adam  \n",
       "2            240              1         sigmoid  binary_crossentropy     Nadam  \n",
       "3            120              2         sigmoid  binary_crossentropy      Adam  \n",
       "4            120              1         sigmoid  binary_crossentropy      Adam  \n",
       "5             60              1         sigmoid  binary_crossentropy     Nadam  \n",
       "6            240              2         sigmoid  binary_crossentropy      Adam  \n",
       "7             30              2         sigmoid  binary_crossentropy      Adam  \n",
       "8             30              2         sigmoid  binary_crossentropy     Nadam  \n",
       "9            240              1         sigmoid  binary_crossentropy     Nadam  \n",
       "10            60              2         sigmoid  binary_crossentropy     Nadam  \n",
       "11            30              1         sigmoid  binary_crossentropy     Nadam  \n",
       "12            30              1         sigmoid  binary_crossentropy      Adam  \n",
       "13           240              1         sigmoid  binary_crossentropy      Adam  \n",
       "14           120              2         sigmoid  binary_crossentropy     Nadam  \n",
       "15           120              2         sigmoid  binary_crossentropy      Adam  \n",
       "16           120              2         sigmoid  binary_crossentropy      Adam  \n",
       "17            30              2         sigmoid  binary_crossentropy     Nadam  \n",
       "18           240              2         sigmoid  binary_crossentropy     Nadam  \n",
       "19           120              1         sigmoid  binary_crossentropy      Adam  \n",
       "20            60              1         sigmoid  binary_crossentropy      Adam  \n",
       "21            60              2         sigmoid  binary_crossentropy      Adam  \n",
       "22           240              1         sigmoid  binary_crossentropy      Adam  \n",
       "23           120              1         sigmoid  binary_crossentropy     Nadam  \n",
       "24            30              2         sigmoid  binary_crossentropy     Nadam  \n",
       "25            30              2         sigmoid  binary_crossentropy     Nadam  \n",
       "26           240              2         sigmoid  binary_crossentropy     Nadam  \n",
       "27            60              2         sigmoid  binary_crossentropy      Adam  \n",
       "28           120              1         sigmoid  binary_crossentropy      Adam  \n",
       "29            30              1         sigmoid  binary_crossentropy     Nadam  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display a dataframe comapring the results of the different combinations \n",
    "t.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "filename = 'crowding_model_death.h5'\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(\"Model 2 - Deep_learning.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "dev"
  },
  "kernelspec": {
   "display_name": "Python [conda env:PythonData] *",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
