{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "df = pd.read_csv(\"clean_data.csv\", low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'expid', 'membid', 'myear', 'sex', 'calcage', 'citizen', 'status',\n",
       "       'msolo', 'msuccess', 'msmtdate1', 'msmtdate2', 'msmtdate3', 'route1',\n",
       "       'route2', 'route3', 'route4', 'mo2used', 'mo2none', 'mo2climb',\n",
       "       'mo2descent', 'mo2sleep', 'death', 'deathdate', 'msmtbid', 'stdrte',\n",
       "       'new_route', 'new_status', 'climber_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View column names and drop unnecesary columns for the model \n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set features\n",
    "feature_names = ['sex', 'calcage', 'citizen', 'msolo', 'new_route', 'mo2used', 'mo2climb',\n",
    "                 'mo2descent', 'mo2sleep', 'stdrte', 'new_status']\n",
    "\n",
    "X = df[feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>calcage</th>\n",
       "      <th>citizen</th>\n",
       "      <th>msolo</th>\n",
       "      <th>new_route</th>\n",
       "      <th>mo2used</th>\n",
       "      <th>mo2climb</th>\n",
       "      <th>mo2descent</th>\n",
       "      <th>mo2sleep</th>\n",
       "      <th>stdrte</th>\n",
       "      <th>new_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21693</th>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21694</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21695</th>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21696</th>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21697</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21698 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sex  calcage  citizen  msolo  new_route  mo2used  mo2climb  mo2descent  \\\n",
       "0        0       49       15    0.0          2      0.0       0.0         0.0   \n",
       "1        1       30       89    0.0          2      0.0       0.0         0.0   \n",
       "2        0       32       15    0.0          2      1.0       1.0         0.0   \n",
       "3        0       40       85    0.0          2      0.0       0.0         0.0   \n",
       "4        0       29       85    0.0          2      1.0       1.0         0.0   \n",
       "...    ...      ...      ...    ...        ...      ...       ...         ...   \n",
       "21693    0       47       28    0.0          0      1.0       1.0         0.0   \n",
       "21694    0       37       28    0.0          0      1.0       1.0         0.0   \n",
       "21695    0       57       28    0.0          0      1.0       1.0         0.0   \n",
       "21696    0       35       28    0.0          0      1.0       1.0         0.0   \n",
       "21697    0       37       28    0.0          0      1.0       1.0         0.0   \n",
       "\n",
       "       mo2sleep  stdrte  new_status  \n",
       "0           0.0     1.0           3  \n",
       "1           0.0     1.0           3  \n",
       "2           1.0     1.0           0  \n",
       "3           0.0     1.0           5  \n",
       "4           1.0     1.0           5  \n",
       "...         ...     ...         ...  \n",
       "21693       0.0     1.0           0  \n",
       "21694       1.0     1.0           0  \n",
       "21695       1.0     1.0           0  \n",
       "21696       1.0     1.0           0  \n",
       "21697       1.0     1.0           0  \n",
       "\n",
       "[21698 rows x 11 columns]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert X values to numerical \n",
    "\n",
    "###                KEY                  ### \n",
    "###        Male = 0, Female = 1         ###\n",
    "###        True = 1, False = 0          ###oute, \n",
    "###  Citizen and Route = see label map  ###\n",
    "\n",
    "X.replace(True, 1, inplace=True)\n",
    "X['sex'] = pd.get_dummies(X['sex'])\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "# Perform label transformation and create label maps for later use \n",
    "X['citizen'] = le.fit_transform(X['citizen'])\n",
    "country_label_map = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "X['new_route'] = le.fit_transform(X['new_route'])\n",
    "route_label_map = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "X['new_status'] = le.fit_transform(X['new_status'])\n",
    "status_label_map = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Climber': 0, 'Cook': 1, 'Deputy': 2, 'Doctor': 3, 'Leader': 4, 'Other': 5}"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "status_label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_names = df['msuccess'].unique()\n",
    "target_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "y  = df['msuccess']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Train Test Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "Scale the data using the MinMaxScaler and perform some feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create the scaler\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "\n",
    "# Transform the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data_scaler.pkl']"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the scaler for later use\n",
    "import joblib \n",
    "\n",
    "filename = 'data_scaler.pkl'\n",
    "joblib.dump(X_scaler, filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the y values to numerical using label_encoder/to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)\n",
    "y_test_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and initial trial model and add layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "inputs = X_train.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=60, activation='relu', input_dim=inputs))\n",
    "model.add(Dense(units=200, activation='relu'))\n",
    "model.add(Dense(units=2, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 60)                720       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 200)               12200     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 402       \n",
      "=================================================================\n",
      "Total params: 13,322\n",
      "Trainable params: 13,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "509/509 - 1s - loss: 0.3436 - accuracy: 0.8669\n",
      "Epoch 2/100\n",
      "509/509 - 0s - loss: 0.3205 - accuracy: 0.8753\n",
      "Epoch 3/100\n",
      "509/509 - 0s - loss: 0.3205 - accuracy: 0.8762\n",
      "Epoch 4/100\n",
      "509/509 - 0s - loss: 0.3200 - accuracy: 0.8756\n",
      "Epoch 5/100\n",
      "509/509 - 0s - loss: 0.3196 - accuracy: 0.8757\n",
      "Epoch 6/100\n",
      "509/509 - 0s - loss: 0.3189 - accuracy: 0.8751\n",
      "Epoch 7/100\n",
      "509/509 - 0s - loss: 0.3185 - accuracy: 0.8766\n",
      "Epoch 8/100\n",
      "509/509 - 0s - loss: 0.3183 - accuracy: 0.8762\n",
      "Epoch 9/100\n",
      "509/509 - 0s - loss: 0.3181 - accuracy: 0.8756\n",
      "Epoch 10/100\n",
      "509/509 - 0s - loss: 0.3175 - accuracy: 0.8762\n",
      "Epoch 11/100\n",
      "509/509 - 0s - loss: 0.3168 - accuracy: 0.8762\n",
      "Epoch 12/100\n",
      "509/509 - 0s - loss: 0.3179 - accuracy: 0.8770\n",
      "Epoch 13/100\n",
      "509/509 - 0s - loss: 0.3169 - accuracy: 0.8762\n",
      "Epoch 14/100\n",
      "509/509 - 0s - loss: 0.3165 - accuracy: 0.8764\n",
      "Epoch 15/100\n",
      "509/509 - 0s - loss: 0.3166 - accuracy: 0.8765\n",
      "Epoch 16/100\n",
      "509/509 - 0s - loss: 0.3158 - accuracy: 0.8758\n",
      "Epoch 17/100\n",
      "509/509 - 0s - loss: 0.3159 - accuracy: 0.8763\n",
      "Epoch 18/100\n",
      "509/509 - 0s - loss: 0.3158 - accuracy: 0.8763\n",
      "Epoch 19/100\n",
      "509/509 - 0s - loss: 0.3160 - accuracy: 0.8772\n",
      "Epoch 20/100\n",
      "509/509 - 0s - loss: 0.3146 - accuracy: 0.8772\n",
      "Epoch 21/100\n",
      "509/509 - 0s - loss: 0.3152 - accuracy: 0.8768\n",
      "Epoch 22/100\n",
      "509/509 - 0s - loss: 0.3151 - accuracy: 0.8769\n",
      "Epoch 23/100\n",
      "509/509 - 0s - loss: 0.3143 - accuracy: 0.8773\n",
      "Epoch 24/100\n",
      "509/509 - 0s - loss: 0.3142 - accuracy: 0.8770\n",
      "Epoch 25/100\n",
      "509/509 - 0s - loss: 0.3143 - accuracy: 0.8760\n",
      "Epoch 26/100\n",
      "509/509 - 0s - loss: 0.3143 - accuracy: 0.8773\n",
      "Epoch 27/100\n",
      "509/509 - 0s - loss: 0.3134 - accuracy: 0.8774\n",
      "Epoch 28/100\n",
      "509/509 - 0s - loss: 0.3137 - accuracy: 0.8765\n",
      "Epoch 29/100\n",
      "509/509 - 0s - loss: 0.3133 - accuracy: 0.8777\n",
      "Epoch 30/100\n",
      "509/509 - 0s - loss: 0.3133 - accuracy: 0.8775\n",
      "Epoch 31/100\n",
      "509/509 - 0s - loss: 0.3131 - accuracy: 0.8773\n",
      "Epoch 32/100\n",
      "509/509 - 0s - loss: 0.3121 - accuracy: 0.8770\n",
      "Epoch 33/100\n",
      "509/509 - 0s - loss: 0.3124 - accuracy: 0.8773\n",
      "Epoch 34/100\n",
      "509/509 - 0s - loss: 0.3122 - accuracy: 0.8776\n",
      "Epoch 35/100\n",
      "509/509 - 0s - loss: 0.3126 - accuracy: 0.8773\n",
      "Epoch 36/100\n",
      "509/509 - 0s - loss: 0.3116 - accuracy: 0.8775\n",
      "Epoch 37/100\n",
      "509/509 - 0s - loss: 0.3117 - accuracy: 0.8771\n",
      "Epoch 38/100\n",
      "509/509 - 0s - loss: 0.3117 - accuracy: 0.8776\n",
      "Epoch 39/100\n",
      "509/509 - 0s - loss: 0.3108 - accuracy: 0.8777\n",
      "Epoch 40/100\n",
      "509/509 - 0s - loss: 0.3109 - accuracy: 0.8775\n",
      "Epoch 41/100\n",
      "509/509 - 0s - loss: 0.3113 - accuracy: 0.8777\n",
      "Epoch 42/100\n",
      "509/509 - 0s - loss: 0.3103 - accuracy: 0.8772\n",
      "Epoch 43/100\n",
      "509/509 - 0s - loss: 0.3107 - accuracy: 0.8773\n",
      "Epoch 44/100\n",
      "509/509 - 0s - loss: 0.3103 - accuracy: 0.8786\n",
      "Epoch 45/100\n",
      "509/509 - 0s - loss: 0.3099 - accuracy: 0.8781\n",
      "Epoch 46/100\n",
      "509/509 - 0s - loss: 0.3104 - accuracy: 0.8780\n",
      "Epoch 47/100\n",
      "509/509 - 0s - loss: 0.3101 - accuracy: 0.8778\n",
      "Epoch 48/100\n",
      "509/509 - 0s - loss: 0.3097 - accuracy: 0.8786\n",
      "Epoch 49/100\n",
      "509/509 - 0s - loss: 0.3094 - accuracy: 0.8781\n",
      "Epoch 50/100\n",
      "509/509 - 0s - loss: 0.3097 - accuracy: 0.8780\n",
      "Epoch 51/100\n",
      "509/509 - 0s - loss: 0.3097 - accuracy: 0.8775\n",
      "Epoch 52/100\n",
      "509/509 - 0s - loss: 0.3091 - accuracy: 0.8783\n",
      "Epoch 53/100\n",
      "509/509 - 0s - loss: 0.3093 - accuracy: 0.8787\n",
      "Epoch 54/100\n",
      "509/509 - 0s - loss: 0.3092 - accuracy: 0.8785\n",
      "Epoch 55/100\n",
      "509/509 - 0s - loss: 0.3088 - accuracy: 0.8780\n",
      "Epoch 56/100\n",
      "509/509 - 0s - loss: 0.3087 - accuracy: 0.8792\n",
      "Epoch 57/100\n",
      "509/509 - 0s - loss: 0.3083 - accuracy: 0.8782\n",
      "Epoch 58/100\n",
      "509/509 - 0s - loss: 0.3083 - accuracy: 0.8777\n",
      "Epoch 59/100\n",
      "509/509 - 0s - loss: 0.3078 - accuracy: 0.8791\n",
      "Epoch 60/100\n",
      "509/509 - 0s - loss: 0.3075 - accuracy: 0.8786\n",
      "Epoch 61/100\n",
      "509/509 - 0s - loss: 0.3077 - accuracy: 0.8789\n",
      "Epoch 62/100\n",
      "509/509 - 0s - loss: 0.3076 - accuracy: 0.8784\n",
      "Epoch 63/100\n",
      "509/509 - 0s - loss: 0.3074 - accuracy: 0.8792\n",
      "Epoch 64/100\n",
      "509/509 - 0s - loss: 0.3074 - accuracy: 0.8791\n",
      "Epoch 65/100\n",
      "509/509 - 0s - loss: 0.3068 - accuracy: 0.8795\n",
      "Epoch 66/100\n",
      "509/509 - 0s - loss: 0.3065 - accuracy: 0.8801\n",
      "Epoch 67/100\n",
      "509/509 - 0s - loss: 0.3065 - accuracy: 0.8791\n",
      "Epoch 68/100\n",
      "509/509 - 0s - loss: 0.3061 - accuracy: 0.8799\n",
      "Epoch 69/100\n",
      "509/509 - 0s - loss: 0.3066 - accuracy: 0.8796\n",
      "Epoch 70/100\n",
      "509/509 - 0s - loss: 0.3059 - accuracy: 0.8796\n",
      "Epoch 71/100\n",
      "509/509 - 0s - loss: 0.3060 - accuracy: 0.8796\n",
      "Epoch 72/100\n",
      "509/509 - 0s - loss: 0.3062 - accuracy: 0.8788\n",
      "Epoch 73/100\n",
      "509/509 - 0s - loss: 0.3052 - accuracy: 0.8794\n",
      "Epoch 74/100\n",
      "509/509 - 0s - loss: 0.3051 - accuracy: 0.8795\n",
      "Epoch 75/100\n",
      "509/509 - 0s - loss: 0.3047 - accuracy: 0.8797\n",
      "Epoch 76/100\n",
      "509/509 - 0s - loss: 0.3052 - accuracy: 0.8807\n",
      "Epoch 77/100\n",
      "509/509 - 0s - loss: 0.3052 - accuracy: 0.8799\n",
      "Epoch 78/100\n",
      "509/509 - 0s - loss: 0.3049 - accuracy: 0.8801\n",
      "Epoch 79/100\n",
      "509/509 - 0s - loss: 0.3046 - accuracy: 0.8796\n",
      "Epoch 80/100\n",
      "509/509 - 0s - loss: 0.3045 - accuracy: 0.8808\n",
      "Epoch 81/100\n",
      "509/509 - 0s - loss: 0.3041 - accuracy: 0.8796\n",
      "Epoch 82/100\n",
      "509/509 - 0s - loss: 0.3037 - accuracy: 0.8807\n",
      "Epoch 83/100\n",
      "509/509 - 0s - loss: 0.3044 - accuracy: 0.8795\n",
      "Epoch 84/100\n",
      "509/509 - 0s - loss: 0.3038 - accuracy: 0.8792\n",
      "Epoch 85/100\n",
      "509/509 - 0s - loss: 0.3035 - accuracy: 0.8808\n",
      "Epoch 86/100\n",
      "509/509 - 0s - loss: 0.3028 - accuracy: 0.8806\n",
      "Epoch 87/100\n",
      "509/509 - 0s - loss: 0.3028 - accuracy: 0.8809\n",
      "Epoch 88/100\n",
      "509/509 - 0s - loss: 0.3037 - accuracy: 0.8812\n",
      "Epoch 89/100\n",
      "509/509 - 0s - loss: 0.3027 - accuracy: 0.8812\n",
      "Epoch 90/100\n",
      "509/509 - 0s - loss: 0.3023 - accuracy: 0.8805\n",
      "Epoch 91/100\n",
      "509/509 - 0s - loss: 0.3033 - accuracy: 0.8800\n",
      "Epoch 92/100\n",
      "509/509 - 0s - loss: 0.3023 - accuracy: 0.8814\n",
      "Epoch 93/100\n",
      "509/509 - 0s - loss: 0.3021 - accuracy: 0.8807\n",
      "Epoch 94/100\n",
      "509/509 - 0s - loss: 0.3021 - accuracy: 0.8815\n",
      "Epoch 95/100\n",
      "509/509 - 0s - loss: 0.3016 - accuracy: 0.8812\n",
      "Epoch 96/100\n",
      "509/509 - 0s - loss: 0.3020 - accuracy: 0.8817\n",
      "Epoch 97/100\n",
      "509/509 - 0s - loss: 0.3019 - accuracy: 0.8815\n",
      "Epoch 98/100\n",
      "509/509 - 0s - loss: 0.3015 - accuracy: 0.8825\n",
      "Epoch 99/100\n",
      "509/509 - 0s - loss: 0.3013 - accuracy: 0.8813\n",
      "Epoch 100/100\n",
      "509/509 - 0s - loss: 0.3010 - accuracy: 0.8818\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f095572320>"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    verbose=2,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantify Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 - 1s - loss: 0.3203 - accuracy: 0.8780\n",
      "Neural Network Performace - Loss: 0.32033467292785645, Accuracy: 0.8779723644256592\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(f\"Neural Network Performace - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chance of success for datapoint 50 is: 93.75%\n"
     ]
    }
   ],
   "source": [
    "# Print some test data to try out the preduction model \n",
    "test_values = X_train_scaled[50].tolist()\n",
    "result = model.predict([test_values])\n",
    "print(f\"Chance of success for datapoint 50 is: {round(result[0][1]*100,2)}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 540x540 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a confusion matrix to visualise the performance \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "predictions = np.argmax(model.predict(X_test_scaled), axis=-1)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true=encoded_y_test, y_pred=predictions)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
    "\n",
    "ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)\n",
    "\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        ax.text(x=j, y=i, s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
    "\n",
    "plt.title('Confusion Matrix', fontsize=18)\n",
    "plt.xlabel('Predictions', fontsize=18)\n",
    "ax.set_xticks([0,1])\n",
    "ax.set_xticklabels(target_names)\n",
    "plt.ylabel('Actuals', fontsize=18)\n",
    "ax.set_yticks([0,1])\n",
    "ax.set_yticklabels(target_names)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sex', 'calcage', 'citizen', 'msolo', 'new_route', 'mo2used',\n",
       "       'mo2climb', 'mo2descent', 'mo2sleep', 'stdrte', 'new_status'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use recursive feature elimination to identify the best performing features\n",
    "from sklearn.feature_selection import RFECV\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "# Initiate RFE cross-validation and fit with a linear regression model\n",
    "rfecv = RFECV(\n",
    "    estimator=tree.DecisionTreeClassifier(),\n",
    "    min_features_to_select=8,\n",
    "    step=5,\n",
    "    n_jobs=-1,\n",
    "    scoring=\"r2\",\n",
    "    cv=5,\n",
    ")\n",
    "\n",
    "_ = rfecv.fit(X_train_scaled, encoded_y_train)\n",
    "\n",
    "# Print the best columns\n",
    "X_train.columns[rfecv.support_]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RFE Suggests keeping all features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperperameter tuning\n",
    "\n",
    "#### Talos Custom Hyperparameter Optimiser for Keras, Tensorflow used \n",
    "Availble from: <a href=\"https://github.com/autonomio/talos/\">https://github.com/autonomio/talos/</a>\n",
    "<img src=\"https://raw.githubusercontent.com/autonomio/talos/master/logo.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import talos\n",
    "\n",
    "# Function to run the model \n",
    "def everest(x_train, y_train, x_val, y_val, params):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(params['first_neuron'], input_dim=x_train.shape[1], \n",
    "              activation=params['activation']))\n",
    " \n",
    "    model.add(Dropout(params['dropout']))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=params['optimizer'], metrics=['accuracy'])\n",
    "    \n",
    "    out = model.fit(x_train, \n",
    "                    y_train,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    epochs=params['epochs'],\n",
    "                    batch_size=params['batch_size'],\n",
    "                    verbose=0)\n",
    "    \n",
    "    return out, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a parameter dictionary\n",
    "p = {'first_neuron':[30,60,120,240],\n",
    "    'hidden_layers':[1, 2],\n",
    "    'batch_size': [10,20, 30],\n",
    "    'epochs': [100, 150, 200],\n",
    "    'dropout': [0],\n",
    "    'optimizer': ['Nadam', 'Adam'],\n",
    "    'losses': ['binary_crossentropy'],\n",
    "    'activation':['relu'],\n",
    "    'last_activation': ['sigmoid']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [29:15<00:00, 58.53s/it]\n"
     ]
    }
   ],
   "source": [
    "t = talos.Scan(x=X_train_scaled, y=encoded_y_train, params=p, model=everest, experiment_name='everest_tune', round_limit=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "experiment_name            everest_tune\n",
       "random_method          uniform_mersenne\n",
       "reduction_method                   None\n",
       "reduction_interval                   50\n",
       "reduction_window                     20\n",
       "reduction_threshold                 0.2\n",
       "reduction_metric                val_acc\n",
       "complete_time            08/21/21/16:45\n",
       "x_shape                     (16273, 11)\n",
       "y_shape                        (16273,)\n",
       "dtype: object"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best parameters:  \n",
    "  \n",
    "(as per table below)  \n",
    "first layer: 30  \n",
    "hidden layers: 1  \n",
    "activation: relu  \n",
    "batch_size: 10  \n",
    "epochs: 100  \n",
    "dropout: 0  \n",
    "optimizer: Nadam  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>duration</th>\n",
       "      <th>round_epochs</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>activation</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>dropout</th>\n",
       "      <th>epochs</th>\n",
       "      <th>first_neuron</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>last_activation</th>\n",
       "      <th>losses</th>\n",
       "      <th>optimizer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>08/21/21-161627</td>\n",
       "      <td>08/21/21-161654</td>\n",
       "      <td>27.428869</td>\n",
       "      <td>100</td>\n",
       "      <td>0.314192</td>\n",
       "      <td>0.877008</td>\n",
       "      <td>0.313542</td>\n",
       "      <td>0.876485</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>240</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>08/21/21-161654</td>\n",
       "      <td>08/21/21-161847</td>\n",
       "      <td>112.313444</td>\n",
       "      <td>150</td>\n",
       "      <td>0.314628</td>\n",
       "      <td>0.877710</td>\n",
       "      <td>0.316710</td>\n",
       "      <td>0.875871</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>08/21/21-161847</td>\n",
       "      <td>08/21/21-162001</td>\n",
       "      <td>73.792638</td>\n",
       "      <td>100</td>\n",
       "      <td>0.318849</td>\n",
       "      <td>0.876657</td>\n",
       "      <td>0.316764</td>\n",
       "      <td>0.875666</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>08/21/21-162001</td>\n",
       "      <td>08/21/21-162027</td>\n",
       "      <td>26.533146</td>\n",
       "      <td>100</td>\n",
       "      <td>0.319753</td>\n",
       "      <td>0.875252</td>\n",
       "      <td>0.314730</td>\n",
       "      <td>0.877100</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08/21/21-162027</td>\n",
       "      <td>08/21/21-162254</td>\n",
       "      <td>146.847889</td>\n",
       "      <td>200</td>\n",
       "      <td>0.312867</td>\n",
       "      <td>0.878588</td>\n",
       "      <td>0.320297</td>\n",
       "      <td>0.875256</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>08/21/21-162254</td>\n",
       "      <td>08/21/21-162333</td>\n",
       "      <td>38.282059</td>\n",
       "      <td>100</td>\n",
       "      <td>0.316513</td>\n",
       "      <td>0.877008</td>\n",
       "      <td>0.317701</td>\n",
       "      <td>0.874027</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>08/21/21-162333</td>\n",
       "      <td>08/21/21-162447</td>\n",
       "      <td>74.685859</td>\n",
       "      <td>100</td>\n",
       "      <td>0.314151</td>\n",
       "      <td>0.876657</td>\n",
       "      <td>0.320401</td>\n",
       "      <td>0.874846</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>240</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>08/21/21-162448</td>\n",
       "      <td>08/21/21-162546</td>\n",
       "      <td>58.378733</td>\n",
       "      <td>150</td>\n",
       "      <td>0.310814</td>\n",
       "      <td>0.878325</td>\n",
       "      <td>0.319806</td>\n",
       "      <td>0.874846</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>240</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>08/21/21-162546</td>\n",
       "      <td>08/21/21-162625</td>\n",
       "      <td>38.974841</td>\n",
       "      <td>100</td>\n",
       "      <td>0.320476</td>\n",
       "      <td>0.875165</td>\n",
       "      <td>0.316014</td>\n",
       "      <td>0.877100</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>08/21/21-162625</td>\n",
       "      <td>08/21/21-162740</td>\n",
       "      <td>75.203448</td>\n",
       "      <td>200</td>\n",
       "      <td>0.311862</td>\n",
       "      <td>0.877623</td>\n",
       "      <td>0.319145</td>\n",
       "      <td>0.874027</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>08/21/21-162741</td>\n",
       "      <td>08/21/21-162839</td>\n",
       "      <td>58.540379</td>\n",
       "      <td>150</td>\n",
       "      <td>0.310996</td>\n",
       "      <td>0.878149</td>\n",
       "      <td>0.319729</td>\n",
       "      <td>0.876075</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>240</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>08/21/21-162839</td>\n",
       "      <td>08/21/21-162938</td>\n",
       "      <td>58.507061</td>\n",
       "      <td>150</td>\n",
       "      <td>0.314198</td>\n",
       "      <td>0.876569</td>\n",
       "      <td>0.316526</td>\n",
       "      <td>0.874642</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>120</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>08/21/21-162938</td>\n",
       "      <td>08/21/21-163030</td>\n",
       "      <td>51.777108</td>\n",
       "      <td>200</td>\n",
       "      <td>0.315389</td>\n",
       "      <td>0.876833</td>\n",
       "      <td>0.315345</td>\n",
       "      <td>0.874846</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>08/21/21-163030</td>\n",
       "      <td>08/21/21-163144</td>\n",
       "      <td>74.617181</td>\n",
       "      <td>200</td>\n",
       "      <td>0.312768</td>\n",
       "      <td>0.877886</td>\n",
       "      <td>0.316420</td>\n",
       "      <td>0.875461</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>08/21/21-163144</td>\n",
       "      <td>08/21/21-163222</td>\n",
       "      <td>37.679940</td>\n",
       "      <td>100</td>\n",
       "      <td>0.315743</td>\n",
       "      <td>0.876745</td>\n",
       "      <td>0.322123</td>\n",
       "      <td>0.875051</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>120</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>08/21/21-163222</td>\n",
       "      <td>08/21/21-163302</td>\n",
       "      <td>39.469143</td>\n",
       "      <td>150</td>\n",
       "      <td>0.315568</td>\n",
       "      <td>0.876657</td>\n",
       "      <td>0.316097</td>\n",
       "      <td>0.874642</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>08/21/21-163302</td>\n",
       "      <td>08/21/21-163419</td>\n",
       "      <td>77.099050</td>\n",
       "      <td>200</td>\n",
       "      <td>0.317142</td>\n",
       "      <td>0.877008</td>\n",
       "      <td>0.318572</td>\n",
       "      <td>0.876690</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>08/21/21-163419</td>\n",
       "      <td>08/21/21-163512</td>\n",
       "      <td>52.598148</td>\n",
       "      <td>200</td>\n",
       "      <td>0.311672</td>\n",
       "      <td>0.877096</td>\n",
       "      <td>0.318988</td>\n",
       "      <td>0.875461</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>120</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>08/21/21-163512</td>\n",
       "      <td>08/21/21-163551</td>\n",
       "      <td>39.512364</td>\n",
       "      <td>150</td>\n",
       "      <td>0.313996</td>\n",
       "      <td>0.877798</td>\n",
       "      <td>0.316271</td>\n",
       "      <td>0.875871</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>08/21/21-163551</td>\n",
       "      <td>08/21/21-163631</td>\n",
       "      <td>39.704157</td>\n",
       "      <td>150</td>\n",
       "      <td>0.319661</td>\n",
       "      <td>0.876130</td>\n",
       "      <td>0.316820</td>\n",
       "      <td>0.876690</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>08/21/21-163631</td>\n",
       "      <td>08/21/21-163709</td>\n",
       "      <td>37.885782</td>\n",
       "      <td>100</td>\n",
       "      <td>0.320013</td>\n",
       "      <td>0.875165</td>\n",
       "      <td>0.315719</td>\n",
       "      <td>0.876485</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>08/21/21-163709</td>\n",
       "      <td>08/21/21-163736</td>\n",
       "      <td>26.899813</td>\n",
       "      <td>100</td>\n",
       "      <td>0.315002</td>\n",
       "      <td>0.876833</td>\n",
       "      <td>0.317495</td>\n",
       "      <td>0.876485</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>240</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>08/21/21-163736</td>\n",
       "      <td>08/21/21-163930</td>\n",
       "      <td>113.365251</td>\n",
       "      <td>150</td>\n",
       "      <td>0.312233</td>\n",
       "      <td>0.878764</td>\n",
       "      <td>0.320588</td>\n",
       "      <td>0.876075</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>08/21/21-163930</td>\n",
       "      <td>08/21/21-163957</td>\n",
       "      <td>26.844901</td>\n",
       "      <td>100</td>\n",
       "      <td>0.314628</td>\n",
       "      <td>0.876481</td>\n",
       "      <td>0.317459</td>\n",
       "      <td>0.873617</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>240</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>08/21/21-163957</td>\n",
       "      <td>08/21/21-164109</td>\n",
       "      <td>72.772682</td>\n",
       "      <td>100</td>\n",
       "      <td>0.318960</td>\n",
       "      <td>0.876130</td>\n",
       "      <td>0.314043</td>\n",
       "      <td>0.877919</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>08/21/21-164110</td>\n",
       "      <td>08/21/21-164150</td>\n",
       "      <td>40.449511</td>\n",
       "      <td>150</td>\n",
       "      <td>0.311402</td>\n",
       "      <td>0.877710</td>\n",
       "      <td>0.318913</td>\n",
       "      <td>0.876895</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>240</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>08/21/21-164150</td>\n",
       "      <td>08/21/21-164229</td>\n",
       "      <td>38.770196</td>\n",
       "      <td>100</td>\n",
       "      <td>0.313640</td>\n",
       "      <td>0.876394</td>\n",
       "      <td>0.316750</td>\n",
       "      <td>0.873822</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>240</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>08/21/21-164229</td>\n",
       "      <td>08/21/21-164419</td>\n",
       "      <td>110.318695</td>\n",
       "      <td>150</td>\n",
       "      <td>0.312446</td>\n",
       "      <td>0.878325</td>\n",
       "      <td>0.323250</td>\n",
       "      <td>0.874846</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>240</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>08/21/21-164420</td>\n",
       "      <td>08/21/21-164516</td>\n",
       "      <td>56.362377</td>\n",
       "      <td>150</td>\n",
       "      <td>0.311565</td>\n",
       "      <td>0.878237</td>\n",
       "      <td>0.317957</td>\n",
       "      <td>0.876075</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>240</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>08/21/21-164516</td>\n",
       "      <td>08/21/21-164543</td>\n",
       "      <td>26.686513</td>\n",
       "      <td>100</td>\n",
       "      <td>0.318336</td>\n",
       "      <td>0.877359</td>\n",
       "      <td>0.316946</td>\n",
       "      <td>0.876075</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              start              end    duration  round_epochs      loss  \\\n",
       "0   08/21/21-161627  08/21/21-161654   27.428869           100  0.314192   \n",
       "1   08/21/21-161654  08/21/21-161847  112.313444           150  0.314628   \n",
       "2   08/21/21-161847  08/21/21-162001   73.792638           100  0.318849   \n",
       "3   08/21/21-162001  08/21/21-162027   26.533146           100  0.319753   \n",
       "4   08/21/21-162027  08/21/21-162254  146.847889           200  0.312867   \n",
       "5   08/21/21-162254  08/21/21-162333   38.282059           100  0.316513   \n",
       "6   08/21/21-162333  08/21/21-162447   74.685859           100  0.314151   \n",
       "7   08/21/21-162448  08/21/21-162546   58.378733           150  0.310814   \n",
       "8   08/21/21-162546  08/21/21-162625   38.974841           100  0.320476   \n",
       "9   08/21/21-162625  08/21/21-162740   75.203448           200  0.311862   \n",
       "10  08/21/21-162741  08/21/21-162839   58.540379           150  0.310996   \n",
       "11  08/21/21-162839  08/21/21-162938   58.507061           150  0.314198   \n",
       "12  08/21/21-162938  08/21/21-163030   51.777108           200  0.315389   \n",
       "13  08/21/21-163030  08/21/21-163144   74.617181           200  0.312768   \n",
       "14  08/21/21-163144  08/21/21-163222   37.679940           100  0.315743   \n",
       "15  08/21/21-163222  08/21/21-163302   39.469143           150  0.315568   \n",
       "16  08/21/21-163302  08/21/21-163419   77.099050           200  0.317142   \n",
       "17  08/21/21-163419  08/21/21-163512   52.598148           200  0.311672   \n",
       "18  08/21/21-163512  08/21/21-163551   39.512364           150  0.313996   \n",
       "19  08/21/21-163551  08/21/21-163631   39.704157           150  0.319661   \n",
       "20  08/21/21-163631  08/21/21-163709   37.885782           100  0.320013   \n",
       "21  08/21/21-163709  08/21/21-163736   26.899813           100  0.315002   \n",
       "22  08/21/21-163736  08/21/21-163930  113.365251           150  0.312233   \n",
       "23  08/21/21-163930  08/21/21-163957   26.844901           100  0.314628   \n",
       "24  08/21/21-163957  08/21/21-164109   72.772682           100  0.318960   \n",
       "25  08/21/21-164110  08/21/21-164150   40.449511           150  0.311402   \n",
       "26  08/21/21-164150  08/21/21-164229   38.770196           100  0.313640   \n",
       "27  08/21/21-164229  08/21/21-164419  110.318695           150  0.312446   \n",
       "28  08/21/21-164420  08/21/21-164516   56.362377           150  0.311565   \n",
       "29  08/21/21-164516  08/21/21-164543   26.686513           100  0.318336   \n",
       "\n",
       "    accuracy  val_loss  val_accuracy activation  batch_size  dropout  epochs  \\\n",
       "0   0.877008  0.313542      0.876485       relu          30        0     100   \n",
       "1   0.877710  0.316710      0.875871       relu          10        0     150   \n",
       "2   0.876657  0.316764      0.875666       relu          10        0     100   \n",
       "3   0.875252  0.314730      0.877100       relu          30        0     100   \n",
       "4   0.878588  0.320297      0.875256       relu          10        0     200   \n",
       "5   0.877008  0.317701      0.874027       relu          20        0     100   \n",
       "6   0.876657  0.320401      0.874846       relu          10        0     100   \n",
       "7   0.878325  0.319806      0.874846       relu          20        0     150   \n",
       "8   0.875165  0.316014      0.877100       relu          20        0     100   \n",
       "9   0.877623  0.319145      0.874027       relu          20        0     200   \n",
       "10  0.878149  0.319729      0.876075       relu          20        0     150   \n",
       "11  0.876569  0.316526      0.874642       relu          20        0     150   \n",
       "12  0.876833  0.315345      0.874846       relu          30        0     200   \n",
       "13  0.877886  0.316420      0.875461       relu          20        0     200   \n",
       "14  0.876745  0.322123      0.875051       relu          20        0     100   \n",
       "15  0.876657  0.316097      0.874642       relu          30        0     150   \n",
       "16  0.877008  0.318572      0.876690       relu          20        0     200   \n",
       "17  0.877096  0.318988      0.875461       relu          30        0     200   \n",
       "18  0.877798  0.316271      0.875871       relu          30        0     150   \n",
       "19  0.876130  0.316820      0.876690       relu          30        0     150   \n",
       "20  0.875165  0.315719      0.876485       relu          20        0     100   \n",
       "21  0.876833  0.317495      0.876485       relu          30        0     100   \n",
       "22  0.878764  0.320588      0.876075       relu          10        0     150   \n",
       "23  0.876481  0.317459      0.873617       relu          30        0     100   \n",
       "24  0.876130  0.314043      0.877919       relu          10        0     100   \n",
       "25  0.877710  0.318913      0.876895       relu          30        0     150   \n",
       "26  0.876394  0.316750      0.873822       relu          20        0     100   \n",
       "27  0.878325  0.323250      0.874846       relu          10        0     150   \n",
       "28  0.878237  0.317957      0.876075       relu          20        0     150   \n",
       "29  0.877359  0.316946      0.876075       relu          30        0     100   \n",
       "\n",
       "    first_neuron  hidden_layers last_activation               losses optimizer  \n",
       "0            240              1         sigmoid  binary_crossentropy      Adam  \n",
       "1             60              1         sigmoid  binary_crossentropy     Nadam  \n",
       "2             30              2         sigmoid  binary_crossentropy      Adam  \n",
       "3             30              2         sigmoid  binary_crossentropy     Nadam  \n",
       "4             60              2         sigmoid  binary_crossentropy     Nadam  \n",
       "5             60              2         sigmoid  binary_crossentropy      Adam  \n",
       "6            240              2         sigmoid  binary_crossentropy      Adam  \n",
       "7            240              1         sigmoid  binary_crossentropy      Adam  \n",
       "8             30              1         sigmoid  binary_crossentropy      Adam  \n",
       "9            120              1         sigmoid  binary_crossentropy     Nadam  \n",
       "10           240              2         sigmoid  binary_crossentropy      Adam  \n",
       "11           120              2         sigmoid  binary_crossentropy     Nadam  \n",
       "12            60              2         sigmoid  binary_crossentropy     Nadam  \n",
       "13            60              1         sigmoid  binary_crossentropy     Nadam  \n",
       "14           120              2         sigmoid  binary_crossentropy     Nadam  \n",
       "15            60              1         sigmoid  binary_crossentropy      Adam  \n",
       "16            30              2         sigmoid  binary_crossentropy      Adam  \n",
       "17           120              2         sigmoid  binary_crossentropy     Nadam  \n",
       "18           120              1         sigmoid  binary_crossentropy      Adam  \n",
       "19            30              1         sigmoid  binary_crossentropy     Nadam  \n",
       "20            30              1         sigmoid  binary_crossentropy     Nadam  \n",
       "21           240              2         sigmoid  binary_crossentropy     Nadam  \n",
       "22           120              1         sigmoid  binary_crossentropy      Adam  \n",
       "23           240              1         sigmoid  binary_crossentropy     Nadam  \n",
       "24            30              1         sigmoid  binary_crossentropy     Nadam  \n",
       "25           240              1         sigmoid  binary_crossentropy      Adam  \n",
       "26           240              1         sigmoid  binary_crossentropy     Nadam  \n",
       "27           240              2         sigmoid  binary_crossentropy     Nadam  \n",
       "28           240              1         sigmoid  binary_crossentropy     Nadam  \n",
       "29            60              2         sigmoid  binary_crossentropy      Adam  "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display a dataframe comapring the results of the different combinations \n",
    "t.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the model with the optimised paramaters \n",
    "\n",
    "p_optimisied = {'first_neuron':30,\n",
    "#                 'second_neuron':15,\n",
    "                'hidden_layers':1,\n",
    "                'batch_size': 10,\n",
    "                'epochs': 100,\n",
    "                'dropout': 0,\n",
    "                'optimizer': 'Nadam',\n",
    "                'activation':'relu',\n",
    "               }\n",
    "\n",
    "def everest_optimised(x_train, y_train, params):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(params['first_neuron'], input_dim=x_train.shape[1], \n",
    "              activation=params['activation']))\n",
    "    \n",
    "#     model.add(Dense(params['second_neuron'], activation=params['activation']))\n",
    " \n",
    "    model.add(Dropout(params['dropout']))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=params['optimizer'], metrics=['accuracy'])\n",
    "    \n",
    "    out = model.fit(x_train, \n",
    "                    y_train,\n",
    "                    epochs=params['epochs'],\n",
    "                    batch_size=params['batch_size'],\n",
    "                    verbose=0)\n",
    "\n",
    "    return out, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-fit the training data to the model\n",
    "out, model = everest_optimised(X_train_scaled, encoded_y_train, p_optimisied)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 - 0s - loss: 0.3124 - accuracy: 0.8796\n",
      "Neural Network Performace - Loss: 0.31235188245773315, Accuracy: 0.8796313405036926\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(X_test_scaled, encoded_y_test, verbose=2)\n",
    "print(f\"Neural Network Performace - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 540x540 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a confusion matrix to visualise the performance of the adjusted model\n",
    "predictions = np.argmax(model.predict(X_test_scaled), axis=-1)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true=encoded_y_test, y_pred=predictions)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
    "\n",
    "ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)\n",
    "\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        ax.text(x=j, y=i, s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
    "\n",
    "plt.title('Confusion Matrix', fontsize=18)\n",
    "plt.xlabel('Predictions', fontsize=18)\n",
    "ax.set_xticks([0,1])\n",
    "ax.set_xticklabels(target_names)\n",
    "plt.ylabel('Actuals', fontsize=18)\n",
    "ax.set_yticks([0,1])\n",
    "ax.set_yticklabels(target_names)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "filename = 'success_model.h5'\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(\"Model 2 - Deep_learning.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "dev"
  },
  "kernelspec": {
   "display_name": "Python [conda env:PythonData] *",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
