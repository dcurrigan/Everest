{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import tensorflow\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the CSV and Perform Basic Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "df = pd.read_csv(\"clean_data.csv\", low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['expid', 'membid', 'myear', 'fname', 'lname', 'sex', 'calcage',\n",
       "       'citizen', 'occupation', 'sherpa', 'tibetan', 'msolo', 'msuccess',\n",
       "       'mhighpt', 'mperhighpt', 'msmtdate1', 'msmtdate2', 'msmtdate3',\n",
       "       'msmttime1', 'msmttime2', 'msmttime3', 'bconly', 'nottobc', 'route1',\n",
       "       'route2', 'route3', 'route4', 'mo2used', 'mo2none', 'mo2climb',\n",
       "       'mo2descent', 'mo2sleep', 'death', 'deathdate', 'deathhgtm', 'msmtbid',\n",
       "       'nohired', 'hired', 'new_route'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View column names and drop unnecesary columns for the model \n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the unnecessary columns \n",
    "df.drop(['expid', 'membid', 'fname', 'lname', 'mperhighpt', 'msmtdate1', 'msmtdate2', 'msmtdate3',\n",
    "         'msmttime1', 'msmttime2', 'msmttime3', 'deathdate', 'deathhgtm', 'route2', 'route3', 'route4', 'msmtbid'], \n",
    "          axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Definitions\n",
    "\n",
    "<b>expid</b> - Expedition id \n",
    "\n",
    "<b>membid</b> - Member id\n",
    "\n",
    "<b>*NOTE:*</b> - Individual record id is compound key of expedition id + member id\n",
    "\n",
    "-----\n",
    "\n",
    "<b>bconly</b> - BC / Advanced BC only (Y/N) if yes, The member did not climb above base camp (or advanced\n",
    "base camp in cases where the path from base camp does not require technical climbing skills) \n",
    "  \n",
    "<b>nottobc</b> - Not to base camp (Y/N) if yes, The member did not reach base camp\n",
    "\n",
    "<b>hired</b> - The person was hired by the expedition\n",
    "\n",
    "<b>msolo</b> - Solo (Y/N)\n",
    "\n",
    "<b>sherpa</b> - Sherpa (Y/N) \n",
    "\n",
    "<b>tibetan</b> - Tibetan (Y/N)\n",
    "\n",
    "<b>mhighpt</b> - Expedition high-point reached (Y/N)\n",
    "\n",
    "<b>mperhighpt</b> - Personal high-point (m)\n",
    "\n",
    "<b>msmdate1</b> - 1st summit / high-point date\n",
    "\n",
    "<b>msmdate2</b> - 2nd summit date\n",
    "\n",
    "<b>msmdate3</b> - 3rd summit date\n",
    "\n",
    "<b>mroute1</b> - 1st ascent route\n",
    "\n",
    "<b>mroute2</b> - 2nd ascent route\n",
    "\n",
    "<b>mroute3</b> - 3rd ascent route\n",
    "\n",
    "<b>mo2used</b> - Oxygen used (Y/N)\n",
    "\n",
    "<b>mo2none</b> - Oxygen not used (Y/N)\n",
    "\n",
    "<b>deathhgtm</b> - Death Height (m)\n",
    "\n",
    "<b>msmtbid</b> - Summit Bid:\n",
    "```\n",
    "0 – Unspecified\n",
    "1 – No summit bid\n",
    "2 – Aborted below high camp\n",
    "3 – Aborted at high camp\n",
    "4 – Aborted above high camp\n",
    "5 – Successful summit bid\n",
    "```\n",
    "<b>nohired</b> - No hired personnel used (above BC)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set features\n",
    "# X = df.drop('msuccess', axis=1)\n",
    "\n",
    "# feature_names = ['myear', 'sex', 'calcage', 'citizen', 'sherpa', 'tibetan', 'msolo',\n",
    "#                  'mhighpt', 'bconly', 'nottobc', 'route1', 'mo2used',\n",
    "#                  'mo2none', 'death', 'nohired', 'hired', 'occupation']\n",
    "\n",
    "feature_names = ['sex', 'calcage', 'citizen', 'msolo', 'new_route', 'mo2used', 'mo2climb',\n",
    "                 'mo2descent', 'mo2sleep', 'nohired']\n",
    "\n",
    "X = df[feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>calcage</th>\n",
       "      <th>citizen</th>\n",
       "      <th>msolo</th>\n",
       "      <th>new_route</th>\n",
       "      <th>mo2used</th>\n",
       "      <th>mo2climb</th>\n",
       "      <th>mo2descent</th>\n",
       "      <th>mo2sleep</th>\n",
       "      <th>nohired</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21696</th>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21697</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21698</th>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21699</th>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21700</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21701 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sex  calcage  citizen  msolo  new_route  mo2used  mo2climb  mo2descent  \\\n",
       "0        0       49       15    0.0          2      0.0       0.0         0.0   \n",
       "1        1       30       89    0.0          2      0.0       0.0         0.0   \n",
       "2        0       32       15    0.0          2      1.0       1.0         0.0   \n",
       "3        0       40       85    0.0          2      0.0       0.0         0.0   \n",
       "4        0       29       85    0.0          2      1.0       1.0         0.0   \n",
       "...    ...      ...      ...    ...        ...      ...       ...         ...   \n",
       "21696    0       47       28    0.0          0      1.0       1.0         0.0   \n",
       "21697    0        0       28    0.0          0      1.0       1.0         0.0   \n",
       "21698    0       57       28    0.0          0      1.0       1.0         0.0   \n",
       "21699    0       35       28    0.0          0      1.0       1.0         0.0   \n",
       "21700    0        0       28    0.0          0      1.0       1.0         0.0   \n",
       "\n",
       "       mo2sleep  nohired  \n",
       "0           0.0      0.0  \n",
       "1           0.0      0.0  \n",
       "2           1.0      0.0  \n",
       "3           0.0      0.0  \n",
       "4           1.0      0.0  \n",
       "...         ...      ...  \n",
       "21696       0.0      0.0  \n",
       "21697       1.0      0.0  \n",
       "21698       1.0      0.0  \n",
       "21699       1.0      0.0  \n",
       "21700       1.0      0.0  \n",
       "\n",
       "[21701 rows x 10 columns]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert X values to numerical \n",
    "\n",
    "###            KEY             ### \n",
    "###    Male = 1, Female = 0    ###\n",
    "###    True = 1, False = 0     ###\n",
    "###  Citizen and Route = many  ###\n",
    "\n",
    "X.replace(True, 1, inplace=True)\n",
    "X['sex'] = pd.get_dummies(X['sex'])\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = preprocessing.LabelEncoder()\n",
    "X['citizen'] = le.fit_transform(X['citizen'])\n",
    "X['new_route'] = le.fit_transform(X['new_route'])\n",
    "# X['occupation'] = le.fit_transform(X['occupation'])\n",
    "\n",
    "X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True])"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_names = df['msuccess'].unique()\n",
    "target_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "y  = df['msuccess']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Train Test Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "Scale the data using the MinMaxScaler and perform some feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create the scaler\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "\n",
    "# Transform the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       ...,\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the y values to numerical using label_encoder/to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)\n",
    "y_test_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model and add layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "inputs = X_train.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=60, activation='relu', input_dim=inputs))\n",
    "model.add(Dense(units=200, activation='relu'))\n",
    "model.add(Dense(units=2, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 17 features, but MinMaxScaler is expecting 7 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-236-8a63840c2d97>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m19\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m34\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m21\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtest_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_scaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m         X = self._validate_data(X, copy=self.copy, dtype=FLOAT_DTYPES,\n\u001b[1;32m--> 435\u001b[1;33m                                 force_all_finite=\"allow-nan\", reset=False)\n\u001b[0m\u001b[0;32m    436\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ensure_2d'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 437\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    364\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m             raise ValueError(\n\u001b[1;32m--> 366\u001b[1;33m                 \u001b[1;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    367\u001b[0m                 f\"is expecting {self.n_features_in_} features as input.\")\n\u001b[0;32m    368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: X has 17 features, but MinMaxScaler is expecting 7 features as input."
     ]
    }
   ],
   "source": [
    "sample = [[15,  12, 100, 8, 19, 0, 3, 25, 34, 21, 1, 1, 0, 7, 2, 1, 7]]\n",
    "test_values = X_scaler.transform(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_21 (Dense)             (None, 60)                660       \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 200)               12200     \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 2)                 402       \n",
      "=================================================================\n",
      "Total params: 13,262\n",
      "Trainable params: 13,262\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "509/509 - 0s - loss: 0.3154 - accuracy: 0.8796\n",
      "Epoch 2/100\n",
      "509/509 - 0s - loss: 0.3152 - accuracy: 0.8800\n",
      "Epoch 3/100\n",
      "509/509 - 0s - loss: 0.3149 - accuracy: 0.8806\n",
      "Epoch 4/100\n",
      "509/509 - 0s - loss: 0.3148 - accuracy: 0.8800\n",
      "Epoch 5/100\n",
      "509/509 - 0s - loss: 0.3133 - accuracy: 0.8798\n",
      "Epoch 6/100\n",
      "509/509 - 0s - loss: 0.3145 - accuracy: 0.8795\n",
      "Epoch 7/100\n",
      "509/509 - 0s - loss: 0.3136 - accuracy: 0.8797\n",
      "Epoch 8/100\n",
      "509/509 - 0s - loss: 0.3138 - accuracy: 0.8806\n",
      "Epoch 9/100\n",
      "509/509 - 0s - loss: 0.3124 - accuracy: 0.8812\n",
      "Epoch 10/100\n",
      "509/509 - 0s - loss: 0.3124 - accuracy: 0.8808\n",
      "Epoch 11/100\n",
      "509/509 - 0s - loss: 0.3114 - accuracy: 0.8809\n",
      "Epoch 12/100\n",
      "509/509 - 0s - loss: 0.3111 - accuracy: 0.8806\n",
      "Epoch 13/100\n",
      "509/509 - 0s - loss: 0.3109 - accuracy: 0.8812\n",
      "Epoch 14/100\n",
      "509/509 - 0s - loss: 0.3111 - accuracy: 0.8816\n",
      "Epoch 15/100\n",
      "509/509 - 0s - loss: 0.3105 - accuracy: 0.8807\n",
      "Epoch 16/100\n",
      "509/509 - 0s - loss: 0.3097 - accuracy: 0.8812\n",
      "Epoch 17/100\n",
      "509/509 - 0s - loss: 0.3098 - accuracy: 0.8810\n",
      "Epoch 18/100\n",
      "509/509 - 0s - loss: 0.3098 - accuracy: 0.8813\n",
      "Epoch 19/100\n",
      "509/509 - 0s - loss: 0.3097 - accuracy: 0.8812\n",
      "Epoch 20/100\n",
      "509/509 - 0s - loss: 0.3085 - accuracy: 0.8817\n",
      "Epoch 21/100\n",
      "509/509 - 0s - loss: 0.3090 - accuracy: 0.8818\n",
      "Epoch 22/100\n",
      "509/509 - 0s - loss: 0.3084 - accuracy: 0.8812\n",
      "Epoch 23/100\n",
      "509/509 - 0s - loss: 0.3078 - accuracy: 0.8816\n",
      "Epoch 24/100\n",
      "509/509 - 0s - loss: 0.3082 - accuracy: 0.8820\n",
      "Epoch 25/100\n",
      "509/509 - 0s - loss: 0.3074 - accuracy: 0.8817\n",
      "Epoch 26/100\n",
      "509/509 - 0s - loss: 0.3071 - accuracy: 0.8810\n",
      "Epoch 27/100\n",
      "509/509 - 0s - loss: 0.3068 - accuracy: 0.8811\n",
      "Epoch 28/100\n",
      "509/509 - 0s - loss: 0.3071 - accuracy: 0.8816\n",
      "Epoch 29/100\n",
      "509/509 - 0s - loss: 0.3069 - accuracy: 0.8823\n",
      "Epoch 30/100\n",
      "509/509 - 0s - loss: 0.3062 - accuracy: 0.8817\n",
      "Epoch 31/100\n",
      "509/509 - 0s - loss: 0.3066 - accuracy: 0.8818\n",
      "Epoch 32/100\n",
      "509/509 - 0s - loss: 0.3061 - accuracy: 0.8820\n",
      "Epoch 33/100\n",
      "509/509 - 0s - loss: 0.3059 - accuracy: 0.8817\n",
      "Epoch 34/100\n",
      "509/509 - 0s - loss: 0.3052 - accuracy: 0.8823\n",
      "Epoch 35/100\n",
      "509/509 - 0s - loss: 0.3063 - accuracy: 0.8817\n",
      "Epoch 36/100\n",
      "509/509 - 0s - loss: 0.3062 - accuracy: 0.8822\n",
      "Epoch 37/100\n",
      "509/509 - 0s - loss: 0.3055 - accuracy: 0.8820\n",
      "Epoch 38/100\n",
      "509/509 - 0s - loss: 0.3050 - accuracy: 0.8819\n",
      "Epoch 39/100\n",
      "509/509 - 0s - loss: 0.3046 - accuracy: 0.8814\n",
      "Epoch 40/100\n",
      "509/509 - 0s - loss: 0.3047 - accuracy: 0.8818\n",
      "Epoch 41/100\n",
      "509/509 - 0s - loss: 0.3042 - accuracy: 0.8829\n",
      "Epoch 42/100\n",
      "509/509 - 0s - loss: 0.3044 - accuracy: 0.8823\n",
      "Epoch 43/100\n",
      "509/509 - 0s - loss: 0.3042 - accuracy: 0.8829\n",
      "Epoch 44/100\n",
      "509/509 - 0s - loss: 0.3044 - accuracy: 0.8818\n",
      "Epoch 45/100\n",
      "509/509 - 0s - loss: 0.3045 - accuracy: 0.8821\n",
      "Epoch 46/100\n",
      "509/509 - 0s - loss: 0.3042 - accuracy: 0.8825\n",
      "Epoch 47/100\n",
      "509/509 - 0s - loss: 0.3032 - accuracy: 0.8829\n",
      "Epoch 48/100\n",
      "509/509 - 0s - loss: 0.3032 - accuracy: 0.8817\n",
      "Epoch 49/100\n",
      "509/509 - 0s - loss: 0.3032 - accuracy: 0.8824\n",
      "Epoch 50/100\n",
      "509/509 - 0s - loss: 0.3032 - accuracy: 0.8826\n",
      "Epoch 51/100\n",
      "509/509 - 0s - loss: 0.3029 - accuracy: 0.8823\n",
      "Epoch 52/100\n",
      "509/509 - 0s - loss: 0.3024 - accuracy: 0.8818\n",
      "Epoch 53/100\n",
      "509/509 - 0s - loss: 0.3024 - accuracy: 0.8831\n",
      "Epoch 54/100\n",
      "509/509 - 0s - loss: 0.3027 - accuracy: 0.8825\n",
      "Epoch 55/100\n",
      "509/509 - 0s - loss: 0.3033 - accuracy: 0.8814\n",
      "Epoch 56/100\n",
      "509/509 - 0s - loss: 0.3023 - accuracy: 0.8828\n",
      "Epoch 57/100\n",
      "509/509 - 0s - loss: 0.3019 - accuracy: 0.8834\n",
      "Epoch 58/100\n",
      "509/509 - 0s - loss: 0.3013 - accuracy: 0.8829\n",
      "Epoch 59/100\n",
      "509/509 - 0s - loss: 0.3017 - accuracy: 0.8819\n",
      "Epoch 60/100\n",
      "509/509 - 0s - loss: 0.3010 - accuracy: 0.8833\n",
      "Epoch 61/100\n",
      "509/509 - 0s - loss: 0.3015 - accuracy: 0.8829\n",
      "Epoch 62/100\n",
      "509/509 - 0s - loss: 0.3012 - accuracy: 0.8832\n",
      "Epoch 63/100\n",
      "509/509 - 0s - loss: 0.3011 - accuracy: 0.8829\n",
      "Epoch 64/100\n",
      "509/509 - 0s - loss: 0.3004 - accuracy: 0.8832\n",
      "Epoch 65/100\n",
      "509/509 - 0s - loss: 0.3014 - accuracy: 0.8823\n",
      "Epoch 66/100\n",
      "509/509 - 0s - loss: 0.3008 - accuracy: 0.8830\n",
      "Epoch 67/100\n",
      "509/509 - 0s - loss: 0.3007 - accuracy: 0.8831\n",
      "Epoch 68/100\n",
      "509/509 - 0s - loss: 0.3012 - accuracy: 0.8828\n",
      "Epoch 69/100\n",
      "509/509 - 0s - loss: 0.3005 - accuracy: 0.8822\n",
      "Epoch 70/100\n",
      "509/509 - 0s - loss: 0.2997 - accuracy: 0.8831\n",
      "Epoch 71/100\n",
      "509/509 - 0s - loss: 0.3004 - accuracy: 0.8826\n",
      "Epoch 72/100\n",
      "509/509 - 0s - loss: 0.3001 - accuracy: 0.8824\n",
      "Epoch 73/100\n",
      "509/509 - 0s - loss: 0.3001 - accuracy: 0.8827\n",
      "Epoch 74/100\n",
      "509/509 - 0s - loss: 0.3005 - accuracy: 0.8836\n",
      "Epoch 75/100\n",
      "509/509 - 0s - loss: 0.3003 - accuracy: 0.8833\n",
      "Epoch 76/100\n",
      "509/509 - 0s - loss: 0.2998 - accuracy: 0.8834\n",
      "Epoch 77/100\n",
      "509/509 - 0s - loss: 0.3001 - accuracy: 0.8831\n",
      "Epoch 78/100\n",
      "509/509 - 0s - loss: 0.3001 - accuracy: 0.8835\n",
      "Epoch 79/100\n",
      "509/509 - 0s - loss: 0.2996 - accuracy: 0.8831\n",
      "Epoch 80/100\n",
      "509/509 - 0s - loss: 0.2992 - accuracy: 0.8837\n",
      "Epoch 81/100\n",
      "509/509 - 0s - loss: 0.2991 - accuracy: 0.8830\n",
      "Epoch 82/100\n",
      "509/509 - 0s - loss: 0.2987 - accuracy: 0.8831\n",
      "Epoch 83/100\n",
      "509/509 - 0s - loss: 0.2991 - accuracy: 0.8828\n",
      "Epoch 84/100\n",
      "509/509 - 0s - loss: 0.2989 - accuracy: 0.8836\n",
      "Epoch 85/100\n",
      "509/509 - 0s - loss: 0.2994 - accuracy: 0.8834\n",
      "Epoch 86/100\n",
      "509/509 - 0s - loss: 0.2989 - accuracy: 0.8828\n",
      "Epoch 87/100\n",
      "509/509 - 0s - loss: 0.2985 - accuracy: 0.8829\n",
      "Epoch 88/100\n",
      "509/509 - 0s - loss: 0.2987 - accuracy: 0.8828\n",
      "Epoch 89/100\n",
      "509/509 - 0s - loss: 0.2980 - accuracy: 0.8833\n",
      "Epoch 90/100\n",
      "509/509 - 0s - loss: 0.2985 - accuracy: 0.8829\n",
      "Epoch 91/100\n",
      "509/509 - 0s - loss: 0.2989 - accuracy: 0.8829\n",
      "Epoch 92/100\n",
      "509/509 - 0s - loss: 0.2987 - accuracy: 0.8844\n",
      "Epoch 93/100\n",
      "509/509 - 0s - loss: 0.2981 - accuracy: 0.8832\n",
      "Epoch 94/100\n",
      "509/509 - 0s - loss: 0.2981 - accuracy: 0.8839\n",
      "Epoch 95/100\n",
      "509/509 - 0s - loss: 0.2981 - accuracy: 0.8835\n",
      "Epoch 96/100\n",
      "509/509 - 0s - loss: 0.2978 - accuracy: 0.8844\n",
      "Epoch 97/100\n",
      "509/509 - 0s - loss: 0.2976 - accuracy: 0.8834\n",
      "Epoch 98/100\n",
      "509/509 - 0s - loss: 0.2980 - accuracy: 0.8840\n",
      "Epoch 99/100\n",
      "509/509 - 0s - loss: 0.2971 - accuracy: 0.8838\n",
      "Epoch 100/100\n",
      "509/509 - 0s - loss: 0.2979 - accuracy: 0.8844\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20c8912f6a0>"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    verbose=2,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantify Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 - 0s - loss: 0.3251 - accuracy: 0.8734\n",
      "Normal Neural Network - Loss: 0.3250739276409149, Accuracy: 0.8733873963356018\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(f\"Neural Network Performace - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chance of success for datapoint 5000 is: 57.86%\n"
     ]
    }
   ],
   "source": [
    "result = np.array([X_train_scaled[5000]])\n",
    "result = model.predict(result)\n",
    "print(f\"Chance of success for datapoint 5000 is: {round(result[0][1]*100,2)}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 540x540 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a confusion matrix to visualise the performance \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "predictions = np.argmax(model.predict(X_test_scaled), axis=-1)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true=encoded_y_test, y_pred=predictions)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
    "\n",
    "ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)\n",
    "\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        ax.text(x=j, y=i, s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
    "\n",
    "plt.title('Confusion Matrix', fontsize=18)\n",
    "plt.xlabel('Predictions', fontsize=18)\n",
    "ax.set_xticks([0,1,2])\n",
    "ax.set_xticklabels(target_names)\n",
    "plt.ylabel('Actuals', fontsize=18)\n",
    "ax.set_yticks([0,1,2])\n",
    "ax.set_yticklabels(target_names)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['calcage', 'citizen', 'new_route', 'mo2climb', 'mo2sleep'], dtype='object')"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use recursive feature elimination to identify the best performing features\n",
    "from sklearn.feature_selection import RFECV\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "# Initiate RFE cross-validation and fit with a linear regression model\n",
    "rfecv = RFECV(\n",
    "    estimator=tree.DecisionTreeClassifier(),\n",
    "    min_features_to_select=5,\n",
    "    step=5,\n",
    "    n_jobs=-1,\n",
    "    scoring=\"r2\",\n",
    "    cv=5,\n",
    ")\n",
    "\n",
    "_ = rfecv.fit(X_train_scaled, encoded_y_train)\n",
    "\n",
    "# Print the best columns\n",
    "X_train.columns[rfecv.support_]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-select the features based on the RFE\n",
    "feature_names = ['calcage', 'citizen', 'new_route', 'mo2climb', 'mo2sleep']\n",
    "\n",
    "X_train = X_train[feature_names]\n",
    "X_test = X_test[feature_names]\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "509/509 - 1s - loss: 0.3488 - accuracy: 0.8723\n",
      "Epoch 2/100\n",
      "509/509 - 0s - loss: 0.3294 - accuracy: 0.8753\n",
      "Epoch 3/100\n",
      "509/509 - 0s - loss: 0.3273 - accuracy: 0.8767\n",
      "Epoch 4/100\n",
      "509/509 - 0s - loss: 0.3255 - accuracy: 0.8760\n",
      "Epoch 5/100\n",
      "509/509 - 0s - loss: 0.3228 - accuracy: 0.8773\n",
      "Epoch 6/100\n",
      "509/509 - 0s - loss: 0.3229 - accuracy: 0.8764\n",
      "Epoch 7/100\n",
      "509/509 - 0s - loss: 0.3213 - accuracy: 0.8772\n",
      "Epoch 8/100\n",
      "509/509 - 0s - loss: 0.3213 - accuracy: 0.8762\n",
      "Epoch 9/100\n",
      "509/509 - 0s - loss: 0.3200 - accuracy: 0.8776\n",
      "Epoch 10/100\n",
      "509/509 - 0s - loss: 0.3196 - accuracy: 0.8774\n",
      "Epoch 11/100\n",
      "509/509 - 0s - loss: 0.3199 - accuracy: 0.8777\n",
      "Epoch 12/100\n",
      "509/509 - 0s - loss: 0.3192 - accuracy: 0.8772\n",
      "Epoch 13/100\n",
      "509/509 - 0s - loss: 0.3183 - accuracy: 0.8778\n",
      "Epoch 14/100\n",
      "509/509 - 0s - loss: 0.3179 - accuracy: 0.8776\n",
      "Epoch 15/100\n",
      "509/509 - 0s - loss: 0.3182 - accuracy: 0.8777\n",
      "Epoch 16/100\n",
      "509/509 - 0s - loss: 0.3179 - accuracy: 0.8778\n",
      "Epoch 17/100\n",
      "509/509 - 0s - loss: 0.3169 - accuracy: 0.8785\n",
      "Epoch 18/100\n",
      "509/509 - 0s - loss: 0.3172 - accuracy: 0.8786\n",
      "Epoch 19/100\n",
      "509/509 - 0s - loss: 0.3165 - accuracy: 0.8791\n",
      "Epoch 20/100\n",
      "509/509 - 0s - loss: 0.3164 - accuracy: 0.8791\n",
      "Epoch 21/100\n",
      "509/509 - 0s - loss: 0.3159 - accuracy: 0.8791\n",
      "Epoch 22/100\n",
      "509/509 - 0s - loss: 0.3154 - accuracy: 0.8784\n",
      "Epoch 23/100\n",
      "509/509 - 0s - loss: 0.3162 - accuracy: 0.8785\n",
      "Epoch 24/100\n",
      "509/509 - 0s - loss: 0.3149 - accuracy: 0.8782\n",
      "Epoch 25/100\n",
      "509/509 - 0s - loss: 0.3152 - accuracy: 0.8789\n",
      "Epoch 26/100\n",
      "509/509 - 0s - loss: 0.3147 - accuracy: 0.8794\n",
      "Epoch 27/100\n",
      "509/509 - 0s - loss: 0.3149 - accuracy: 0.8794\n",
      "Epoch 28/100\n",
      "509/509 - 0s - loss: 0.3148 - accuracy: 0.8793\n",
      "Epoch 29/100\n",
      "509/509 - 0s - loss: 0.3150 - accuracy: 0.8793\n",
      "Epoch 30/100\n",
      "509/509 - 0s - loss: 0.3141 - accuracy: 0.8793\n",
      "Epoch 31/100\n",
      "509/509 - 0s - loss: 0.3142 - accuracy: 0.8796\n",
      "Epoch 32/100\n",
      "509/509 - 0s - loss: 0.3137 - accuracy: 0.8798\n",
      "Epoch 33/100\n",
      "509/509 - 0s - loss: 0.3134 - accuracy: 0.8804\n",
      "Epoch 34/100\n",
      "509/509 - 0s - loss: 0.3140 - accuracy: 0.8800\n",
      "Epoch 35/100\n",
      "509/509 - 0s - loss: 0.3133 - accuracy: 0.8805\n",
      "Epoch 36/100\n",
      "509/509 - 0s - loss: 0.3132 - accuracy: 0.8803\n",
      "Epoch 37/100\n",
      "509/509 - 0s - loss: 0.3131 - accuracy: 0.8806\n",
      "Epoch 38/100\n",
      "509/509 - 0s - loss: 0.3130 - accuracy: 0.8806\n",
      "Epoch 39/100\n",
      "509/509 - 0s - loss: 0.3127 - accuracy: 0.8803\n",
      "Epoch 40/100\n",
      "509/509 - 0s - loss: 0.3122 - accuracy: 0.8802\n",
      "Epoch 41/100\n",
      "509/509 - 0s - loss: 0.3125 - accuracy: 0.8804\n",
      "Epoch 42/100\n",
      "509/509 - 0s - loss: 0.3118 - accuracy: 0.8810\n",
      "Epoch 43/100\n",
      "509/509 - 0s - loss: 0.3122 - accuracy: 0.8799\n",
      "Epoch 44/100\n",
      "509/509 - 0s - loss: 0.3122 - accuracy: 0.8794\n",
      "Epoch 45/100\n",
      "509/509 - 0s - loss: 0.3118 - accuracy: 0.8804\n",
      "Epoch 46/100\n",
      "509/509 - 0s - loss: 0.3120 - accuracy: 0.8803\n",
      "Epoch 47/100\n",
      "509/509 - 0s - loss: 0.3118 - accuracy: 0.8806\n",
      "Epoch 48/100\n",
      "509/509 - 0s - loss: 0.3104 - accuracy: 0.8811\n",
      "Epoch 49/100\n",
      "509/509 - 0s - loss: 0.3112 - accuracy: 0.8803\n",
      "Epoch 50/100\n",
      "509/509 - 0s - loss: 0.3112 - accuracy: 0.8816\n",
      "Epoch 51/100\n",
      "509/509 - 0s - loss: 0.3113 - accuracy: 0.8804\n",
      "Epoch 52/100\n",
      "509/509 - 0s - loss: 0.3114 - accuracy: 0.8803\n",
      "Epoch 53/100\n",
      "509/509 - 0s - loss: 0.3104 - accuracy: 0.8809\n",
      "Epoch 54/100\n",
      "509/509 - 0s - loss: 0.3105 - accuracy: 0.8799\n",
      "Epoch 55/100\n",
      "509/509 - 0s - loss: 0.3105 - accuracy: 0.8808\n",
      "Epoch 56/100\n",
      "509/509 - 0s - loss: 0.3111 - accuracy: 0.8796\n",
      "Epoch 57/100\n",
      "509/509 - 0s - loss: 0.3100 - accuracy: 0.8813\n",
      "Epoch 58/100\n",
      "509/509 - 0s - loss: 0.3103 - accuracy: 0.8807\n",
      "Epoch 59/100\n",
      "509/509 - 0s - loss: 0.3106 - accuracy: 0.8804\n",
      "Epoch 60/100\n",
      "509/509 - 0s - loss: 0.3098 - accuracy: 0.8806\n",
      "Epoch 61/100\n",
      "509/509 - 0s - loss: 0.3101 - accuracy: 0.8804\n",
      "Epoch 62/100\n",
      "509/509 - 0s - loss: 0.3100 - accuracy: 0.8807\n",
      "Epoch 63/100\n",
      "509/509 - 0s - loss: 0.3100 - accuracy: 0.8809\n",
      "Epoch 64/100\n",
      "509/509 - 0s - loss: 0.3100 - accuracy: 0.8808\n",
      "Epoch 65/100\n",
      "509/509 - 0s - loss: 0.3094 - accuracy: 0.8804\n",
      "Epoch 66/100\n",
      "509/509 - 0s - loss: 0.3101 - accuracy: 0.8808\n",
      "Epoch 67/100\n",
      "509/509 - 0s - loss: 0.3098 - accuracy: 0.8810\n",
      "Epoch 68/100\n",
      "509/509 - 0s - loss: 0.3099 - accuracy: 0.8806\n",
      "Epoch 69/100\n",
      "509/509 - 0s - loss: 0.3090 - accuracy: 0.8801\n",
      "Epoch 70/100\n",
      "509/509 - 0s - loss: 0.3098 - accuracy: 0.8812\n",
      "Epoch 71/100\n",
      "509/509 - 0s - loss: 0.3094 - accuracy: 0.8814\n",
      "Epoch 72/100\n",
      "509/509 - 0s - loss: 0.3092 - accuracy: 0.8802\n",
      "Epoch 73/100\n",
      "509/509 - 0s - loss: 0.3089 - accuracy: 0.8801\n",
      "Epoch 74/100\n",
      "509/509 - 0s - loss: 0.3090 - accuracy: 0.8812\n",
      "Epoch 75/100\n",
      "509/509 - 0s - loss: 0.3090 - accuracy: 0.8807\n",
      "Epoch 76/100\n",
      "509/509 - 0s - loss: 0.3094 - accuracy: 0.8805\n",
      "Epoch 77/100\n",
      "509/509 - 0s - loss: 0.3081 - accuracy: 0.8815\n",
      "Epoch 78/100\n",
      "509/509 - 0s - loss: 0.3091 - accuracy: 0.8803\n",
      "Epoch 79/100\n",
      "509/509 - 0s - loss: 0.3088 - accuracy: 0.8802\n",
      "Epoch 80/100\n",
      "509/509 - 0s - loss: 0.3088 - accuracy: 0.8812\n",
      "Epoch 81/100\n",
      "509/509 - 0s - loss: 0.3089 - accuracy: 0.8821\n",
      "Epoch 82/100\n",
      "509/509 - 0s - loss: 0.3081 - accuracy: 0.8808\n",
      "Epoch 83/100\n",
      "509/509 - 0s - loss: 0.3085 - accuracy: 0.8810\n",
      "Epoch 84/100\n",
      "509/509 - 0s - loss: 0.3082 - accuracy: 0.8806\n",
      "Epoch 85/100\n",
      "509/509 - 0s - loss: 0.3081 - accuracy: 0.8811\n",
      "Epoch 86/100\n",
      "509/509 - 0s - loss: 0.3088 - accuracy: 0.8815\n",
      "Epoch 87/100\n",
      "509/509 - 0s - loss: 0.3079 - accuracy: 0.8801\n",
      "Epoch 88/100\n",
      "509/509 - 0s - loss: 0.3090 - accuracy: 0.8815\n",
      "Epoch 89/100\n",
      "509/509 - 0s - loss: 0.3078 - accuracy: 0.8814\n",
      "Epoch 90/100\n",
      "509/509 - 0s - loss: 0.3074 - accuracy: 0.8817\n",
      "Epoch 91/100\n",
      "509/509 - 0s - loss: 0.3079 - accuracy: 0.8806\n",
      "Epoch 92/100\n",
      "509/509 - 0s - loss: 0.3082 - accuracy: 0.8816\n",
      "Epoch 93/100\n",
      "509/509 - 0s - loss: 0.3081 - accuracy: 0.8809\n",
      "Epoch 94/100\n",
      "509/509 - 0s - loss: 0.3075 - accuracy: 0.8818\n",
      "Epoch 95/100\n",
      "509/509 - 0s - loss: 0.3075 - accuracy: 0.8817\n",
      "Epoch 96/100\n",
      "509/509 - 0s - loss: 0.3079 - accuracy: 0.8811\n",
      "Epoch 97/100\n",
      "509/509 - 0s - loss: 0.3074 - accuracy: 0.8817\n",
      "Epoch 98/100\n",
      "509/509 - 0s - loss: 0.3078 - accuracy: 0.8818\n",
      "Epoch 99/100\n",
      "509/509 - 0s - loss: 0.3073 - accuracy: 0.8811\n",
      "Epoch 100/100\n",
      "509/509 - 0s - loss: 0.3073 - accuracy: 0.8804\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20c8a84ed68>"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Re-run the model with the new-feature selections\n",
    "inputs = X_train.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=60, activation='relu', input_dim=inputs))\n",
    "model.add(Dense(units=200, activation='relu'))\n",
    "model.add(Dense(units=2, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    verbose=2,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 - 0s - loss: 0.3215 - accuracy: 0.8714\n",
      "Normal Neural Network - Loss: 0.32154572010040283, Accuracy: 0.8713601231575012\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(f\"Neural Network Permorfance - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 430 Complete [00h 00m 01s]\n",
      "val_accuracy: 0.8685100078582764\n",
      "\n",
      "Best val_accuracy So Far: 0.8740399479866028\n",
      "Total elapsed time: 00h 10m 23s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "# Use Keras tuner to tuner the number of units in layers 1 and 2 and the learning rate\n",
    "import keras_tuner as kt\n",
    "\n",
    "def build_model(hp):\n",
    "    model = tensorflow.keras.Sequential()\n",
    "\n",
    "    # Tune the number of units in the layers\n",
    "    hp_units1 = hp.Int('units1', min_value=40, max_value=400, step=40)\n",
    "    hp_units2 = hp.Int('units2', min_value=40, max_value=400, step=40)\n",
    "        \n",
    "    # Add the layers      \n",
    "    model.add(Dense(units=hp_units1, activation='relu', input_dim=inputs))\n",
    "    model.add(Dense(units=hp_units2, activation='relu'))\n",
    "    model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "    # Tune the learning rate for the optimizer\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[0.001, 0.01, 0.1, 0.2, 0.3])\n",
    "\n",
    "    model.compile(\n",
    "      optimizer = tensorflow.keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "      loss = 'categorical_crossentropy',\n",
    "      metrics = ['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# HyperBand algorithm from keras_tuner\n",
    "tuner = kt.Hyperband(\n",
    "        build_model,\n",
    "        objective='val_accuracy',\n",
    "        max_epochs=1000,\n",
    "        directory='hp_dir',\n",
    "        project_name='neural_net_tuning'\n",
    "        )\n",
    "\n",
    "# Perform the hyperperameter tuning \n",
    "tuner.search(X_train_scaled, y_train_categorical, epochs=200, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 [==============================] - 0s 582us/step - loss: 0.3298 - accuracy: 0.8664\n"
     ]
    }
   ],
   "source": [
    "# Extract the best model and evaluate with the test data\n",
    "# Print accuracy and loss with test data\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "loss, accuracy = best_model.evaluate(X_test_scaled, y_test_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "units1 360\n",
      "units2 360\n",
      "learning_rate 0.001\n"
     ]
    }
   ],
   "source": [
    "# Print optimal hyperparamaters\n",
    "for h_param in [f\"units{i}\" for i in range(1,3)] + ['learning_rate']:\n",
    "    print(h_param, tuner.get_best_hyperparameters()[0].get(h_param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the adjusted model\n",
    "inputs = X_train.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=360, activation='relu', input_dim=inputs))\n",
    "model.add(Dense(units=360, activation='relu'))\n",
    "model.add(Dense(units=2, activation='sigmoid'))\n",
    "\n",
    "# Compile the adjusted model\n",
    "model.compile(optimizer=tensorflow.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'],\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "509/509 - 1s - loss: 0.3401 - accuracy: 0.8645\n",
      "Epoch 2/200\n",
      "509/509 - 0s - loss: 0.3215 - accuracy: 0.8701\n",
      "Epoch 3/200\n",
      "509/509 - 0s - loss: 0.3184 - accuracy: 0.8721\n",
      "Epoch 4/200\n",
      "509/509 - 0s - loss: 0.3173 - accuracy: 0.8724\n",
      "Epoch 5/200\n",
      "509/509 - 0s - loss: 0.3162 - accuracy: 0.8724\n",
      "Epoch 6/200\n",
      "509/509 - 0s - loss: 0.3158 - accuracy: 0.8743\n",
      "Epoch 7/200\n",
      "509/509 - 0s - loss: 0.3147 - accuracy: 0.8744\n",
      "Epoch 8/200\n",
      "509/509 - 0s - loss: 0.3145 - accuracy: 0.8731\n",
      "Epoch 9/200\n",
      "509/509 - 0s - loss: 0.3134 - accuracy: 0.8749\n",
      "Epoch 10/200\n",
      "509/509 - 0s - loss: 0.3140 - accuracy: 0.8738\n",
      "Epoch 11/200\n",
      "509/509 - 0s - loss: 0.3146 - accuracy: 0.8740\n",
      "Epoch 12/200\n",
      "509/509 - 0s - loss: 0.3133 - accuracy: 0.8739\n",
      "Epoch 13/200\n",
      "509/509 - 0s - loss: 0.3144 - accuracy: 0.8747\n",
      "Epoch 14/200\n",
      "509/509 - 0s - loss: 0.3132 - accuracy: 0.8743\n",
      "Epoch 15/200\n",
      "509/509 - 0s - loss: 0.3120 - accuracy: 0.8741\n",
      "Epoch 16/200\n",
      "509/509 - 0s - loss: 0.3132 - accuracy: 0.8740\n",
      "Epoch 17/200\n",
      "509/509 - 0s - loss: 0.3124 - accuracy: 0.8746\n",
      "Epoch 18/200\n",
      "509/509 - 0s - loss: 0.3123 - accuracy: 0.8750\n",
      "Epoch 19/200\n",
      "509/509 - 0s - loss: 0.3125 - accuracy: 0.8750\n",
      "Epoch 20/200\n",
      "509/509 - 0s - loss: 0.3128 - accuracy: 0.8743\n",
      "Epoch 21/200\n",
      "509/509 - 0s - loss: 0.3121 - accuracy: 0.8740\n",
      "Epoch 22/200\n",
      "509/509 - 0s - loss: 0.3122 - accuracy: 0.8751\n",
      "Epoch 23/200\n",
      "509/509 - 0s - loss: 0.3111 - accuracy: 0.8742\n",
      "Epoch 24/200\n",
      "509/509 - 0s - loss: 0.3117 - accuracy: 0.8756\n",
      "Epoch 25/200\n",
      "509/509 - 0s - loss: 0.3125 - accuracy: 0.8732\n",
      "Epoch 26/200\n",
      "509/509 - 0s - loss: 0.3111 - accuracy: 0.8748\n",
      "Epoch 27/200\n",
      "509/509 - 0s - loss: 0.3109 - accuracy: 0.8755\n",
      "Epoch 28/200\n",
      "509/509 - 0s - loss: 0.3109 - accuracy: 0.8744\n",
      "Epoch 29/200\n",
      "509/509 - 0s - loss: 0.3113 - accuracy: 0.8742\n",
      "Epoch 30/200\n",
      "509/509 - 0s - loss: 0.3112 - accuracy: 0.8755\n",
      "Epoch 31/200\n",
      "509/509 - 0s - loss: 0.3110 - accuracy: 0.8748\n",
      "Epoch 32/200\n",
      "509/509 - 0s - loss: 0.3103 - accuracy: 0.8755\n",
      "Epoch 33/200\n",
      "509/509 - 0s - loss: 0.3103 - accuracy: 0.8745\n",
      "Epoch 34/200\n",
      "509/509 - 0s - loss: 0.3107 - accuracy: 0.8765\n",
      "Epoch 35/200\n",
      "509/509 - 0s - loss: 0.3102 - accuracy: 0.8746\n",
      "Epoch 36/200\n",
      "509/509 - 0s - loss: 0.3101 - accuracy: 0.8763\n",
      "Epoch 37/200\n",
      "509/509 - 0s - loss: 0.3098 - accuracy: 0.8759\n",
      "Epoch 38/200\n",
      "509/509 - 0s - loss: 0.3102 - accuracy: 0.8759\n",
      "Epoch 39/200\n",
      "509/509 - 0s - loss: 0.3097 - accuracy: 0.8764\n",
      "Epoch 40/200\n",
      "509/509 - 0s - loss: 0.3094 - accuracy: 0.8757\n",
      "Epoch 41/200\n",
      "509/509 - 0s - loss: 0.3099 - accuracy: 0.8751\n",
      "Epoch 42/200\n",
      "509/509 - 0s - loss: 0.3094 - accuracy: 0.8761\n",
      "Epoch 43/200\n",
      "509/509 - 0s - loss: 0.3099 - accuracy: 0.8764\n",
      "Epoch 44/200\n",
      "509/509 - 0s - loss: 0.3092 - accuracy: 0.8761\n",
      "Epoch 45/200\n",
      "509/509 - 0s - loss: 0.3092 - accuracy: 0.8769\n",
      "Epoch 46/200\n",
      "509/509 - 0s - loss: 0.3085 - accuracy: 0.8755\n",
      "Epoch 47/200\n",
      "509/509 - 0s - loss: 0.3087 - accuracy: 0.8746\n",
      "Epoch 48/200\n",
      "509/509 - 0s - loss: 0.3085 - accuracy: 0.8760\n",
      "Epoch 49/200\n",
      "509/509 - 0s - loss: 0.3095 - accuracy: 0.8761\n",
      "Epoch 50/200\n",
      "509/509 - 0s - loss: 0.3095 - accuracy: 0.8754\n",
      "Epoch 51/200\n",
      "509/509 - 0s - loss: 0.3090 - accuracy: 0.8760\n",
      "Epoch 52/200\n",
      "509/509 - 0s - loss: 0.3082 - accuracy: 0.8755\n",
      "Epoch 53/200\n",
      "509/509 - 0s - loss: 0.3087 - accuracy: 0.8752\n",
      "Epoch 54/200\n",
      "509/509 - 0s - loss: 0.3091 - accuracy: 0.8766\n",
      "Epoch 55/200\n",
      "509/509 - 0s - loss: 0.3091 - accuracy: 0.8761\n",
      "Epoch 56/200\n",
      "509/509 - 0s - loss: 0.3086 - accuracy: 0.8759\n",
      "Epoch 57/200\n",
      "509/509 - 0s - loss: 0.3085 - accuracy: 0.8758\n",
      "Epoch 58/200\n",
      "509/509 - 0s - loss: 0.3084 - accuracy: 0.8773\n",
      "Epoch 59/200\n",
      "509/509 - 0s - loss: 0.3088 - accuracy: 0.8751\n",
      "Epoch 60/200\n",
      "509/509 - 0s - loss: 0.3080 - accuracy: 0.8761\n",
      "Epoch 61/200\n",
      "509/509 - 0s - loss: 0.3079 - accuracy: 0.8762\n",
      "Epoch 62/200\n",
      "509/509 - 0s - loss: 0.3081 - accuracy: 0.8755\n",
      "Epoch 63/200\n",
      "509/509 - 0s - loss: 0.3087 - accuracy: 0.8765\n",
      "Epoch 64/200\n",
      "509/509 - 0s - loss: 0.3086 - accuracy: 0.8770\n",
      "Epoch 65/200\n",
      "509/509 - 0s - loss: 0.3080 - accuracy: 0.8765\n",
      "Epoch 66/200\n",
      "509/509 - 0s - loss: 0.3079 - accuracy: 0.8768\n",
      "Epoch 67/200\n",
      "509/509 - 0s - loss: 0.3086 - accuracy: 0.8769\n",
      "Epoch 68/200\n",
      "509/509 - 0s - loss: 0.3079 - accuracy: 0.8758\n",
      "Epoch 69/200\n",
      "509/509 - 0s - loss: 0.3078 - accuracy: 0.8767\n",
      "Epoch 70/200\n",
      "509/509 - 0s - loss: 0.3078 - accuracy: 0.8766\n",
      "Epoch 71/200\n",
      "509/509 - 0s - loss: 0.3088 - accuracy: 0.8756\n",
      "Epoch 72/200\n",
      "509/509 - 0s - loss: 0.3081 - accuracy: 0.8766\n",
      "Epoch 73/200\n",
      "509/509 - 0s - loss: 0.3072 - accuracy: 0.8753\n",
      "Epoch 74/200\n",
      "509/509 - 0s - loss: 0.3077 - accuracy: 0.8758\n",
      "Epoch 75/200\n",
      "509/509 - 0s - loss: 0.3078 - accuracy: 0.8764\n",
      "Epoch 76/200\n",
      "509/509 - 0s - loss: 0.3083 - accuracy: 0.8764\n",
      "Epoch 77/200\n",
      "509/509 - 0s - loss: 0.3076 - accuracy: 0.8769\n",
      "Epoch 78/200\n",
      "509/509 - 0s - loss: 0.3075 - accuracy: 0.8765\n",
      "Epoch 79/200\n",
      "509/509 - 0s - loss: 0.3081 - accuracy: 0.8762\n",
      "Epoch 80/200\n",
      "509/509 - 0s - loss: 0.3073 - accuracy: 0.8765\n",
      "Epoch 81/200\n",
      "509/509 - 0s - loss: 0.3069 - accuracy: 0.8757\n",
      "Epoch 82/200\n",
      "509/509 - 0s - loss: 0.3071 - accuracy: 0.8776\n",
      "Epoch 83/200\n",
      "509/509 - 0s - loss: 0.3067 - accuracy: 0.8767\n",
      "Epoch 84/200\n",
      "509/509 - 0s - loss: 0.3072 - accuracy: 0.8763\n",
      "Epoch 85/200\n",
      "509/509 - 0s - loss: 0.3069 - accuracy: 0.8772\n",
      "Epoch 86/200\n",
      "509/509 - 0s - loss: 0.3071 - accuracy: 0.8755\n",
      "Epoch 87/200\n",
      "509/509 - 0s - loss: 0.3063 - accuracy: 0.8762\n",
      "Epoch 88/200\n",
      "509/509 - 0s - loss: 0.3071 - accuracy: 0.8764\n",
      "Epoch 89/200\n",
      "509/509 - 0s - loss: 0.3069 - accuracy: 0.8760\n",
      "Epoch 90/200\n",
      "509/509 - 0s - loss: 0.3074 - accuracy: 0.8758\n",
      "Epoch 91/200\n",
      "509/509 - 0s - loss: 0.3064 - accuracy: 0.8761\n",
      "Epoch 92/200\n",
      "509/509 - 0s - loss: 0.3071 - accuracy: 0.8761\n",
      "Epoch 93/200\n",
      "509/509 - 0s - loss: 0.3067 - accuracy: 0.8756\n",
      "Epoch 94/200\n",
      "509/509 - 0s - loss: 0.3067 - accuracy: 0.8765\n",
      "Epoch 95/200\n",
      "509/509 - 0s - loss: 0.3060 - accuracy: 0.8770\n",
      "Epoch 96/200\n",
      "509/509 - 0s - loss: 0.3069 - accuracy: 0.8771\n",
      "Epoch 97/200\n",
      "509/509 - 0s - loss: 0.3065 - accuracy: 0.8769\n",
      "Epoch 98/200\n",
      "509/509 - 0s - loss: 0.3060 - accuracy: 0.8771\n",
      "Epoch 99/200\n",
      "509/509 - 0s - loss: 0.3063 - accuracy: 0.8769\n",
      "Epoch 100/200\n",
      "509/509 - 0s - loss: 0.3064 - accuracy: 0.8775\n",
      "Epoch 101/200\n",
      "509/509 - 0s - loss: 0.3063 - accuracy: 0.8768\n",
      "Epoch 102/200\n",
      "509/509 - 0s - loss: 0.3059 - accuracy: 0.8760\n",
      "Epoch 103/200\n",
      "509/509 - 0s - loss: 0.3063 - accuracy: 0.8763\n",
      "Epoch 104/200\n",
      "509/509 - 0s - loss: 0.3064 - accuracy: 0.8777\n",
      "Epoch 105/200\n",
      "509/509 - 0s - loss: 0.3063 - accuracy: 0.8782\n",
      "Epoch 106/200\n",
      "509/509 - 0s - loss: 0.3063 - accuracy: 0.8764\n",
      "Epoch 107/200\n",
      "509/509 - 0s - loss: 0.3058 - accuracy: 0.8774\n",
      "Epoch 108/200\n",
      "509/509 - 0s - loss: 0.3063 - accuracy: 0.8777\n",
      "Epoch 109/200\n",
      "509/509 - 0s - loss: 0.3066 - accuracy: 0.8760\n",
      "Epoch 110/200\n",
      "509/509 - 0s - loss: 0.3064 - accuracy: 0.8771\n",
      "Epoch 111/200\n",
      "509/509 - 0s - loss: 0.3067 - accuracy: 0.8774\n",
      "Epoch 112/200\n",
      "509/509 - 0s - loss: 0.3059 - accuracy: 0.8769\n",
      "Epoch 113/200\n",
      "509/509 - 0s - loss: 0.3056 - accuracy: 0.8764\n",
      "Epoch 114/200\n",
      "509/509 - 0s - loss: 0.3053 - accuracy: 0.8756\n",
      "Epoch 115/200\n",
      "509/509 - 0s - loss: 0.3061 - accuracy: 0.8773\n",
      "Epoch 116/200\n",
      "509/509 - 0s - loss: 0.3059 - accuracy: 0.8764\n",
      "Epoch 117/200\n",
      "509/509 - 0s - loss: 0.3052 - accuracy: 0.8764\n",
      "Epoch 118/200\n",
      "509/509 - 0s - loss: 0.3056 - accuracy: 0.8759\n",
      "Epoch 119/200\n",
      "509/509 - 0s - loss: 0.3061 - accuracy: 0.8771\n",
      "Epoch 120/200\n",
      "509/509 - 0s - loss: 0.3063 - accuracy: 0.8763\n",
      "Epoch 121/200\n",
      "509/509 - 0s - loss: 0.3052 - accuracy: 0.8774\n",
      "Epoch 122/200\n",
      "509/509 - 0s - loss: 0.3053 - accuracy: 0.8763\n",
      "Epoch 123/200\n",
      "509/509 - 0s - loss: 0.3056 - accuracy: 0.8766\n",
      "Epoch 124/200\n",
      "509/509 - 0s - loss: 0.3053 - accuracy: 0.8771\n",
      "Epoch 125/200\n",
      "509/509 - 0s - loss: 0.3056 - accuracy: 0.8772\n",
      "Epoch 126/200\n",
      "509/509 - 0s - loss: 0.3054 - accuracy: 0.8770\n",
      "Epoch 127/200\n",
      "509/509 - 0s - loss: 0.3047 - accuracy: 0.8772\n",
      "Epoch 128/200\n",
      "509/509 - 0s - loss: 0.3059 - accuracy: 0.8774\n",
      "Epoch 129/200\n",
      "509/509 - 0s - loss: 0.3053 - accuracy: 0.8771\n",
      "Epoch 130/200\n",
      "509/509 - 0s - loss: 0.3055 - accuracy: 0.8770\n",
      "Epoch 131/200\n",
      "509/509 - 0s - loss: 0.3046 - accuracy: 0.8768\n",
      "Epoch 132/200\n",
      "509/509 - 0s - loss: 0.3045 - accuracy: 0.8772\n",
      "Epoch 133/200\n",
      "509/509 - 0s - loss: 0.3054 - accuracy: 0.8767\n",
      "Epoch 134/200\n",
      "509/509 - 0s - loss: 0.3057 - accuracy: 0.8763\n",
      "Epoch 135/200\n",
      "509/509 - 0s - loss: 0.3053 - accuracy: 0.8763\n",
      "Epoch 136/200\n",
      "509/509 - 0s - loss: 0.3048 - accuracy: 0.8773\n",
      "Epoch 137/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "509/509 - 0s - loss: 0.3048 - accuracy: 0.8768\n",
      "Epoch 138/200\n",
      "509/509 - 0s - loss: 0.3053 - accuracy: 0.8766\n",
      "Epoch 139/200\n",
      "509/509 - 0s - loss: 0.3056 - accuracy: 0.8765\n",
      "Epoch 140/200\n",
      "509/509 - 0s - loss: 0.3049 - accuracy: 0.8773\n",
      "Epoch 141/200\n",
      "509/509 - 0s - loss: 0.3049 - accuracy: 0.8771\n",
      "Epoch 142/200\n",
      "509/509 - 0s - loss: 0.3044 - accuracy: 0.8772\n",
      "Epoch 143/200\n",
      "509/509 - 0s - loss: 0.3041 - accuracy: 0.8775\n",
      "Epoch 144/200\n",
      "509/509 - 0s - loss: 0.3044 - accuracy: 0.8769\n",
      "Epoch 145/200\n",
      "509/509 - 0s - loss: 0.3050 - accuracy: 0.8769\n",
      "Epoch 146/200\n",
      "509/509 - 0s - loss: 0.3048 - accuracy: 0.8765\n",
      "Epoch 147/200\n",
      "509/509 - 0s - loss: 0.3046 - accuracy: 0.8771\n",
      "Epoch 148/200\n",
      "509/509 - 0s - loss: 0.3052 - accuracy: 0.8772\n",
      "Epoch 149/200\n",
      "509/509 - 0s - loss: 0.3045 - accuracy: 0.8769\n",
      "Epoch 150/200\n",
      "509/509 - 0s - loss: 0.3049 - accuracy: 0.8772\n",
      "Epoch 151/200\n",
      "509/509 - 0s - loss: 0.3045 - accuracy: 0.8777\n",
      "Epoch 152/200\n",
      "509/509 - 0s - loss: 0.3038 - accuracy: 0.8776\n",
      "Epoch 153/200\n",
      "509/509 - 0s - loss: 0.3045 - accuracy: 0.8778\n",
      "Epoch 154/200\n",
      "509/509 - 0s - loss: 0.3048 - accuracy: 0.8764\n",
      "Epoch 155/200\n",
      "509/509 - 0s - loss: 0.3045 - accuracy: 0.8766\n",
      "Epoch 156/200\n",
      "509/509 - 0s - loss: 0.3044 - accuracy: 0.8766\n",
      "Epoch 157/200\n",
      "509/509 - 0s - loss: 0.3053 - accuracy: 0.8764\n",
      "Epoch 158/200\n",
      "509/509 - 0s - loss: 0.3042 - accuracy: 0.8773\n",
      "Epoch 159/200\n",
      "509/509 - 0s - loss: 0.3045 - accuracy: 0.8775\n",
      "Epoch 160/200\n",
      "509/509 - 0s - loss: 0.3044 - accuracy: 0.8768\n",
      "Epoch 161/200\n",
      "509/509 - 0s - loss: 0.3043 - accuracy: 0.8767\n",
      "Epoch 162/200\n",
      "509/509 - 0s - loss: 0.3046 - accuracy: 0.8767\n",
      "Epoch 163/200\n",
      "509/509 - 0s - loss: 0.3041 - accuracy: 0.8771\n",
      "Epoch 164/200\n",
      "509/509 - 0s - loss: 0.3038 - accuracy: 0.8769\n",
      "Epoch 165/200\n",
      "509/509 - 0s - loss: 0.3048 - accuracy: 0.8774\n",
      "Epoch 166/200\n",
      "509/509 - 0s - loss: 0.3033 - accuracy: 0.8777\n",
      "Epoch 167/200\n",
      "509/509 - 0s - loss: 0.3041 - accuracy: 0.8782\n",
      "Epoch 168/200\n",
      "509/509 - 0s - loss: 0.3039 - accuracy: 0.8777\n",
      "Epoch 169/200\n",
      "509/509 - 0s - loss: 0.3043 - accuracy: 0.8772\n",
      "Epoch 170/200\n",
      "509/509 - 0s - loss: 0.3038 - accuracy: 0.8782\n",
      "Epoch 171/200\n",
      "509/509 - 0s - loss: 0.3037 - accuracy: 0.8777\n",
      "Epoch 172/200\n",
      "509/509 - 0s - loss: 0.3037 - accuracy: 0.8783\n",
      "Epoch 173/200\n",
      "509/509 - 0s - loss: 0.3036 - accuracy: 0.8768\n",
      "Epoch 174/200\n",
      "509/509 - 0s - loss: 0.3036 - accuracy: 0.8763\n",
      "Epoch 175/200\n",
      "509/509 - 0s - loss: 0.3040 - accuracy: 0.8780\n",
      "Epoch 176/200\n",
      "509/509 - 0s - loss: 0.3037 - accuracy: 0.8785\n",
      "Epoch 177/200\n",
      "509/509 - 0s - loss: 0.3044 - accuracy: 0.8782\n",
      "Epoch 178/200\n",
      "509/509 - 0s - loss: 0.3039 - accuracy: 0.8774\n",
      "Epoch 179/200\n",
      "509/509 - 0s - loss: 0.3030 - accuracy: 0.8774\n",
      "Epoch 180/200\n",
      "509/509 - 0s - loss: 0.3038 - accuracy: 0.8770\n",
      "Epoch 181/200\n",
      "509/509 - 0s - loss: 0.3032 - accuracy: 0.8771\n",
      "Epoch 182/200\n",
      "509/509 - 0s - loss: 0.3040 - accuracy: 0.8773\n",
      "Epoch 183/200\n",
      "509/509 - 0s - loss: 0.3037 - accuracy: 0.8772\n",
      "Epoch 184/200\n",
      "509/509 - 0s - loss: 0.3038 - accuracy: 0.8764\n",
      "Epoch 185/200\n",
      "509/509 - 0s - loss: 0.3034 - accuracy: 0.8774\n",
      "Epoch 186/200\n",
      "509/509 - 0s - loss: 0.3030 - accuracy: 0.8785\n",
      "Epoch 187/200\n",
      "509/509 - 0s - loss: 0.3037 - accuracy: 0.8772\n",
      "Epoch 188/200\n",
      "509/509 - 0s - loss: 0.3029 - accuracy: 0.8763\n",
      "Epoch 189/200\n",
      "509/509 - 0s - loss: 0.3029 - accuracy: 0.8782\n",
      "Epoch 190/200\n",
      "509/509 - 0s - loss: 0.3034 - accuracy: 0.8772\n",
      "Epoch 191/200\n",
      "509/509 - 0s - loss: 0.3029 - accuracy: 0.8776\n",
      "Epoch 192/200\n",
      "509/509 - 0s - loss: 0.3034 - accuracy: 0.8771\n",
      "Epoch 193/200\n",
      "509/509 - 0s - loss: 0.3038 - accuracy: 0.8777\n",
      "Epoch 194/200\n",
      "509/509 - 0s - loss: 0.3028 - accuracy: 0.8774\n",
      "Epoch 195/200\n",
      "509/509 - 0s - loss: 0.3029 - accuracy: 0.8766\n",
      "Epoch 196/200\n",
      "509/509 - 0s - loss: 0.3031 - accuracy: 0.8769\n",
      "Epoch 197/200\n",
      "509/509 - 0s - loss: 0.3030 - accuracy: 0.8775\n",
      "Epoch 198/200\n",
      "509/509 - 0s - loss: 0.3031 - accuracy: 0.8769\n",
      "Epoch 199/200\n",
      "509/509 - 0s - loss: 0.3025 - accuracy: 0.8778\n",
      "Epoch 200/200\n",
      "509/509 - 0s - loss: 0.3032 - accuracy: 0.8773\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20c856a85f8>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the adjusted model\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=200,\n",
    "    shuffle=True,\n",
    "    verbose=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 - 0s - loss: 0.3259 - accuracy: 0.8697\n",
      "Normal Neural Network - Loss: 0.32592320442199707, Accuracy: 0.8697014451026917\n"
     ]
    }
   ],
   "source": [
    "# Qunatify the adjusted model\n",
    "model_loss, model_accuracy = model.evaluate(X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 540x540 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a confusion matrix to visualise the performance of the adjusted model\n",
    "predictions = np.argmax(model.predict(X_test_scaled), axis=-1)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true=encoded_y_test, y_pred=predictions)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
    "\n",
    "ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)\n",
    "\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        ax.text(x=j, y=i, s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
    "\n",
    "plt.title('Confusion Matrix', fontsize=18)\n",
    "plt.xlabel('Predictions', fontsize=18)\n",
    "ax.set_xticks([0,1,2])\n",
    "ax.set_xticklabels(target_names)\n",
    "plt.ylabel('Actuals', fontsize=18)\n",
    "ax.set_yticks([0,1,2])\n",
    "ax.set_yticklabels(target_names)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "filename = 'Model 2 - Deep_learning.h5'\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(\"Model 2 - Deep_learning.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\User\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1569 predict_function  *\n        return step_function(self, iterator)\n    C:\\Users\\User\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1559 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\User\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\User\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\User\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\User\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1552 run_step  **\n        outputs = model.predict_step(data)\n    C:\\Users\\User\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1525 predict_step\n        return self(x, training=False)\n    C:\\Users\\User\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1013 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    C:\\Users\\User\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:255 assert_input_compatibility\n        ' but received input with shape ' + display_shape(x.shape))\n\n    ValueError: Input 0 of layer sequential_1 is incompatible with the layer: expected axis -1 of input shape to have value 14 but received input with shape (None, 1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-e5ea9a503e84>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1725\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1726\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1727\u001b[1;33m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1728\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1729\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    762\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m    763\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[1;32m--> 764\u001b[1;33m             *args, **kwds))\n\u001b[0m\u001b[0;32m    765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3048\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3049\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3050\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3051\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3444\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3287\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3288\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3289\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   3290\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3291\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    998\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 999\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1000\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    670\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 672\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    673\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    984\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\User\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1569 predict_function  *\n        return step_function(self, iterator)\n    C:\\Users\\User\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1559 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\User\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\User\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\User\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\User\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1552 run_step  **\n        outputs = model.predict_step(data)\n    C:\\Users\\User\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1525 predict_step\n        return self(x, training=False)\n    C:\\Users\\User\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1013 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    C:\\Users\\User\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:255 assert_input_compatibility\n        ' but received input with shape ' + display_shape(x.shape))\n\n    ValueError: Input 0 of layer sequential_1 is incompatible with the layer: expected axis -1 of input shape to have value 14 but received input with shape (None, 1)\n"
     ]
    }
   ],
   "source": [
    "model.predict(X_train_scaled[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "dev"
  },
  "kernelspec": {
   "display_name": "Python [conda env:PythonData] *",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
