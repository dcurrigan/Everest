{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "df = pd.read_csv(\"crowding_data.csv\", low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'expid', 'membid', 'myear', 'sex', 'calcage', 'citizen', 'status',\n",
       "       'msolo', 'msuccess', 'msmtdate1', 'msmtdate2', 'msmtdate3', 'route1',\n",
       "       'route2', 'route3', 'route4', 'mo2used', 'mo2none', 'mo2climb',\n",
       "       'mo2descent', 'mo2sleep', 'death', 'deathdate', 'msmtbid', 'stdrte',\n",
       "       'new_route', 'new_status', 'climber_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View column names and drop unnecesary columns for the model \n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set features\n",
    "feature_names = ['sex', 'calcage', 'citizen', 'msolo', 'new_route', 'mo2used', 'mo2climb',\n",
    "                 'mo2descent', 'mo2sleep', 'stdrte', 'new_status', 'climber_count']\n",
    "\n",
    "X = df[feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>calcage</th>\n",
       "      <th>citizen</th>\n",
       "      <th>msolo</th>\n",
       "      <th>new_route</th>\n",
       "      <th>mo2used</th>\n",
       "      <th>mo2climb</th>\n",
       "      <th>mo2descent</th>\n",
       "      <th>mo2sleep</th>\n",
       "      <th>stdrte</th>\n",
       "      <th>new_status</th>\n",
       "      <th>climber_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15003</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15004</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15005</th>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15006</th>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15007</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15008 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sex  calcage  citizen  msolo  new_route  mo2used  mo2climb  mo2descent  \\\n",
       "0        0       32       15    0.0          2      1.0       1.0         0.0   \n",
       "1        0       40       82    0.0          2      0.0       0.0         0.0   \n",
       "2        0       29       82    0.0          2      1.0       1.0         0.0   \n",
       "3        0       37       82    0.0          1      0.0       0.0         0.0   \n",
       "4        0       33       82    0.0          1      0.0       0.0         0.0   \n",
       "...    ...      ...      ...    ...        ...      ...       ...         ...   \n",
       "15003    1       16       27    0.0          0      1.0       1.0         0.0   \n",
       "15004    0       37       27    0.0          0      1.0       1.0         0.0   \n",
       "15005    0       57       27    0.0          0      1.0       1.0         0.0   \n",
       "15006    0       35       27    0.0          0      1.0       1.0         0.0   \n",
       "15007    0       37       27    0.0          0      1.0       1.0         0.0   \n",
       "\n",
       "       mo2sleep  stdrte  new_status  climber_count  \n",
       "0           1.0     1.0           2            3.0  \n",
       "1           0.0     1.0           2            3.0  \n",
       "2           1.0     1.0           2            3.0  \n",
       "3           0.0     0.0           1            3.0  \n",
       "4           0.0     0.0           1            3.0  \n",
       "...         ...     ...         ...            ...  \n",
       "15003       1.0     1.0           0           15.0  \n",
       "15004       1.0     1.0           0           15.0  \n",
       "15005       1.0     1.0           0           15.0  \n",
       "15006       1.0     1.0           0           15.0  \n",
       "15007       1.0     1.0           0           15.0  \n",
       "\n",
       "[15008 rows x 12 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert X values to numerical \n",
    "\n",
    "###                KEY                  ### \n",
    "###        Male = 0, Female = 1         ###\n",
    "###        True = 1, False = 0          ###\n",
    "###  Citizen and Route = see label map  ###\n",
    "\n",
    "X.replace(True, 1, inplace=True)\n",
    "X['sex'] = pd.get_dummies(X['sex'])\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "# Perform label transformation and create label maps for later use \n",
    "X['citizen'] = le.fit_transform(X['citizen'])\n",
    "country_label_map = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "X['new_route'] = le.fit_transform(X['new_route'])\n",
    "route_label_map = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "X['new_status'] = le.fit_transform(X['new_route'])\n",
    "status_label_map = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_names = df['msuccess'].unique()\n",
    "target_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y  = df['msuccess']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Train Test Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "Scale the data using the MinMaxScaler and perform some feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create the scaler\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "\n",
    "# Transform the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the y values to numerical using label_encoder/to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)\n",
    "y_test_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and initial trial model and add layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "inputs = X_train.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=60, activation='relu', input_dim=inputs))\n",
    "model.add(Dense(units=200, activation='relu'))\n",
    "model.add(Dense(units=2, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 60)                780       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 200)               12200     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 402       \n",
      "=================================================================\n",
      "Total params: 13,382\n",
      "Trainable params: 13,382\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "352/352 - 1s - loss: 0.4361 - accuracy: 0.8199\n",
      "Epoch 2/100\n",
      "352/352 - 0s - loss: 0.4093 - accuracy: 0.8353\n",
      "Epoch 3/100\n",
      "352/352 - 0s - loss: 0.4072 - accuracy: 0.8347\n",
      "Epoch 4/100\n",
      "352/352 - 0s - loss: 0.4031 - accuracy: 0.8364\n",
      "Epoch 5/100\n",
      "352/352 - 0s - loss: 0.4027 - accuracy: 0.8364\n",
      "Epoch 6/100\n",
      "352/352 - 0s - loss: 0.4021 - accuracy: 0.8355\n",
      "Epoch 7/100\n",
      "352/352 - 0s - loss: 0.3994 - accuracy: 0.8360\n",
      "Epoch 8/100\n",
      "352/352 - 0s - loss: 0.3990 - accuracy: 0.8364\n",
      "Epoch 9/100\n",
      "352/352 - 0s - loss: 0.3978 - accuracy: 0.8383\n",
      "Epoch 10/100\n",
      "352/352 - 0s - loss: 0.3971 - accuracy: 0.8379\n",
      "Epoch 11/100\n",
      "352/352 - 0s - loss: 0.3971 - accuracy: 0.8394\n",
      "Epoch 12/100\n",
      "352/352 - 0s - loss: 0.3953 - accuracy: 0.8381\n",
      "Epoch 13/100\n",
      "352/352 - 0s - loss: 0.3956 - accuracy: 0.8378\n",
      "Epoch 14/100\n",
      "352/352 - 0s - loss: 0.3948 - accuracy: 0.8395\n",
      "Epoch 15/100\n",
      "352/352 - 0s - loss: 0.3949 - accuracy: 0.8381\n",
      "Epoch 16/100\n",
      "352/352 - 0s - loss: 0.3937 - accuracy: 0.8399\n",
      "Epoch 17/100\n",
      "352/352 - 0s - loss: 0.3929 - accuracy: 0.8396\n",
      "Epoch 18/100\n",
      "352/352 - 0s - loss: 0.3918 - accuracy: 0.8383\n",
      "Epoch 19/100\n",
      "352/352 - 0s - loss: 0.3921 - accuracy: 0.8414\n",
      "Epoch 20/100\n",
      "352/352 - 0s - loss: 0.3912 - accuracy: 0.8386\n",
      "Epoch 21/100\n",
      "352/352 - 0s - loss: 0.3913 - accuracy: 0.8412\n",
      "Epoch 22/100\n",
      "352/352 - 0s - loss: 0.3912 - accuracy: 0.8414\n",
      "Epoch 23/100\n",
      "352/352 - 0s - loss: 0.3898 - accuracy: 0.8410\n",
      "Epoch 24/100\n",
      "352/352 - 0s - loss: 0.3902 - accuracy: 0.8406\n",
      "Epoch 25/100\n",
      "352/352 - 0s - loss: 0.3897 - accuracy: 0.8431\n",
      "Epoch 26/100\n",
      "352/352 - 0s - loss: 0.3892 - accuracy: 0.8417\n",
      "Epoch 27/100\n",
      "352/352 - 0s - loss: 0.3893 - accuracy: 0.8401\n",
      "Epoch 28/100\n",
      "352/352 - 0s - loss: 0.3877 - accuracy: 0.8415\n",
      "Epoch 29/100\n",
      "352/352 - 0s - loss: 0.3873 - accuracy: 0.8404\n",
      "Epoch 30/100\n",
      "352/352 - 0s - loss: 0.3879 - accuracy: 0.8396\n",
      "Epoch 31/100\n",
      "352/352 - 0s - loss: 0.3868 - accuracy: 0.8418\n",
      "Epoch 32/100\n",
      "352/352 - 0s - loss: 0.3857 - accuracy: 0.8442\n",
      "Epoch 33/100\n",
      "352/352 - 0s - loss: 0.3862 - accuracy: 0.8431\n",
      "Epoch 34/100\n",
      "352/352 - 0s - loss: 0.3847 - accuracy: 0.8439\n",
      "Epoch 35/100\n",
      "352/352 - 0s - loss: 0.3848 - accuracy: 0.8436\n",
      "Epoch 36/100\n",
      "352/352 - 0s - loss: 0.3840 - accuracy: 0.8449\n",
      "Epoch 37/100\n",
      "352/352 - 0s - loss: 0.3836 - accuracy: 0.8444\n",
      "Epoch 38/100\n",
      "352/352 - 0s - loss: 0.3823 - accuracy: 0.8434\n",
      "Epoch 39/100\n",
      "352/352 - 0s - loss: 0.3826 - accuracy: 0.8436\n",
      "Epoch 40/100\n",
      "352/352 - 0s - loss: 0.3824 - accuracy: 0.8422\n",
      "Epoch 41/100\n",
      "352/352 - 0s - loss: 0.3821 - accuracy: 0.8442\n",
      "Epoch 42/100\n",
      "352/352 - 0s - loss: 0.3823 - accuracy: 0.8440\n",
      "Epoch 43/100\n",
      "352/352 - 0s - loss: 0.3817 - accuracy: 0.8432\n",
      "Epoch 44/100\n",
      "352/352 - 0s - loss: 0.3810 - accuracy: 0.8459\n",
      "Epoch 45/100\n",
      "352/352 - 0s - loss: 0.3791 - accuracy: 0.8442\n",
      "Epoch 46/100\n",
      "352/352 - 0s - loss: 0.3791 - accuracy: 0.8464\n",
      "Epoch 47/100\n",
      "352/352 - 0s - loss: 0.3800 - accuracy: 0.8459\n",
      "Epoch 48/100\n",
      "352/352 - 0s - loss: 0.3791 - accuracy: 0.8463\n",
      "Epoch 49/100\n",
      "352/352 - 0s - loss: 0.3787 - accuracy: 0.8457\n",
      "Epoch 50/100\n",
      "352/352 - 0s - loss: 0.3781 - accuracy: 0.8459\n",
      "Epoch 51/100\n",
      "352/352 - 0s - loss: 0.3777 - accuracy: 0.8473\n",
      "Epoch 52/100\n",
      "352/352 - 0s - loss: 0.3775 - accuracy: 0.8463\n",
      "Epoch 53/100\n",
      "352/352 - 0s - loss: 0.3773 - accuracy: 0.8463\n",
      "Epoch 54/100\n",
      "352/352 - 0s - loss: 0.3756 - accuracy: 0.8476\n",
      "Epoch 55/100\n",
      "352/352 - 0s - loss: 0.3762 - accuracy: 0.8460\n",
      "Epoch 56/100\n",
      "352/352 - 0s - loss: 0.3754 - accuracy: 0.8487\n",
      "Epoch 57/100\n",
      "352/352 - 0s - loss: 0.3738 - accuracy: 0.8490\n",
      "Epoch 58/100\n",
      "352/352 - 0s - loss: 0.3748 - accuracy: 0.8478\n",
      "Epoch 59/100\n",
      "352/352 - 0s - loss: 0.3742 - accuracy: 0.8494\n",
      "Epoch 60/100\n",
      "352/352 - 0s - loss: 0.3746 - accuracy: 0.8465\n",
      "Epoch 61/100\n",
      "352/352 - 0s - loss: 0.3741 - accuracy: 0.8498\n",
      "Epoch 62/100\n",
      "352/352 - 0s - loss: 0.3748 - accuracy: 0.8473\n",
      "Epoch 63/100\n",
      "352/352 - 0s - loss: 0.3724 - accuracy: 0.8472\n",
      "Epoch 64/100\n",
      "352/352 - 0s - loss: 0.3733 - accuracy: 0.8491\n",
      "Epoch 65/100\n",
      "352/352 - 0s - loss: 0.3741 - accuracy: 0.8475\n",
      "Epoch 66/100\n",
      "352/352 - 0s - loss: 0.3727 - accuracy: 0.8507\n",
      "Epoch 67/100\n",
      "352/352 - 0s - loss: 0.3715 - accuracy: 0.8507\n",
      "Epoch 68/100\n",
      "352/352 - 0s - loss: 0.3712 - accuracy: 0.8507\n",
      "Epoch 69/100\n",
      "352/352 - 0s - loss: 0.3721 - accuracy: 0.8499\n",
      "Epoch 70/100\n",
      "352/352 - 0s - loss: 0.3710 - accuracy: 0.8502\n",
      "Epoch 71/100\n",
      "352/352 - 0s - loss: 0.3712 - accuracy: 0.8499\n",
      "Epoch 72/100\n",
      "352/352 - 0s - loss: 0.3693 - accuracy: 0.8503\n",
      "Epoch 73/100\n",
      "352/352 - 0s - loss: 0.3695 - accuracy: 0.8507\n",
      "Epoch 74/100\n",
      "352/352 - 0s - loss: 0.3699 - accuracy: 0.8503\n",
      "Epoch 75/100\n",
      "352/352 - 0s - loss: 0.3700 - accuracy: 0.8526\n",
      "Epoch 76/100\n",
      "352/352 - 0s - loss: 0.3692 - accuracy: 0.8504\n",
      "Epoch 77/100\n",
      "352/352 - 0s - loss: 0.3669 - accuracy: 0.8525\n",
      "Epoch 78/100\n",
      "352/352 - 0s - loss: 0.3680 - accuracy: 0.8534\n",
      "Epoch 79/100\n",
      "352/352 - 0s - loss: 0.3668 - accuracy: 0.8511\n",
      "Epoch 80/100\n",
      "352/352 - 0s - loss: 0.3662 - accuracy: 0.8531\n",
      "Epoch 81/100\n",
      "352/352 - 0s - loss: 0.3666 - accuracy: 0.8519\n",
      "Epoch 82/100\n",
      "352/352 - 0s - loss: 0.3666 - accuracy: 0.8519\n",
      "Epoch 83/100\n",
      "352/352 - 0s - loss: 0.3649 - accuracy: 0.8532\n",
      "Epoch 84/100\n",
      "352/352 - 0s - loss: 0.3657 - accuracy: 0.8515\n",
      "Epoch 85/100\n",
      "352/352 - 0s - loss: 0.3663 - accuracy: 0.8526\n",
      "Epoch 86/100\n",
      "352/352 - 0s - loss: 0.3663 - accuracy: 0.8528\n",
      "Epoch 87/100\n",
      "352/352 - 0s - loss: 0.3657 - accuracy: 0.8517\n",
      "Epoch 88/100\n",
      "352/352 - 0s - loss: 0.3658 - accuracy: 0.8533\n",
      "Epoch 89/100\n",
      "352/352 - 0s - loss: 0.3649 - accuracy: 0.8516\n",
      "Epoch 90/100\n",
      "352/352 - 0s - loss: 0.3655 - accuracy: 0.8547\n",
      "Epoch 91/100\n",
      "352/352 - 0s - loss: 0.3647 - accuracy: 0.8523\n",
      "Epoch 92/100\n",
      "352/352 - 0s - loss: 0.3629 - accuracy: 0.8527\n",
      "Epoch 93/100\n",
      "352/352 - 0s - loss: 0.3641 - accuracy: 0.8525\n",
      "Epoch 94/100\n",
      "352/352 - 0s - loss: 0.3623 - accuracy: 0.8539\n",
      "Epoch 95/100\n",
      "352/352 - 0s - loss: 0.3628 - accuracy: 0.8525\n",
      "Epoch 96/100\n",
      "352/352 - 0s - loss: 0.3618 - accuracy: 0.8549\n",
      "Epoch 97/100\n",
      "352/352 - 0s - loss: 0.3625 - accuracy: 0.8542\n",
      "Epoch 98/100\n",
      "352/352 - 0s - loss: 0.3623 - accuracy: 0.8552\n",
      "Epoch 99/100\n",
      "352/352 - 0s - loss: 0.3621 - accuracy: 0.8530\n",
      "Epoch 100/100\n",
      "352/352 - 0s - loss: 0.3609 - accuracy: 0.8545\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x17716b6a860>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    verbose=2,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantify Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 - 0s - loss: 0.3846 - accuracy: 0.8462\n",
      "Neural Network Performace - Loss: 0.38461750745773315, Accuracy: 0.8462153673171997\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(f\"Neural Network Performace - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chance of success for datapoint 50 is: 87.51%\n",
      "\n",
      "With crowding model the chance of success is: 96.65%\n"
     ]
    }
   ],
   "source": [
    "# Print some test data to try out the preduction model \n",
    "from tensorflow.keras.models import load_model\n",
    "success_model = load_model(\"success_model.h5\")\n",
    "\n",
    "test_values2 = X_train_scaled[50].tolist()\n",
    "test_values1 = test_values[:-1]\n",
    "result1 = success_model.predict([test_values1])\n",
    "print(f\"Chance of success for datapoint 50 is: {round(result1[0][0]*100,2)}%\")\n",
    "\n",
    "result2 = model.predict([test_values2])\n",
    "print(\"\")\n",
    "print(f\"With crowding model the chance of success is: {round(result2[0][1]*100,2)}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 540x540 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a confusion matrix to visualise the performance \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "predictions = np.argmax(model.predict(X_test_scaled), axis=-1)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true=encoded_y_test, y_pred=predictions)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
    "\n",
    "ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)\n",
    "\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        ax.text(x=j, y=i, s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
    "\n",
    "plt.title('Confusion Matrix', fontsize=18)\n",
    "plt.xlabel('Predictions', fontsize=18)\n",
    "ax.set_xticks([0,1])\n",
    "ax.set_xticklabels(target_names)\n",
    "plt.ylabel('Actuals', fontsize=18)\n",
    "ax.set_yticks([0,1])\n",
    "ax.set_yticklabels(target_names)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperperameter tuning\n",
    "\n",
    "#### Talos Custom Hyperparameter Optimiser for Keras, Tensorflow used \n",
    "Availble from: <a href=\"https://github.com/autonomio/talos/\">https://github.com/autonomio/talos/</a>\n",
    "<img src=\"https://raw.githubusercontent.com/autonomio/talos/master/logo.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import talos\n",
    "\n",
    "# Function to run the model \n",
    "def everest(x_train, y_train, x_val, y_val, params):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(params['first_neuron'], input_dim=x_train.shape[1], \n",
    "              activation=params['activation']))\n",
    " \n",
    "    model.add(Dropout(params['dropout']))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=params['optimizer'], metrics=['accuracy'])\n",
    "    \n",
    "    out = model.fit(x_train, \n",
    "                    y_train,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    epochs=params['epochs'],\n",
    "                    batch_size=params['batch_size'],\n",
    "                    verbose=0)\n",
    "    \n",
    "    return out, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a parameter dictionary\n",
    "p = {'first_neuron':[30,60,120,240],\n",
    "    'hidden_layers':[1, 2],\n",
    "    'batch_size': [10,20, 30],\n",
    "    'epochs': [100, 150, 200],\n",
    "    'dropout': [0],\n",
    "    'optimizer': ['Nadam', 'Adam'],\n",
    "    'losses': ['binary_crossentropy'],\n",
    "    'activation':['relu'],\n",
    "    'last_activation': ['sigmoid']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [25:53<00:00, 51.80s/it]\n"
     ]
    }
   ],
   "source": [
    "t = talos.Scan(x=X_train_scaled, y=encoded_y_train, params=p, model=everest, experiment_name='everest_tune', round_limit=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "experiment_name            everest_tune\n",
       "random_method          uniform_mersenne\n",
       "reduction_method                   None\n",
       "reduction_interval                   50\n",
       "reduction_window                     20\n",
       "reduction_threshold                 0.2\n",
       "reduction_metric                val_acc\n",
       "complete_time            08/21/21/22:55\n",
       "x_shape                     (11256, 12)\n",
       "y_shape                        (11256,)\n",
       "dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best parameters:  \n",
    "  \n",
    "(as per table below)  \n",
    "first layer: 30  \n",
    "hidden layers: 2  \n",
    "activation: relu  \n",
    "batch_size: 10  \n",
    "epochs: 200  \n",
    "dropout: 0  \n",
    "optimizer: adam  \n",
    "<b>accuracy:</b> 84.69%  \n",
    "<b>loss:</b> 0.391798"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>duration</th>\n",
       "      <th>round_epochs</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>activation</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>dropout</th>\n",
       "      <th>epochs</th>\n",
       "      <th>first_neuron</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>last_activation</th>\n",
       "      <th>losses</th>\n",
       "      <th>optimizer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>08/21/21-222929</td>\n",
       "      <td>08/21/21-222958</td>\n",
       "      <td>28.517795</td>\n",
       "      <td>100</td>\n",
       "      <td>0.382524</td>\n",
       "      <td>0.846554</td>\n",
       "      <td>0.391210</td>\n",
       "      <td>0.841575</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>120</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>08/21/21-222958</td>\n",
       "      <td>08/21/21-223050</td>\n",
       "      <td>52.033421</td>\n",
       "      <td>100</td>\n",
       "      <td>0.385897</td>\n",
       "      <td>0.844523</td>\n",
       "      <td>0.393752</td>\n",
       "      <td>0.843056</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>08/21/21-223050</td>\n",
       "      <td>08/21/21-223130</td>\n",
       "      <td>40.474386</td>\n",
       "      <td>150</td>\n",
       "      <td>0.387497</td>\n",
       "      <td>0.844143</td>\n",
       "      <td>0.392169</td>\n",
       "      <td>0.843648</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>08/21/21-223130</td>\n",
       "      <td>08/21/21-223150</td>\n",
       "      <td>19.096133</td>\n",
       "      <td>100</td>\n",
       "      <td>0.381258</td>\n",
       "      <td>0.844904</td>\n",
       "      <td>0.392164</td>\n",
       "      <td>0.840687</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08/21/21-223150</td>\n",
       "      <td>08/21/21-223336</td>\n",
       "      <td>105.885855</td>\n",
       "      <td>200</td>\n",
       "      <td>0.376885</td>\n",
       "      <td>0.850616</td>\n",
       "      <td>0.395725</td>\n",
       "      <td>0.843056</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>08/21/21-223336</td>\n",
       "      <td>08/21/21-223405</td>\n",
       "      <td>29.245488</td>\n",
       "      <td>150</td>\n",
       "      <td>0.374778</td>\n",
       "      <td>0.847443</td>\n",
       "      <td>0.391716</td>\n",
       "      <td>0.841575</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>240</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>08/21/21-223405</td>\n",
       "      <td>08/21/21-223434</td>\n",
       "      <td>29.196423</td>\n",
       "      <td>150</td>\n",
       "      <td>0.374669</td>\n",
       "      <td>0.849600</td>\n",
       "      <td>0.391096</td>\n",
       "      <td>0.843352</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>240</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>08/21/21-223434</td>\n",
       "      <td>08/21/21-223529</td>\n",
       "      <td>54.661345</td>\n",
       "      <td>200</td>\n",
       "      <td>0.382906</td>\n",
       "      <td>0.847316</td>\n",
       "      <td>0.392676</td>\n",
       "      <td>0.840687</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>08/21/21-223529</td>\n",
       "      <td>08/21/21-223718</td>\n",
       "      <td>108.977342</td>\n",
       "      <td>200</td>\n",
       "      <td>0.382500</td>\n",
       "      <td>0.845539</td>\n",
       "      <td>0.391798</td>\n",
       "      <td>0.846906</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>08/21/21-223718</td>\n",
       "      <td>08/21/21-223747</td>\n",
       "      <td>28.269647</td>\n",
       "      <td>150</td>\n",
       "      <td>0.388526</td>\n",
       "      <td>0.841350</td>\n",
       "      <td>0.395752</td>\n",
       "      <td>0.839799</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>08/21/21-223747</td>\n",
       "      <td>08/21/21-223906</td>\n",
       "      <td>79.696895</td>\n",
       "      <td>150</td>\n",
       "      <td>0.373586</td>\n",
       "      <td>0.849727</td>\n",
       "      <td>0.395742</td>\n",
       "      <td>0.842464</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>120</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>08/21/21-223906</td>\n",
       "      <td>08/21/21-224001</td>\n",
       "      <td>54.513952</td>\n",
       "      <td>100</td>\n",
       "      <td>0.387069</td>\n",
       "      <td>0.843254</td>\n",
       "      <td>0.390802</td>\n",
       "      <td>0.842760</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>08/21/21-224001</td>\n",
       "      <td>08/21/21-224030</td>\n",
       "      <td>29.035641</td>\n",
       "      <td>150</td>\n",
       "      <td>0.381441</td>\n",
       "      <td>0.847189</td>\n",
       "      <td>0.390576</td>\n",
       "      <td>0.842760</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>08/21/21-224030</td>\n",
       "      <td>08/21/21-224126</td>\n",
       "      <td>56.266153</td>\n",
       "      <td>200</td>\n",
       "      <td>0.379708</td>\n",
       "      <td>0.847950</td>\n",
       "      <td>0.391582</td>\n",
       "      <td>0.842760</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>08/21/21-224127</td>\n",
       "      <td>08/21/21-224205</td>\n",
       "      <td>38.639579</td>\n",
       "      <td>200</td>\n",
       "      <td>0.374442</td>\n",
       "      <td>0.849854</td>\n",
       "      <td>0.389438</td>\n",
       "      <td>0.844833</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>120</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>08/21/21-224205</td>\n",
       "      <td>08/21/21-224236</td>\n",
       "      <td>30.553203</td>\n",
       "      <td>100</td>\n",
       "      <td>0.381197</td>\n",
       "      <td>0.846173</td>\n",
       "      <td>0.388690</td>\n",
       "      <td>0.843648</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>08/21/21-224236</td>\n",
       "      <td>08/21/21-224330</td>\n",
       "      <td>53.779867</td>\n",
       "      <td>200</td>\n",
       "      <td>0.384521</td>\n",
       "      <td>0.845285</td>\n",
       "      <td>0.392892</td>\n",
       "      <td>0.843352</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>08/21/21-224330</td>\n",
       "      <td>08/21/21-224425</td>\n",
       "      <td>55.210048</td>\n",
       "      <td>200</td>\n",
       "      <td>0.378884</td>\n",
       "      <td>0.847696</td>\n",
       "      <td>0.389568</td>\n",
       "      <td>0.843648</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>08/21/21-224425</td>\n",
       "      <td>08/21/21-224549</td>\n",
       "      <td>84.174098</td>\n",
       "      <td>150</td>\n",
       "      <td>0.378809</td>\n",
       "      <td>0.848077</td>\n",
       "      <td>0.392198</td>\n",
       "      <td>0.842168</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>08/21/21-224550</td>\n",
       "      <td>08/21/21-224748</td>\n",
       "      <td>118.263300</td>\n",
       "      <td>200</td>\n",
       "      <td>0.364065</td>\n",
       "      <td>0.853281</td>\n",
       "      <td>0.400232</td>\n",
       "      <td>0.845721</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>240</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>08/21/21-224748</td>\n",
       "      <td>08/21/21-224946</td>\n",
       "      <td>118.097177</td>\n",
       "      <td>200</td>\n",
       "      <td>0.365044</td>\n",
       "      <td>0.855946</td>\n",
       "      <td>0.406091</td>\n",
       "      <td>0.845129</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>240</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>08/21/21-224946</td>\n",
       "      <td>08/21/21-225029</td>\n",
       "      <td>43.220797</td>\n",
       "      <td>150</td>\n",
       "      <td>0.385437</td>\n",
       "      <td>0.846808</td>\n",
       "      <td>0.393242</td>\n",
       "      <td>0.840983</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>08/21/21-225030</td>\n",
       "      <td>08/21/21-225100</td>\n",
       "      <td>30.918448</td>\n",
       "      <td>100</td>\n",
       "      <td>0.377937</td>\n",
       "      <td>0.848331</td>\n",
       "      <td>0.393936</td>\n",
       "      <td>0.842168</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>240</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>08/21/21-225101</td>\n",
       "      <td>08/21/21-225121</td>\n",
       "      <td>20.198595</td>\n",
       "      <td>100</td>\n",
       "      <td>0.385315</td>\n",
       "      <td>0.846554</td>\n",
       "      <td>0.390716</td>\n",
       "      <td>0.845129</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>08/21/21-225121</td>\n",
       "      <td>08/21/21-225141</td>\n",
       "      <td>19.924400</td>\n",
       "      <td>100</td>\n",
       "      <td>0.390616</td>\n",
       "      <td>0.841477</td>\n",
       "      <td>0.396537</td>\n",
       "      <td>0.842464</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>08/21/21-225141</td>\n",
       "      <td>08/21/21-225202</td>\n",
       "      <td>20.703136</td>\n",
       "      <td>100</td>\n",
       "      <td>0.386656</td>\n",
       "      <td>0.844650</td>\n",
       "      <td>0.397103</td>\n",
       "      <td>0.839206</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>08/21/21-225202</td>\n",
       "      <td>08/21/21-225232</td>\n",
       "      <td>30.632902</td>\n",
       "      <td>100</td>\n",
       "      <td>0.379318</td>\n",
       "      <td>0.848077</td>\n",
       "      <td>0.393636</td>\n",
       "      <td>0.841575</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>240</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>08/21/21-225232</td>\n",
       "      <td>08/21/21-225330</td>\n",
       "      <td>57.954097</td>\n",
       "      <td>100</td>\n",
       "      <td>0.374550</td>\n",
       "      <td>0.849219</td>\n",
       "      <td>0.395248</td>\n",
       "      <td>0.840983</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>240</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>08/21/21-225331</td>\n",
       "      <td>08/21/21-225400</td>\n",
       "      <td>29.510278</td>\n",
       "      <td>100</td>\n",
       "      <td>0.378293</td>\n",
       "      <td>0.848204</td>\n",
       "      <td>0.389448</td>\n",
       "      <td>0.843352</td>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>240</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>08/21/21-225400</td>\n",
       "      <td>08/21/21-225523</td>\n",
       "      <td>82.692002</td>\n",
       "      <td>150</td>\n",
       "      <td>0.383819</td>\n",
       "      <td>0.843889</td>\n",
       "      <td>0.399407</td>\n",
       "      <td>0.841872</td>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              start              end    duration  round_epochs      loss  \\\n",
       "0   08/21/21-222929  08/21/21-222958   28.517795           100  0.382524   \n",
       "1   08/21/21-222958  08/21/21-223050   52.033421           100  0.385897   \n",
       "2   08/21/21-223050  08/21/21-223130   40.474386           150  0.387497   \n",
       "3   08/21/21-223130  08/21/21-223150   19.096133           100  0.381258   \n",
       "4   08/21/21-223150  08/21/21-223336  105.885855           200  0.376885   \n",
       "5   08/21/21-223336  08/21/21-223405   29.245488           150  0.374778   \n",
       "6   08/21/21-223405  08/21/21-223434   29.196423           150  0.374669   \n",
       "7   08/21/21-223434  08/21/21-223529   54.661345           200  0.382906   \n",
       "8   08/21/21-223529  08/21/21-223718  108.977342           200  0.382500   \n",
       "9   08/21/21-223718  08/21/21-223747   28.269647           150  0.388526   \n",
       "10  08/21/21-223747  08/21/21-223906   79.696895           150  0.373586   \n",
       "11  08/21/21-223906  08/21/21-224001   54.513952           100  0.387069   \n",
       "12  08/21/21-224001  08/21/21-224030   29.035641           150  0.381441   \n",
       "13  08/21/21-224030  08/21/21-224126   56.266153           200  0.379708   \n",
       "14  08/21/21-224127  08/21/21-224205   38.639579           200  0.374442   \n",
       "15  08/21/21-224205  08/21/21-224236   30.553203           100  0.381197   \n",
       "16  08/21/21-224236  08/21/21-224330   53.779867           200  0.384521   \n",
       "17  08/21/21-224330  08/21/21-224425   55.210048           200  0.378884   \n",
       "18  08/21/21-224425  08/21/21-224549   84.174098           150  0.378809   \n",
       "19  08/21/21-224550  08/21/21-224748  118.263300           200  0.364065   \n",
       "20  08/21/21-224748  08/21/21-224946  118.097177           200  0.365044   \n",
       "21  08/21/21-224946  08/21/21-225029   43.220797           150  0.385437   \n",
       "22  08/21/21-225030  08/21/21-225100   30.918448           100  0.377937   \n",
       "23  08/21/21-225101  08/21/21-225121   20.198595           100  0.385315   \n",
       "24  08/21/21-225121  08/21/21-225141   19.924400           100  0.390616   \n",
       "25  08/21/21-225141  08/21/21-225202   20.703136           100  0.386656   \n",
       "26  08/21/21-225202  08/21/21-225232   30.632902           100  0.379318   \n",
       "27  08/21/21-225232  08/21/21-225330   57.954097           100  0.374550   \n",
       "28  08/21/21-225331  08/21/21-225400   29.510278           100  0.378293   \n",
       "29  08/21/21-225400  08/21/21-225523   82.692002           150  0.383819   \n",
       "\n",
       "    accuracy  val_loss  val_accuracy activation  batch_size  dropout  epochs  \\\n",
       "0   0.846554  0.391210      0.841575       relu          20        0     100   \n",
       "1   0.844523  0.393752      0.843056       relu          10        0     100   \n",
       "2   0.844143  0.392169      0.843648       relu          20        0     150   \n",
       "3   0.844904  0.392164      0.840687       relu          30        0     100   \n",
       "4   0.850616  0.395725      0.843056       relu          10        0     200   \n",
       "5   0.847443  0.391716      0.841575       relu          30        0     150   \n",
       "6   0.849600  0.391096      0.843352       relu          30        0     150   \n",
       "7   0.847316  0.392676      0.840687       relu          20        0     200   \n",
       "8   0.845539  0.391798      0.846906       relu          10        0     200   \n",
       "9   0.841350  0.395752      0.839799       relu          30        0     150   \n",
       "10  0.849727  0.395742      0.842464       relu          10        0     150   \n",
       "11  0.843254  0.390802      0.842760       relu          10        0     100   \n",
       "12  0.847189  0.390576      0.842760       relu          30        0     150   \n",
       "13  0.847950  0.391582      0.842760       relu          20        0     200   \n",
       "14  0.849854  0.389438      0.844833       relu          30        0     200   \n",
       "15  0.846173  0.388690      0.843648       relu          20        0     100   \n",
       "16  0.845285  0.392892      0.843352       relu          20        0     200   \n",
       "17  0.847696  0.389568      0.843648       relu          20        0     200   \n",
       "18  0.848077  0.392198      0.842168       relu          10        0     150   \n",
       "19  0.853281  0.400232      0.845721       relu          10        0     200   \n",
       "20  0.855946  0.406091      0.845129       relu          10        0     200   \n",
       "21  0.846808  0.393242      0.840983       relu          20        0     150   \n",
       "22  0.848331  0.393936      0.842168       relu          20        0     100   \n",
       "23  0.846554  0.390716      0.845129       relu          30        0     100   \n",
       "24  0.841477  0.396537      0.842464       relu          30        0     100   \n",
       "25  0.844650  0.397103      0.839206       relu          30        0     100   \n",
       "26  0.848077  0.393636      0.841575       relu          20        0     100   \n",
       "27  0.849219  0.395248      0.840983       relu          10        0     100   \n",
       "28  0.848204  0.389448      0.843352       relu          20        0     100   \n",
       "29  0.843889  0.399407      0.841872       relu          10        0     150   \n",
       "\n",
       "    first_neuron  hidden_layers last_activation               losses optimizer  \n",
       "0            120              2         sigmoid  binary_crossentropy     Nadam  \n",
       "1             30              1         sigmoid  binary_crossentropy      Adam  \n",
       "2             30              2         sigmoid  binary_crossentropy      Adam  \n",
       "3            120              1         sigmoid  binary_crossentropy      Adam  \n",
       "4             60              2         sigmoid  binary_crossentropy     Nadam  \n",
       "5            240              1         sigmoid  binary_crossentropy      Adam  \n",
       "6            240              2         sigmoid  binary_crossentropy      Adam  \n",
       "7             30              2         sigmoid  binary_crossentropy     Nadam  \n",
       "8             30              2         sigmoid  binary_crossentropy      Adam  \n",
       "9             30              1         sigmoid  binary_crossentropy      Adam  \n",
       "10           120              2         sigmoid  binary_crossentropy     Nadam  \n",
       "11            30              2         sigmoid  binary_crossentropy     Nadam  \n",
       "12            60              2         sigmoid  binary_crossentropy     Nadam  \n",
       "13            60              2         sigmoid  binary_crossentropy      Adam  \n",
       "14           120              2         sigmoid  binary_crossentropy      Adam  \n",
       "15           120              1         sigmoid  binary_crossentropy     Nadam  \n",
       "16            30              1         sigmoid  binary_crossentropy      Adam  \n",
       "17            60              1         sigmoid  binary_crossentropy      Adam  \n",
       "18            60              2         sigmoid  binary_crossentropy     Nadam  \n",
       "19           240              1         sigmoid  binary_crossentropy     Nadam  \n",
       "20           240              1         sigmoid  binary_crossentropy      Adam  \n",
       "21            30              1         sigmoid  binary_crossentropy      Adam  \n",
       "22           240              2         sigmoid  binary_crossentropy      Adam  \n",
       "23            60              1         sigmoid  binary_crossentropy     Nadam  \n",
       "24            30              2         sigmoid  binary_crossentropy     Nadam  \n",
       "25            60              2         sigmoid  binary_crossentropy      Adam  \n",
       "26           240              1         sigmoid  binary_crossentropy      Adam  \n",
       "27           240              1         sigmoid  binary_crossentropy      Adam  \n",
       "28           240              2         sigmoid  binary_crossentropy     Nadam  \n",
       "29            30              2         sigmoid  binary_crossentropy      Adam  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display a dataframe comapring the results of the different combinations \n",
    "t.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the model with the optimised paramaters \n",
    "\n",
    "p_optimisied = {'first_neuron':30,\n",
    "                'second_neuron':200,\n",
    "                'hidden_layers':2,\n",
    "                'batch_size': 10,\n",
    "                'epochs': 200,\n",
    "                'dropout': 0,\n",
    "                'optimizer': 'adam',\n",
    "                'activation':'relu',\n",
    "               }\n",
    "\n",
    "def everest_optimised(x_train, y_train, params):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(params['first_neuron'], input_dim=x_train.shape[1], \n",
    "              activation=params['activation']))\n",
    "    \n",
    "    model.add(Dense(params['second_neuron'], activation=params['activation']))\n",
    " \n",
    "    model.add(Dropout(params['dropout']))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=params['optimizer'], metrics=['accuracy'])\n",
    "    \n",
    "    out = model.fit(x_train, \n",
    "                    y_train,\n",
    "                    epochs=params['epochs'],\n",
    "                    batch_size=params['batch_size'],\n",
    "                    verbose=0)\n",
    "\n",
    "    return out, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-fit the training data to the model\n",
    "out, model = everest_optimised(X_train_scaled, encoded_y_train, p_optimisied)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 - 0s - loss: 0.4020 - accuracy: 0.8489\n",
      "Neural Network Performace - Loss: 0.40195485949516296, Accuracy: 0.8488805890083313\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(X_test_scaled, encoded_y_test, verbose=2)\n",
    "print(f\"Neural Network Performace - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "filename = 'crowding_model_success.h5'\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(\"Model 2 - Deep_learning.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "dev"
  },
  "kernelspec": {
   "display_name": "Python [conda env:PythonData] *",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
